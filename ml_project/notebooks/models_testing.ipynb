{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pandas import read_csv\n",
    "from sklearn.metrics import accuracy_score, balanced_accuracy_score, roc_auc_score, auc\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from numpy import argmax\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# start with linear classifiers, non-linear ones and eventually the more complex neural nets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load a single file as a numpy array\n",
    "# def load_file(filepath):\n",
    "#     dataframe = read_csv(filepath, header=None, delim_whitespace=True)\n",
    "#     return dataframe.values\n",
    "\n",
    "# load a dataset group, such as train or test\n",
    "# def load_dataset_group(group, prefix=''):\n",
    "#     # load input data\n",
    "#     X = load_file(prefix + group + '/X_'+group+'.txt')\n",
    "#     # load class output\n",
    "#     y = load_file(prefix + group + '/y_'+group+'.txt')\n",
    "#     return X, y\n",
    "\n",
    "# load the dataset, returns train and test X and y elements\n",
    "# def load_dataset(prefix=''):\n",
    "#     # load all train\n",
    "#     trainX, trainy = load_dataset_group('train', prefix + 'HARDataset/')\n",
    "#     print(trainX.shape, trainy.shape)\n",
    "#     # load all test\n",
    "#     testX, testy = load_dataset_group('test', prefix + 'HARDataset/')\n",
    "#     print(testX.shape, testy.shape)\n",
    "#     # flatten y\n",
    "#     trainy, testy = trainy[:,0], testy[:,0]\n",
    "#     print(trainX.shape, trainy.shape, testX.shape, testy.shape)\n",
    "#     return trainX, trainy, testX, testy\n",
    "\n",
    "# def load_dataset(prefix=''):\n",
    "#     # load all train\n",
    "#     train = load_dataset_group('train', prefix + 'HARDataset/')\n",
    "#     print(trainX.shape, trainy.shape)\n",
    "#     # load all test\n",
    "#     testX, testy = load_dataset_group('test', prefix + 'HARDataset/')\n",
    "#     print(testX.shape, testy.shape)\n",
    "#     # flatten y\n",
    "#     trainy, testy = trainy[:,0], testy[:,0]\n",
    "#     print(trainX.shape, trainy.shape, testX.shape, testy.shape)\n",
    "#     return trainX, trainy, testX, testy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path = '../data/processed/flori5hz.csv'\n",
    "# values = load_file(path)\n",
    "# #X, y = load_dataset_group()\n",
    "# values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('../data/processed/train.csv')\n",
    "\n",
    "test_df = pd.read_csv('../data/processed/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1207, 1)\n",
      "(1207,)\n"
     ]
    }
   ],
   "source": [
    "X_train = train_df.drop(['state', 'name'], axis=1)\n",
    "y_train = pd.DataFrame(train_df['state'])\n",
    "\n",
    "X_test = test_df.drop(['state', 'name'], axis=1)\n",
    "y_test = pd.DataFrame(test_df['state'])\n",
    "\n",
    "print(y_test.shape)\n",
    "print(test_df['state'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a dict of standard models to evaluate {name:object}\n",
    "def define_models(models=dict()):\n",
    "    # nonlinear models\n",
    "#     models['knn'] = KNeighborsClassifier()\n",
    "#     models['cart'] = DecisionTreeClassifier()\n",
    "#    models['cart'] = { 'clf': DecisionTreeClassifier(), 'params': {}}\n",
    "    #models['svm'] = SVC()\n",
    "#     models['bayes'] = GaussianNB()\n",
    "    # ensemble models\n",
    "#     models['bag'] = BaggingClassifier(n_estimators=100)\n",
    "    models['rf'] = RandomForestClassifier(n_estimators=100)\n",
    "#     models['et'] = ExtraTreesClassifier(n_estimators=100)\n",
    "    models['gbm'] = GradientBoostingClassifier(n_estimators=100)\n",
    "#     models['bag'] = BaggingClassifier()\n",
    "    #models['rf'] = { 'clf': RandomForestClassifier(n_jobs=-1), 'params': {'n_estimators': [100],\n",
    "#                                                                            'bootstrap': [False],\n",
    "#                                                                            'min_samples_split': [10, 20, 40, 50],\n",
    "#                                                                            'max_features': ['log2', 'sqrt','auto', None], \n",
    "#                                                                           'criterion': ['entropy', 'gini']}}\n",
    "#     models['et'] = ExtraTreesClassifier()\n",
    "#     models['gbm'] = GradientBoostingClassifier()\n",
    "    # sgd is sensitive to feature scaling\n",
    "    #models['sgd'] = SGDClassifier()\n",
    "    #models['gp'] = GaussianProcessClassifier()\n",
    "#     models['mlp'] = MLPClassifier()\n",
    "    print('Defined %d models' % len(models))\n",
    "    return models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defined 2 models\n"
     ]
    }
   ],
   "source": [
    "# get model list\n",
    "models = define_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate a single model\n",
    "def evaluate_model(trainX, trainy, testX, testy, model):\n",
    "    # fit the model\n",
    "    model.fit(trainX, trainy)\n",
    "    # make predictions\n",
    "    yhat = model.predict(testX)\n",
    "    # evaluate predictions\n",
    "    accuracy = balanced_accuracy_score(testy, yhat)\n",
    "    #roc_auc = roc_auc_score(testy, yhat)\n",
    "    \n",
    "    print(classification_report(testy, yhat))\n",
    "    print(confusion_matrix(testy, yhat))\n",
    "    return accuracy * 100.0\n",
    "    #return roc_auc * 100.0\n",
    "\n",
    "# evaluate a dict of models {name:object}, returns {name:score}\n",
    "def evaluate_models(trainX, trainy, testX, testy, models):\n",
    "    results = dict()\n",
    "    for name, model in models.items():\n",
    "        # evaluate the model\n",
    "        results[name] = evaluate_model(trainX, trainy, testX, testy, model)\n",
    "        # show process\n",
    "        print('>%s: %.3f' % (name, results[name]))\n",
    "    return results\n",
    "\n",
    "# print and plot the results\n",
    "def summarize_results(results, maximize=True):\n",
    "    # create a list of (name, mean(scores)) tuples\n",
    "    mean_scores = [(k,v) for k,v in results.items()]\n",
    "    # sort tuples by mean score\n",
    "    mean_scores = sorted(mean_scores, key=lambda x: x[1])\n",
    "    # reverse for descending order (e.g. for accuracy)\n",
    "    if maximize:\n",
    "        mean_scores = list(reversed(mean_scores))\n",
    "    print()\n",
    "    for name, score in mean_scores:\n",
    "        print('Name=%s, Score=%.3f' % (name, score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/elizabeth/education/chair_sensor/ml_project/venv/lib/python3.5/site-packages/ipykernel_launcher.py:4: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  after removing the cwd from sys.path.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.96      0.95       510\n",
      "           1       0.87      0.96      0.92       533\n",
      "           2       0.73      0.58      0.65        79\n",
      "           3       0.89      0.36      0.52        85\n",
      "\n",
      "    accuracy                           0.90      1207\n",
      "   macro avg       0.86      0.72      0.76      1207\n",
      "weighted avg       0.89      0.90      0.89      1207\n",
      "\n",
      "[[490  12   4   4]\n",
      " [ 16 514   3   0]\n",
      " [ 12  21  46   0]\n",
      " [  3  41  10  31]]\n",
      ">rf: 71.803\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/elizabeth/education/chair_sensor/ml_project/venv/lib/python3.5/site-packages/sklearn/ensemble/gradient_boosting.py:1450: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.93      0.94       510\n",
      "           1       0.86      0.97      0.91       533\n",
      "           2       0.69      0.59      0.64        79\n",
      "           3       0.83      0.41      0.55        85\n",
      "\n",
      "    accuracy                           0.89      1207\n",
      "   macro avg       0.83      0.73      0.76      1207\n",
      "weighted avg       0.88      0.89      0.88      1207\n",
      "\n",
      "[[472  23   9   6]\n",
      " [ 13 516   4   0]\n",
      " [ 12  19  47   1]\n",
      " [  1  41   8  35]]\n",
      ">gbm: 72.507\n"
     ]
    }
   ],
   "source": [
    "# evaluate models\n",
    "results = evaluate_models(X_train, y_train, X_test, y_test, models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Name=rf, Score=68.030\n"
     ]
    }
   ],
   "source": [
    "### summarize results\n",
    "summarize_results(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">rf\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "list indices must be integers or slices, not str",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-a03c9daba8d2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     51\u001b[0m         \u001b[0mrun_nested_logo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscorer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m \u001b[0mevaluate_tuned_models\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscorer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-8-a03c9daba8d2>\u001b[0m in \u001b[0;36mevaluate_tuned_models\u001b[0;34m(models, scorer)\u001b[0m\n\u001b[1;32m     48\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'>%s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m         \u001b[0mclf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'clf'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'params'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m         \u001b[0mrun_nested_logo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscorer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/education/chair_sensor/ml_project/venv/lib/python3.5/site-packages/sklearn/ensemble/base.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    142\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m         \u001b[0;34m\"\"\"Returns the index'th estimator in the ensemble.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 144\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimators_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    145\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__iter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: list indices must be integers or slices, not str"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import LeaveOneGroupOut\n",
    "from sklearn.metrics import make_scorer, balanced_accuracy_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from pandas import DataFrame\n",
    "import numpy as np\n",
    "\n",
    "all_df = train_df.append(test_df)\n",
    "all_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "X_all = all_df.drop(['state', 'name'], axis=1)\n",
    "y_all = all_df['state']\n",
    "\n",
    "groups = all_df['name']\n",
    "\n",
    "scorer = make_scorer(balanced_accuracy_score)\n",
    "\n",
    "outcomes = []\n",
    "\n",
    "def run_nested_logo(clf, params, scorer):\n",
    "    logo = LeaveOneGroupOut()\n",
    "    group = 0\n",
    "    \n",
    "    for train_index, test_index in logo.split(X_all, groups=groups):\n",
    "        group += 1\n",
    "        X_train, X_test = X_all.iloc[train_index], X_all.iloc[test_index]\n",
    "        y_train, y_test = y_all.iloc[train_index], y_all.iloc[test_index]\n",
    "        \n",
    "        inner_groups = all_df.iloc[all_df.index.isin(train_index)]['name']\n",
    "\n",
    "        logo = LeaveOneGroupOut()\n",
    "        grid_obj = GridSearchCV(clf, params, scoring=scorer, cv=logo.split(X_train, groups=inner_groups), n_jobs=-1)\n",
    "        grid_obj = grid_obj.fit(X_train, y_train)\n",
    "        \n",
    "        print(grid_obj.best_estimator_)\n",
    "        clf = grid_obj.best_estimator_\n",
    "\n",
    "        clf.fit(X_train, y_train)\n",
    "        predictions = clf.predict(X_test)\n",
    "        \n",
    "        accuracy = balanced_accuracy_score(y_test, predictions)\n",
    "        outcomes.append(accuracy)\n",
    "        print(\"Group {0} accuracy: {1}\".format(group, accuracy))\n",
    "    mean_outcome = np.mean(outcomes)\n",
    "    print(\"Mean Accuracy: {0}\".format(mean_outcome))\n",
    "    \n",
    "def evaluate_tuned_models(models, scorer):\n",
    "    results = dict()\n",
    "    for name, model in models.items():\n",
    "        print('>%s' % (name))\n",
    "        clf, params = model['clf'], model['params']\n",
    "        run_nested_logo(clf, params, scorer)\n",
    "\n",
    "evaluate_tuned_models(models, scorer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest\n",
    "\n",
    "# random_forest = RandomForestClassifier(n_estimators=100)\n",
    "# random_forest.fit(X_train, y_train)\n",
    "# y_pred = random_forest.predict(X_test)\n",
    "# y_pred\n",
    "# acc_random_forest = round(random_forest.score(X_test, y_test) * 100, 2)\n",
    "\n",
    "# cnt = 0\n",
    "# sitting = 0\n",
    "# standing = 0\n",
    "# for i in range(0, len(y_pred)):\n",
    "#     if not y_pred[i] == y_test[i]:\n",
    "#         cnt += 1\n",
    "#         if y_pred[i] == 1:\n",
    "#             sitting += 1\n",
    "#         else:\n",
    "#             standing += 1\n",
    "#         print('predicted', y_pred[i], 'actual', y_test[i])\n",
    "        \n",
    "# print('\\nTotal:', len(y_test))\n",
    "# print('Wrong:', cnt)\n",
    "# print('Accuracy:', acc_random_forest)\n",
    "# print('False positive:', sitting)\n",
    "# print('False negative:', standing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted'].",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31m_RemoteTraceback\u001b[0m                          Traceback (most recent call last)",
      "\u001b[0;31m_RemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"/home/elizabeth/education/chair_sensor/ml_project/venv/lib/python3.5/site-packages/joblib/externals/loky/process_executor.py\", line 418, in _process_worker\n    r = call_item()\n  File \"/home/elizabeth/education/chair_sensor/ml_project/venv/lib/python3.5/site-packages/joblib/externals/loky/process_executor.py\", line 272, in __call__\n    return self.fn(*self.args, **self.kwargs)\n  File \"/home/elizabeth/education/chair_sensor/ml_project/venv/lib/python3.5/site-packages/joblib/_parallel_backends.py\", line 567, in __call__\n    return self.func(*args, **kwargs)\n  File \"/home/elizabeth/education/chair_sensor/ml_project/venv/lib/python3.5/site-packages/joblib/parallel.py\", line 225, in __call__\n    for func, args, kwargs in self.items]\n  File \"/home/elizabeth/education/chair_sensor/ml_project/venv/lib/python3.5/site-packages/joblib/parallel.py\", line 225, in <listcomp>\n    for func, args, kwargs in self.items]\n  File \"/home/elizabeth/education/chair_sensor/ml_project/venv/lib/python3.5/site-packages/sklearn/model_selection/_validation.py\", line 554, in _fit_and_score\n    test_scores = _score(estimator, X_test, y_test, scorer, is_multimetric)\n  File \"/home/elizabeth/education/chair_sensor/ml_project/venv/lib/python3.5/site-packages/sklearn/model_selection/_validation.py\", line 597, in _score\n    return _multimetric_score(estimator, X_test, y_test, scorer)\n  File \"/home/elizabeth/education/chair_sensor/ml_project/venv/lib/python3.5/site-packages/sklearn/model_selection/_validation.py\", line 627, in _multimetric_score\n    score = scorer(estimator, X_test, y_test)\n  File \"/home/elizabeth/education/chair_sensor/ml_project/venv/lib/python3.5/site-packages/sklearn/metrics/scorer.py\", line 97, in __call__\n    **self._kwargs)\n  File \"/home/elizabeth/education/chair_sensor/ml_project/venv/lib/python3.5/site-packages/sklearn/metrics/classification.py\", line 1059, in f1_score\n    sample_weight=sample_weight)\n  File \"/home/elizabeth/education/chair_sensor/ml_project/venv/lib/python3.5/site-packages/sklearn/metrics/classification.py\", line 1182, in fbeta_score\n    sample_weight=sample_weight)\n  File \"/home/elizabeth/education/chair_sensor/ml_project/venv/lib/python3.5/site-packages/sklearn/metrics/classification.py\", line 1415, in precision_recall_fscore_support\n    pos_label)\n  File \"/home/elizabeth/education/chair_sensor/ml_project/venv/lib/python3.5/site-packages/sklearn/metrics/classification.py\", line 1254, in _check_set_wise_labels\n    % (y_type, average_options))\nValueError: Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted'].\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-76d95f3fcaae>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;31m# Run the grid search\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0mgrid_obj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'f1'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgroups\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m \u001b[0mgrid_obj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgrid_obj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;31m# Set the clf to the best combination of parameters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/education/chair_sensor/ml_project/venv/lib/python3.5/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    685\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    686\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 687\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    688\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    689\u001b[0m         \u001b[0;31m# For multi-metric evaluation, store the best_index_, best_params_ and\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/education/chair_sensor/ml_project/venv/lib/python3.5/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1146\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1147\u001b[0m         \u001b[0;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1148\u001b[0;31m         \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1149\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/education/chair_sensor/ml_project/venv/lib/python3.5/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params)\u001b[0m\n\u001b[1;32m    664\u001b[0m                                \u001b[0;32mfor\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    665\u001b[0m                                in product(candidate_params,\n\u001b[0;32m--> 666\u001b[0;31m                                           cv.split(X, y, groups)))\n\u001b[0m\u001b[1;32m    667\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    668\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/education/chair_sensor/ml_project/venv/lib/python3.5/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    932\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    933\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 934\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    935\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    936\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/education/chair_sensor/ml_project/venv/lib/python3.5/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    831\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    832\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 833\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    834\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    835\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/education/chair_sensor/ml_project/venv/lib/python3.5/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[0;34m(future, timeout)\u001b[0m\n\u001b[1;32m    519\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[1;32m    520\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    522\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mLokyTimeoutError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.5/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    403\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mCancelledError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    404\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mFINISHED\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 405\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    406\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    407\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.5/concurrent/futures/_base.py\u001b[0m in \u001b[0;36m__get_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    355\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 357\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    358\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    359\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted']."
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import make_scorer, balanced_accuracy_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import LeaveOneGroupOut\n",
    "\n",
    "X_train = train_df.drop(['state', 'name'], axis=1)\n",
    "y_train = train_df['state']\n",
    "X_test = test_df.drop(['state', 'name'], axis=1)\n",
    "y_test = test_df['state']\n",
    "\n",
    "groups = train_df['name']\n",
    "\n",
    "\n",
    "\n",
    "logo = LeaveOneGroupOut()\n",
    "\n",
    "# Choose the type of classifier. \n",
    "clf = RandomForestClassifier()\n",
    "\n",
    "# clf = GradientBoostingClassifier()\n",
    "\n",
    "depths = [2, 4, 8, 16, 32, 64, 80, 100]\n",
    "\n",
    "# Choose some parameter combinations to try\n",
    "# parameters = {'n_estimators': [100, 200],\n",
    "#               'bootstrap': [False],\n",
    "#               'min_samples_split': [10, 20, 40, 50],\n",
    "#                'max_features': ['log2', 'sqrt','auto', None], \n",
    "#                'criterion': ['entropy', 'gini']\n",
    "# #               'max_depth': depths\n",
    "#              }\n",
    "\n",
    "parameters = {'n_estimators': [100]}\n",
    "\n",
    "# Type of scoring used to compare parameter combinations\n",
    "acc_scorer = make_scorer(balanced_accuracy_score)\n",
    "\n",
    "# Run the grid search\n",
    "grid_obj = GridSearchCV(clf, parameters, scoring=acc_scorer, cv=logo.split(X_train, groups=groups), n_jobs=-1)\n",
    "grid_obj = grid_obj.fit(X_train, y_train)\n",
    "\n",
    "# Set the clf to the best combination of parameters\n",
    "clf = grid_obj.best_estimator_\n",
    "\n",
    "# Fit the best algorithm to the data. \n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "predictions = clf.predict(X_test)\n",
    "print(balanced_accuracy_score(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 100}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_obj.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bootstrap': False,\n",
       " 'criterion': 'gini',\n",
       " 'min_samples_split': 10,\n",
       " 'n_estimators': 200,\n",
       " 'warm_start': False}"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_obj.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=False, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=10,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=200, n_jobs=None,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_obj.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Group 1 accuracy: 0.74502341311965\n",
      "Group 2 accuracy: 0.7084465932863271\n",
      "Group 3 accuracy: 0.4614235167312559\n",
      "Group 4 accuracy: 0.5555467040971589\n",
      "Group 5 accuracy: 0.47061931938279433\n",
      "Group 6 accuracy: 0.8153399197516844\n",
      "Group 7 accuracy: 0.722132992651308\n",
      "Group 8 accuracy: 0.7543498168498168\n",
      "Mean Accuracy: 0.6541102844837494\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import LeaveOneGroupOut\n",
    "from pandas import DataFrame\n",
    "import numpy as np\n",
    "\n",
    "X_train = train_df.drop(['state', 'name'], axis=1)\n",
    "y_train = train_df['state']\n",
    "X_test = test_df.drop(['state', 'name'], axis=1)\n",
    "y_test = test_df['state']\n",
    "\n",
    "X_all = X_train.append(X_test)\n",
    "y_all = y_train.append(y_test)\n",
    "\n",
    "groups = train_df.append(test_df)['name']\n",
    "\n",
    "outcomes = []\n",
    "\n",
    "clf = RandomForestClassifier(criterion='gini',\n",
    "                             max_features=None,\n",
    "                             min_samples_split=5,\n",
    "                             n_estimators=100)\n",
    "\n",
    "clf = GradientBoostingClassifier(n_estimators=100)\n",
    "\n",
    "def run_logo(clf):\n",
    "    logo = LeaveOneGroupOut()\n",
    "    group = 0\n",
    "    \n",
    "    for train_index, test_index in logo.split(X_all, groups=groups):\n",
    "        group += 1\n",
    "        X_train, X_test = X_all.values[train_index], X_all.values[test_index]\n",
    "        y_train, y_test = y_all.values[train_index], y_all.values[test_index]\n",
    "        clf.fit(X_train, y_train)\n",
    "        predictions = clf.predict(X_test)\n",
    "        accuracy = balanced_accuracy_score(y_test, predictions)\n",
    "        outcomes.append(accuracy)\n",
    "        print(\"Group {0} accuracy: {1}\".format(group, accuracy))\n",
    "    mean_outcome = np.mean(outcomes)\n",
    "    print(\"Mean Accuracy: {0}\".format(mean_outcome)) \n",
    "\n",
    "run_logo(clf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# testing keras neural network models\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from numpy import dstack\n",
    "import numpy as np\n",
    "from pandas import read_csv\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import LSTM\n",
    "from keras.utils import to_categorical\n",
    "from matplotlib import pyplot\n",
    "\n",
    "\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# load a single file as a numpy array\n",
    "def load_file(filepath):\n",
    "    dataframe = read_csv(filepath, header=None)\n",
    "    return dataframe.values\n",
    "\n",
    "# load a list of files and return as a 3d numpy array\n",
    "def load_group(filenames, prefix=''):\n",
    "    loaded = list()\n",
    "    for name in filenames:\n",
    "        data = load_file(prefix + name)\n",
    "        loaded.append(data)\n",
    "    # stack group so that features are the 3rd dimension\n",
    "    print('loaded', len(loaded[0]))\n",
    "    print('loaded', loaded)\n",
    "    loaded = dstack(loaded)\n",
    "    print('stacked', loaded.shape)\n",
    "    print('stacked', loaded)\n",
    "    return loaded\n",
    "\n",
    "# load a dataset group, such as train or test\n",
    "def load_dataset_group(group, freq, win, prefix=''):\n",
    "    filepath = prefix + group + '/'\n",
    "    # load all 9 files as a single array\n",
    "    filenames = list()\n",
    "    # total acceleration\n",
    "    filenames += ['total_acc_x_'+group+'_'+win+'_'+freq+'.csv', 'total_acc_y_'+group+'_'+win+'_'+freq+'.csv', 'total_acc_z_'+group+'_'+win+'_'+freq+'.csv']\n",
    "#     # body acceleration\n",
    "#     filenames += ['body_acc_x_'+group+'_'+win+'_'+freq+'.csv', 'body_acc_y_'+group+'_'+win+'_'+freq+'.csv', 'body_acc_z_'+group+'_'+win+'_'+freq+'.csv']\n",
    "#     # body gyroscope\n",
    "#     filenames += ['body_gyro_x_'+group+'_'+win+'_'+freq+'.csv', 'body_gyro_y_'+group+'_'+win+'_'+freq+'.csv', 'body_gyro_z_'+group+'_'+win+'_'+freq+'.csv']\n",
    "    # load input data\n",
    "    X = load_group(filenames, filepath)\n",
    "    # load class output\n",
    "    y = load_file(prefix + group + '/state_'+group+'_'+win+'_'+freq+'.csv')\n",
    "    print('X:', filenames)\n",
    "    print('y:', prefix + group + '/state_'+group+'_'+win+'_'+freq+'.csv')\n",
    "    return X, y\n",
    "\n",
    "# load the dataset, returns train and test X and y elements\n",
    "def load_dataset(freq, win, prefix=''):\n",
    "    # load all train\n",
    "    trainX, trainy = load_dataset_group('train', freq, win, prefix)\n",
    "    print(trainX.shape, trainy.shape)\n",
    "    # load all test\n",
    "    testX, testy = load_dataset_group('test', freq, win, prefix)\n",
    "    print(testX.shape, testy.shape)\n",
    "    # zero-offset class values\n",
    "#     trainy = trainy - 1\n",
    "#     testy = testy - 1\n",
    "    # one hot encode y\n",
    "    trainy = to_categorical(trainy)\n",
    "    y_true = testy\n",
    "    testy = to_categorical(testy)\n",
    "    print(trainX.shape, trainy.shape, testX.shape, testy.shape)\n",
    "    return trainX, trainy, testX, testy, y_true\n",
    "\n",
    "# summarize scores\n",
    "def summarize_results(scores):\n",
    "    print(scores)\n",
    "    m, s = mean(scores), std(scores)\n",
    "    print('Accuracy: %.3f%% (+/-%.3f)' % (m, s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded 26349\n",
      "loaded [array([[-0.02734375, -0.03125   , -0.03808594, ..., -0.0234375 ,\n",
      "        -0.03125   , -0.02148438],\n",
      "       [-0.03222656, -0.03320312, -0.03125   , ..., -0.02636719,\n",
      "        -0.03027344, -0.02929688],\n",
      "       [-0.02050781, -0.02734375, -0.03222656, ..., -0.03125   ,\n",
      "        -0.0390625 , -0.02539062],\n",
      "       ...,\n",
      "       [ 0.07519531,  0.07324219,  0.07128906, ...,  0.06738281,\n",
      "         0.07519531,  0.07421875],\n",
      "       [ 0.0703125 ,  0.07910156,  0.0703125 , ...,  0.07324219,\n",
      "         0.07714844,  0.08203125],\n",
      "       [ 0.07519531,  0.07226562,  0.07714844, ...,  0.07519531,\n",
      "         0.07324219,  0.07226562]]), array([[-0.11816406, -0.11523438, -0.11230469, ..., -0.11914062,\n",
      "        -0.1171875 , -0.12109375],\n",
      "       [-0.1171875 , -0.12109375, -0.11523438, ..., -0.125     ,\n",
      "        -0.11816406, -0.11425781],\n",
      "       [-0.11621094, -0.12011719, -0.11425781, ..., -0.12207031,\n",
      "        -0.12402344, -0.11914062],\n",
      "       ...,\n",
      "       [ 0.0078125 ,  0.00195312,  0.        , ...,  0.00292969,\n",
      "        -0.00097656, -0.00683594],\n",
      "       [-0.00683594, -0.00488281,  0.        , ...,  0.00292969,\n",
      "        -0.00390625,  0.00585938],\n",
      "       [-0.00585938,  0.00097656,  0.00097656, ...,  0.00195312,\n",
      "         0.00195312,  0.00390625]]), array([[0.99609375, 1.00292969, 0.99511719, ..., 0.98535156, 0.98632812,\n",
      "        0.97949219],\n",
      "       [1.00488281, 0.98144531, 0.99414062, ..., 0.99121094, 0.98535156,\n",
      "        0.99023438],\n",
      "       [0.98632812, 0.99316406, 0.98828125, ..., 0.98144531, 0.99511719,\n",
      "        1.0078125 ],\n",
      "       ...,\n",
      "       [0.99121094, 0.98632812, 0.99511719, ..., 0.98046875, 0.99121094,\n",
      "        0.99511719],\n",
      "       [0.98925781, 0.99023438, 0.99511719, ..., 1.00488281, 0.98925781,\n",
      "        0.99316406],\n",
      "       [1.00292969, 0.9921875 , 1.        , ..., 0.99609375, 0.99804688,\n",
      "        0.98828125]])]\n",
      "stacked (26349, 50, 3)\n",
      "stacked [[[-2.73437500e-02 -1.18164062e-01  9.96093750e-01]\n",
      "  [-3.12500000e-02 -1.15234375e-01  1.00292969e+00]\n",
      "  [-3.80859375e-02 -1.12304688e-01  9.95117188e-01]\n",
      "  ...\n",
      "  [-2.34375000e-02 -1.19140625e-01  9.85351562e-01]\n",
      "  [-3.12500000e-02 -1.17187500e-01  9.86328125e-01]\n",
      "  [-2.14843750e-02 -1.21093750e-01  9.79492188e-01]]\n",
      "\n",
      " [[-3.22265625e-02 -1.17187500e-01  1.00488281e+00]\n",
      "  [-3.32031250e-02 -1.21093750e-01  9.81445312e-01]\n",
      "  [-3.12500000e-02 -1.15234375e-01  9.94140625e-01]\n",
      "  ...\n",
      "  [-2.63671875e-02 -1.25000000e-01  9.91210938e-01]\n",
      "  [-3.02734375e-02 -1.18164062e-01  9.85351562e-01]\n",
      "  [-2.92968750e-02 -1.14257812e-01  9.90234375e-01]]\n",
      "\n",
      " [[-2.05078125e-02 -1.16210938e-01  9.86328125e-01]\n",
      "  [-2.73437500e-02 -1.20117188e-01  9.93164062e-01]\n",
      "  [-3.22265625e-02 -1.14257812e-01  9.88281250e-01]\n",
      "  ...\n",
      "  [-3.12500000e-02 -1.22070312e-01  9.81445312e-01]\n",
      "  [-3.90625000e-02 -1.24023438e-01  9.95117188e-01]\n",
      "  [-2.53906250e-02 -1.19140625e-01  1.00781250e+00]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[ 7.51953125e-02  7.81250000e-03  9.91210938e-01]\n",
      "  [ 7.32421875e-02  1.95312500e-03  9.86328125e-01]\n",
      "  [ 7.12890625e-02  0.00000000e+00  9.95117188e-01]\n",
      "  ...\n",
      "  [ 6.73828125e-02  2.92968750e-03  9.80468750e-01]\n",
      "  [ 7.51953125e-02 -9.76562500e-04  9.91210938e-01]\n",
      "  [ 7.42187500e-02 -6.83593750e-03  9.95117188e-01]]\n",
      "\n",
      " [[ 7.03125000e-02 -6.83593750e-03  9.89257812e-01]\n",
      "  [ 7.91015625e-02 -4.88281250e-03  9.90234375e-01]\n",
      "  [ 7.03125000e-02  0.00000000e+00  9.95117188e-01]\n",
      "  ...\n",
      "  [ 7.32421875e-02  2.92968750e-03  1.00488281e+00]\n",
      "  [ 7.71484375e-02 -3.90625000e-03  9.89257812e-01]\n",
      "  [ 8.20312500e-02  5.85937500e-03  9.93164062e-01]]\n",
      "\n",
      " [[ 7.51953125e-02 -5.85937500e-03  1.00292969e+00]\n",
      "  [ 7.22656250e-02  9.76562500e-04  9.92187500e-01]\n",
      "  [ 7.71484375e-02  9.76562500e-04  1.00000000e+00]\n",
      "  ...\n",
      "  [ 7.51953125e-02  1.95312500e-03  9.96093750e-01]\n",
      "  [ 7.32421875e-02  1.95312500e-03  9.98046875e-01]\n",
      "  [ 7.22656250e-02  3.90625000e-03  9.88281250e-01]]]\n",
      "X: ['total_acc_x_train_50_50.csv', 'total_acc_y_train_50_50.csv', 'total_acc_z_train_50_50.csv']\n",
      "y: ../data/processed/train/state_train_50_50.csv\n",
      "(26349, 50, 3) (26349, 1)\n",
      "loaded 1117\n",
      "loaded [array([[-0.0078125 ,  0.        , -0.00097656, ..., -0.00878906,\n",
      "         0.00097656, -0.0078125 ],\n",
      "       [-0.0078125 , -0.00878906, -0.01757812, ..., -0.00195312,\n",
      "        -0.00488281, -0.00292969],\n",
      "       [-0.00097656, -0.00878906, -0.00683594, ...,  0.00878906,\n",
      "        -0.01953125, -0.06738281],\n",
      "       ...,\n",
      "       [-0.01953125,  0.        , -0.01074219, ..., -0.00683594,\n",
      "        -0.0078125 , -0.00976562],\n",
      "       [-0.01269531, -0.00585938, -0.00976562, ..., -0.00683594,\n",
      "        -0.00683594, -0.00585938],\n",
      "       [-0.01074219,  0.00097656, -0.01269531, ..., -0.00878906,\n",
      "        -0.0078125 , -0.01367188]]), array([[-0.10351562, -0.10742188, -0.10546875, ..., -0.11230469,\n",
      "        -0.10253906, -0.10546875],\n",
      "       [-0.10449219, -0.10839844, -0.1015625 , ..., -0.09570312,\n",
      "        -0.09765625, -0.10058594],\n",
      "       [-0.10449219, -0.10253906, -0.10058594, ..., -0.15429688,\n",
      "        -0.09082031, -0.01757812],\n",
      "       ...,\n",
      "       [-0.1015625 , -0.109375  , -0.10644531, ..., -0.10449219,\n",
      "        -0.1171875 , -0.109375  ],\n",
      "       [-0.10644531, -0.1171875 , -0.11132812, ..., -0.11132812,\n",
      "        -0.11035156, -0.11132812],\n",
      "       [-0.11425781, -0.11230469, -0.1171875 , ..., -0.10351562,\n",
      "        -0.11230469, -0.11621094]]), array([[0.99511719, 0.98925781, 0.98144531, ..., 0.99023438, 0.97167969,\n",
      "        0.99902344],\n",
      "       [0.98144531, 0.99121094, 0.98242188, ..., 0.99316406, 1.00097656,\n",
      "        1.00097656],\n",
      "       [0.99707031, 0.99121094, 0.9921875 , ..., 1.01367188, 0.9453125 ,\n",
      "        1.74804688],\n",
      "       ...,\n",
      "       [0.98925781, 0.99414062, 0.99316406, ..., 0.984375  , 0.99316406,\n",
      "        0.98242188],\n",
      "       [0.99511719, 0.98828125, 0.97753906, ..., 0.99804688, 0.98925781,\n",
      "        0.99316406],\n",
      "       [0.98730469, 0.99023438, 0.98144531, ..., 0.99609375, 0.98339844,\n",
      "        1.00292969]])]\n",
      "stacked (1117, 50, 3)\n",
      "stacked [[[-7.81250000e-03 -1.03515625e-01  9.95117188e-01]\n",
      "  [ 0.00000000e+00 -1.07421875e-01  9.89257812e-01]\n",
      "  [-9.76562500e-04 -1.05468750e-01  9.81445312e-01]\n",
      "  ...\n",
      "  [-8.78906250e-03 -1.12304688e-01  9.90234375e-01]\n",
      "  [ 9.76562500e-04 -1.02539062e-01  9.71679688e-01]\n",
      "  [-7.81250000e-03 -1.05468750e-01  9.99023438e-01]]\n",
      "\n",
      " [[-7.81250000e-03 -1.04492188e-01  9.81445312e-01]\n",
      "  [-8.78906250e-03 -1.08398438e-01  9.91210938e-01]\n",
      "  [-1.75781250e-02 -1.01562500e-01  9.82421875e-01]\n",
      "  ...\n",
      "  [-1.95312500e-03 -9.57031250e-02  9.93164062e-01]\n",
      "  [-4.88281250e-03 -9.76562500e-02  1.00097656e+00]\n",
      "  [-2.92968750e-03 -1.00585938e-01  1.00097656e+00]]\n",
      "\n",
      " [[-9.76562500e-04 -1.04492188e-01  9.97070312e-01]\n",
      "  [-8.78906250e-03 -1.02539062e-01  9.91210938e-01]\n",
      "  [-6.83593750e-03 -1.00585938e-01  9.92187500e-01]\n",
      "  ...\n",
      "  [ 8.78906250e-03 -1.54296875e-01  1.01367188e+00]\n",
      "  [-1.95312500e-02 -9.08203125e-02  9.45312500e-01]\n",
      "  [-6.73828125e-02 -1.75781250e-02  1.74804688e+00]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[-1.95312500e-02 -1.01562500e-01  9.89257812e-01]\n",
      "  [ 0.00000000e+00 -1.09375000e-01  9.94140625e-01]\n",
      "  [-1.07421875e-02 -1.06445312e-01  9.93164062e-01]\n",
      "  ...\n",
      "  [-6.83593750e-03 -1.04492188e-01  9.84375000e-01]\n",
      "  [-7.81250000e-03 -1.17187500e-01  9.93164062e-01]\n",
      "  [-9.76562500e-03 -1.09375000e-01  9.82421875e-01]]\n",
      "\n",
      " [[-1.26953125e-02 -1.06445312e-01  9.95117188e-01]\n",
      "  [-5.85937500e-03 -1.17187500e-01  9.88281250e-01]\n",
      "  [-9.76562500e-03 -1.11328125e-01  9.77539062e-01]\n",
      "  ...\n",
      "  [-6.83593750e-03 -1.11328125e-01  9.98046875e-01]\n",
      "  [-6.83593750e-03 -1.10351562e-01  9.89257812e-01]\n",
      "  [-5.85937500e-03 -1.11328125e-01  9.93164062e-01]]\n",
      "\n",
      " [[-1.07421875e-02 -1.14257812e-01  9.87304688e-01]\n",
      "  [ 9.76562500e-04 -1.12304688e-01  9.90234375e-01]\n",
      "  [-1.26953125e-02 -1.17187500e-01  9.81445312e-01]\n",
      "  ...\n",
      "  [-8.78906250e-03 -1.03515625e-01  9.96093750e-01]\n",
      "  [-7.81250000e-03 -1.12304688e-01  9.83398438e-01]\n",
      "  [-1.36718750e-02 -1.16210938e-01  1.00292969e+00]]]\n",
      "X: ['total_acc_x_test_50_50.csv', 'total_acc_y_test_50_50.csv', 'total_acc_z_test_50_50.csv']\n",
      "y: ../data/processed/test/state_test_50_50.csv\n",
      "(1117, 50, 3) (1117, 1)\n",
      "(26349, 50, 3) (26349, 4) (1117, 50, 3) (1117, 4)\n",
      "Epoch 1/20\n",
      "26349/26349 [==============================] - 68s 3ms/step - loss: 1.1333 - categorical_accuracy: 0.4537\n",
      "Epoch 2/20\n",
      "26349/26349 [==============================] - 69s 3ms/step - loss: 0.8544 - categorical_accuracy: 0.6944\n",
      "Epoch 3/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26349/26349 [==============================] - 58s 2ms/step - loss: 0.6073 - categorical_accuracy: 0.7817\n",
      "Epoch 4/20\n",
      "26349/26349 [==============================] - 56s 2ms/step - loss: 0.4679 - categorical_accuracy: 0.8255\n",
      "Epoch 5/20\n",
      "26349/26349 [==============================] - 61s 2ms/step - loss: 0.4153 - categorical_accuracy: 0.8522\n",
      "Epoch 6/20\n",
      "26349/26349 [==============================] - 56s 2ms/step - loss: 0.3901 - categorical_accuracy: 0.8630\n",
      "Epoch 7/20\n",
      "26349/26349 [==============================] - 54s 2ms/step - loss: 0.3650 - categorical_accuracy: 0.8723\n",
      "Epoch 8/20\n",
      "26349/26349 [==============================] - 63s 2ms/step - loss: 0.3601 - categorical_accuracy: 0.8721\n",
      "Epoch 9/20\n",
      "26349/26349 [==============================] - 58s 2ms/step - loss: 0.3410 - categorical_accuracy: 0.8802\n",
      "Epoch 10/20\n",
      "26349/26349 [==============================] - 62s 2ms/step - loss: 0.3284 - categorical_accuracy: 0.8838\n",
      "Epoch 11/20\n",
      "26349/26349 [==============================] - 62s 2ms/step - loss: 0.3182 - categorical_accuracy: 0.8856\n",
      "Epoch 12/20\n",
      "26349/26349 [==============================] - 62s 2ms/step - loss: 0.3091 - categorical_accuracy: 0.8890\n",
      "Epoch 13/20\n",
      "26349/26349 [==============================] - 63s 2ms/step - loss: 0.3004 - categorical_accuracy: 0.8918\n",
      "Epoch 14/20\n",
      "26349/26349 [==============================] - 62s 2ms/step - loss: 0.2907 - categorical_accuracy: 0.8973\n",
      "Epoch 15/20\n",
      "26349/26349 [==============================] - 62s 2ms/step - loss: 0.2869 - categorical_accuracy: 0.8981\n",
      "Epoch 16/20\n",
      "26349/26349 [==============================] - 64s 2ms/step - loss: 0.2776 - categorical_accuracy: 0.8998\n",
      "Epoch 17/20\n",
      "26349/26349 [==============================] - 69s 3ms/step - loss: 0.2663 - categorical_accuracy: 0.9060\n",
      "Epoch 18/20\n",
      "26349/26349 [==============================] - 64s 2ms/step - loss: 0.2616 - categorical_accuracy: 0.9072\n",
      "Epoch 19/20\n",
      "26349/26349 [==============================] - 65s 2ms/step - loss: 0.2546 - categorical_accuracy: 0.9087\n",
      "Epoch 20/20\n",
      "26349/26349 [==============================] - 63s 2ms/step - loss: 0.2475 - categorical_accuracy: 0.9130\n",
      "1117/1117 [==============================] - 1s 595us/step\n",
      "0.8773500430018324\n",
      ">#1: 87.735\n",
      "[87.73500430018323]\n",
      "Accuracy: 87.735% (+/-0.000)\n"
     ]
    }
   ],
   "source": [
    "# lstm model\n",
    "# from sklearn.metrics import confusion_matrix\n",
    "from keras.layers import Bidirectional\n",
    "\n",
    "# fit and evaluate a model\n",
    "def evaluate_model(trainX, trainy, testX, testy):\n",
    "    verbose, epochs, batch_size = 1, 20, 10\n",
    "    n_timesteps, n_features, n_outputs = trainX.shape[1], trainX.shape[2], trainy.shape[1]\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(100, input_shape=(n_timesteps,n_features)))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(100, activation='relu'))\n",
    "    model.add(Dense(n_outputs, activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['categorical_accuracy'])\n",
    "    # fit network\n",
    "#     model.fit(trainX, trainy, validation_split=0.2, epochs=epochs, batch_size=batch_size, verbose=verbose)\n",
    "    model.fit(trainX, trainy, epochs=epochs, batch_size=batch_size, verbose=verbose)\n",
    "    # evaluate model\n",
    "    _, accuracy = model.evaluate(testX, testy, batch_size=batch_size, verbose=1)\n",
    "    prediction = model.predict_classes(testX)\n",
    "    return prediction, accuracy, model\n",
    "\n",
    "# run an experiment\n",
    "def run_experiment(freq, win, repeats=1):\n",
    "    # load data\n",
    "    trainX, trainy, testX, testy, y_true = load_dataset(freq=freq, win=win, prefix='../data/processed/')\n",
    "#     score = evaluate_model(trainX, trainy, testX, testy)\n",
    "#     print(score)\n",
    "    # repeat experiment\n",
    "    scores = list()\n",
    "#     for r in range(repeats):\n",
    "    pred_classes, score, model = evaluate_model(trainX, trainy, testX, testy)\n",
    "    print(score)\n",
    "    score = score * 100.0\n",
    "    print('>#%d: %.3f' % (1, score))\n",
    "    scores.append(score)\n",
    "#     print(classification_report(y_true, pred_classes))\n",
    "#     print(confusion_matrix(y_true, pred_classes))\n",
    "    # summarize results\n",
    "    summarize_results(scores)\n",
    "    return pred_classes, y_true, model\n",
    "\n",
    "# run the experiment\n",
    "freq = '50'\n",
    "win = '50'\n",
    "pred_classes, y_true, model = run_experiment(freq, win)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded 4288\n",
      "loaded [array([[ 0.00683594,  0.00195312,  0.00878906, ...,  0.00976562,\n",
      "         0.01074219,  0.01074219],\n",
      "       [ 0.00097656,  0.0078125 ,  0.00292969, ...,  0.00683594,\n",
      "         0.        ,  0.00585938],\n",
      "       [ 0.00585938, -0.00390625,  0.00585938, ...,  0.00292969,\n",
      "         0.01074219,  0.01074219],\n",
      "       ...,\n",
      "       [ 0.07324219,  0.06152344,  0.06640625, ...,  0.06835938,\n",
      "         0.07519531,  0.07519531],\n",
      "       [ 0.07714844,  0.07421875,  0.07714844, ...,  0.0703125 ,\n",
      "         0.07421875,  0.07324219],\n",
      "       [ 0.07714844,  0.07226562,  0.06835938, ...,  0.06835938,\n",
      "         0.08007812,  0.07226562]]), array([[-0.08496094, -0.08300781, -0.08300781, ..., -0.07226562,\n",
      "        -0.07519531, -0.08984375],\n",
      "       [-0.07421875, -0.07714844, -0.07226562, ..., -0.09179688,\n",
      "        -0.08886719, -0.08789062],\n",
      "       [-0.078125  , -0.0859375 , -0.08691406, ..., -0.08496094,\n",
      "        -0.078125  , -0.08105469],\n",
      "       ...,\n",
      "       [ 0.01464844, -0.00976562, -0.00878906, ...,  0.00488281,\n",
      "        -0.00195312,  0.00292969],\n",
      "       [ 0.        ,  0.00292969,  0.00195312, ...,  0.        ,\n",
      "         0.00292969,  0.        ],\n",
      "       [-0.00390625, -0.00195312, -0.00195312, ..., -0.00097656,\n",
      "        -0.00390625,  0.00488281]]), array([[1.00195312, 0.9921875 , 0.99023438, ..., 0.98535156, 0.99316406,\n",
      "        0.99414062],\n",
      "       [0.99804688, 0.98339844, 0.99316406, ..., 0.98339844, 0.99902344,\n",
      "        0.99511719],\n",
      "       [0.99609375, 0.98144531, 0.98925781, ..., 0.99023438, 0.99609375,\n",
      "        0.98730469],\n",
      "       ...,\n",
      "       [1.00488281, 0.98730469, 0.99609375, ..., 0.98730469, 1.00683594,\n",
      "        0.98828125],\n",
      "       [0.9921875 , 0.98144531, 1.01171875, ..., 0.99511719, 0.99511719,\n",
      "        0.99804688],\n",
      "       [0.99902344, 0.98730469, 1.        , ..., 0.98339844, 1.0078125 ,\n",
      "        0.98828125]])]\n",
      "stacked (4288, 50, 3)\n",
      "stacked [[[ 6.83593750e-03 -8.49609375e-02  1.00195312e+00]\n",
      "  [ 1.95312500e-03 -8.30078125e-02  9.92187500e-01]\n",
      "  [ 8.78906250e-03 -8.30078125e-02  9.90234375e-01]\n",
      "  ...\n",
      "  [ 9.76562500e-03 -7.22656250e-02  9.85351562e-01]\n",
      "  [ 1.07421875e-02 -7.51953125e-02  9.93164062e-01]\n",
      "  [ 1.07421875e-02 -8.98437500e-02  9.94140625e-01]]\n",
      "\n",
      " [[ 9.76562500e-04 -7.42187500e-02  9.98046875e-01]\n",
      "  [ 7.81250000e-03 -7.71484375e-02  9.83398438e-01]\n",
      "  [ 2.92968750e-03 -7.22656250e-02  9.93164062e-01]\n",
      "  ...\n",
      "  [ 6.83593750e-03 -9.17968750e-02  9.83398438e-01]\n",
      "  [ 0.00000000e+00 -8.88671875e-02  9.99023438e-01]\n",
      "  [ 5.85937500e-03 -8.78906250e-02  9.95117188e-01]]\n",
      "\n",
      " [[ 5.85937500e-03 -7.81250000e-02  9.96093750e-01]\n",
      "  [-3.90625000e-03 -8.59375000e-02  9.81445312e-01]\n",
      "  [ 5.85937500e-03 -8.69140625e-02  9.89257812e-01]\n",
      "  ...\n",
      "  [ 2.92968750e-03 -8.49609375e-02  9.90234375e-01]\n",
      "  [ 1.07421875e-02 -7.81250000e-02  9.96093750e-01]\n",
      "  [ 1.07421875e-02 -8.10546875e-02  9.87304688e-01]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[ 7.32421875e-02  1.46484375e-02  1.00488281e+00]\n",
      "  [ 6.15234375e-02 -9.76562500e-03  9.87304688e-01]\n",
      "  [ 6.64062500e-02 -8.78906250e-03  9.96093750e-01]\n",
      "  ...\n",
      "  [ 6.83593750e-02  4.88281250e-03  9.87304688e-01]\n",
      "  [ 7.51953125e-02 -1.95312500e-03  1.00683594e+00]\n",
      "  [ 7.51953125e-02  2.92968750e-03  9.88281250e-01]]\n",
      "\n",
      " [[ 7.71484375e-02  0.00000000e+00  9.92187500e-01]\n",
      "  [ 7.42187500e-02  2.92968750e-03  9.81445312e-01]\n",
      "  [ 7.71484375e-02  1.95312500e-03  1.01171875e+00]\n",
      "  ...\n",
      "  [ 7.03125000e-02  0.00000000e+00  9.95117188e-01]\n",
      "  [ 7.42187500e-02  2.92968750e-03  9.95117188e-01]\n",
      "  [ 7.32421875e-02  0.00000000e+00  9.98046875e-01]]\n",
      "\n",
      " [[ 7.71484375e-02 -3.90625000e-03  9.99023438e-01]\n",
      "  [ 7.22656250e-02 -1.95312500e-03  9.87304688e-01]\n",
      "  [ 6.83593750e-02 -1.95312500e-03  1.00000000e+00]\n",
      "  ...\n",
      "  [ 6.83593750e-02 -9.76562500e-04  9.83398438e-01]\n",
      "  [ 8.00781250e-02 -3.90625000e-03  1.00781250e+00]\n",
      "  [ 7.22656250e-02  4.88281250e-03  9.88281250e-01]]]\n",
      "X: ['total_acc_x_train_50_50.csv', 'total_acc_y_train_50_50.csv', 'total_acc_z_train_50_50.csv']\n",
      "y: ../data/processed/train/state_train_50_50.csv\n",
      "(4288, 50, 3) (4288, 1)\n",
      "loaded 1207\n",
      "loaded [array([[-0.0234375 , -0.01855469, -0.0234375 , ..., -0.0234375 ,\n",
      "        -0.02050781, -0.01953125],\n",
      "       [-0.02246094, -0.02148438, -0.015625  , ..., -0.02539062,\n",
      "        -0.01660156, -0.02246094],\n",
      "       [-0.01660156, -0.02734375, -0.01660156, ..., -0.03027344,\n",
      "        -0.02148438, -0.01660156],\n",
      "       ...,\n",
      "       [ 0.08691406,  0.08496094,  0.08105469, ...,  0.07128906,\n",
      "         0.07714844,  0.07421875],\n",
      "       [ 0.08984375,  0.08105469,  0.08300781, ...,  0.07519531,\n",
      "         0.0859375 ,  0.08496094],\n",
      "       [ 0.07421875,  0.07714844,  0.07617188, ...,  0.078125  ,\n",
      "         0.08496094,  0.07519531]]), array([[-0.10253906, -0.1015625 , -0.09179688, ..., -0.09960938,\n",
      "        -0.09667969, -0.09863281],\n",
      "       [-0.09863281, -0.1015625 , -0.10253906, ..., -0.1015625 ,\n",
      "        -0.10058594, -0.09960938],\n",
      "       [-0.09472656, -0.10546875, -0.08984375, ..., -0.09960938,\n",
      "        -0.09570312, -0.09667969],\n",
      "       ...,\n",
      "       [-0.00976562,  0.00097656, -0.00976562, ..., -0.00683594,\n",
      "        -0.0078125 , -0.00585938],\n",
      "       [-0.00976562, -0.01074219, -0.01660156, ..., -0.00683594,\n",
      "        -0.00195312, -0.00292969],\n",
      "       [-0.00292969, -0.00390625, -0.00585938, ..., -0.01269531,\n",
      "        -0.00683594, -0.00585938]]), array([[0.98632812, 0.99023438, 0.98828125, ..., 0.99414062, 0.98046875,\n",
      "        0.96191406],\n",
      "       [0.99609375, 0.99609375, 0.99902344, ..., 0.99121094, 0.98632812,\n",
      "        0.98828125],\n",
      "       [1.00292969, 0.99414062, 0.98144531, ..., 0.98535156, 0.99316406,\n",
      "        0.99902344],\n",
      "       ...,\n",
      "       [0.99023438, 0.984375  , 1.00976562, ..., 1.00097656, 0.99023438,\n",
      "        0.98242188],\n",
      "       [0.99804688, 0.97949219, 0.98144531, ..., 1.        , 1.00292969,\n",
      "        0.99414062],\n",
      "       [1.00195312, 0.98535156, 0.98828125, ..., 1.00878906, 0.99609375,\n",
      "        0.97558594]])]\n",
      "stacked (1207, 50, 3)\n",
      "stacked [[[-2.34375000e-02 -1.02539062e-01  9.86328125e-01]\n",
      "  [-1.85546875e-02 -1.01562500e-01  9.90234375e-01]\n",
      "  [-2.34375000e-02 -9.17968750e-02  9.88281250e-01]\n",
      "  ...\n",
      "  [-2.34375000e-02 -9.96093750e-02  9.94140625e-01]\n",
      "  [-2.05078125e-02 -9.66796875e-02  9.80468750e-01]\n",
      "  [-1.95312500e-02 -9.86328125e-02  9.61914062e-01]]\n",
      "\n",
      " [[-2.24609375e-02 -9.86328125e-02  9.96093750e-01]\n",
      "  [-2.14843750e-02 -1.01562500e-01  9.96093750e-01]\n",
      "  [-1.56250000e-02 -1.02539062e-01  9.99023438e-01]\n",
      "  ...\n",
      "  [-2.53906250e-02 -1.01562500e-01  9.91210938e-01]\n",
      "  [-1.66015625e-02 -1.00585938e-01  9.86328125e-01]\n",
      "  [-2.24609375e-02 -9.96093750e-02  9.88281250e-01]]\n",
      "\n",
      " [[-1.66015625e-02 -9.47265625e-02  1.00292969e+00]\n",
      "  [-2.73437500e-02 -1.05468750e-01  9.94140625e-01]\n",
      "  [-1.66015625e-02 -8.98437500e-02  9.81445312e-01]\n",
      "  ...\n",
      "  [-3.02734375e-02 -9.96093750e-02  9.85351562e-01]\n",
      "  [-2.14843750e-02 -9.57031250e-02  9.93164062e-01]\n",
      "  [-1.66015625e-02 -9.66796875e-02  9.99023438e-01]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[ 8.69140625e-02 -9.76562500e-03  9.90234375e-01]\n",
      "  [ 8.49609375e-02  9.76562500e-04  9.84375000e-01]\n",
      "  [ 8.10546875e-02 -9.76562500e-03  1.00976562e+00]\n",
      "  ...\n",
      "  [ 7.12890625e-02 -6.83593750e-03  1.00097656e+00]\n",
      "  [ 7.71484375e-02 -7.81250000e-03  9.90234375e-01]\n",
      "  [ 7.42187500e-02 -5.85937500e-03  9.82421875e-01]]\n",
      "\n",
      " [[ 8.98437500e-02 -9.76562500e-03  9.98046875e-01]\n",
      "  [ 8.10546875e-02 -1.07421875e-02  9.79492188e-01]\n",
      "  [ 8.30078125e-02 -1.66015625e-02  9.81445312e-01]\n",
      "  ...\n",
      "  [ 7.51953125e-02 -6.83593750e-03  1.00000000e+00]\n",
      "  [ 8.59375000e-02 -1.95312500e-03  1.00292969e+00]\n",
      "  [ 8.49609375e-02 -2.92968750e-03  9.94140625e-01]]\n",
      "\n",
      " [[ 7.42187500e-02 -2.92968750e-03  1.00195312e+00]\n",
      "  [ 7.71484375e-02 -3.90625000e-03  9.85351562e-01]\n",
      "  [ 7.61718750e-02 -5.85937500e-03  9.88281250e-01]\n",
      "  ...\n",
      "  [ 7.81250000e-02 -1.26953125e-02  1.00878906e+00]\n",
      "  [ 8.49609375e-02 -6.83593750e-03  9.96093750e-01]\n",
      "  [ 7.51953125e-02 -5.85937500e-03  9.75585938e-01]]]\n",
      "X: ['total_acc_x_test_50_50.csv', 'total_acc_y_test_50_50.csv', 'total_acc_z_test_50_50.csv']\n",
      "y: ../data/processed/test/state_test_50_50.csv\n",
      "(1207, 50, 3) (1207, 1)\n",
      "(4288, 50, 3) (4288, 4) (1207, 50, 3) (1207, 4)\n"
     ]
    }
   ],
   "source": [
    "freq='50'\n",
    "win='50'\n",
    "trainX, trainy, testX, testy, y_true = load_dataset(freq=freq, win=win, prefix='../data/processed/')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.0078125, -0.015625, -1.013671875], [-0.00390625, -0.017578125, -1.02734375], [0.0087890625, -0.0078125, -1.015625], [0.0009765625, -0.009765625, -1.0234375], [0.009765625, -0.00390625, -1.0224609375], [-0.001953125, -0.01171875, -1.013671875], [-0.00390625, -0.013671875, -1.013671875], [-0.0009765625, -0.00390625, -1.0166015625], [-0.0009765625, -0.0078125, -1.013671875], [0.0078125, 0, -1.01171875], [-0.0029296875, 0, -1.0302734375], [0, 0.0029296875, -1.0078125], [0.001953125, -0.005859375, -1.009765625], [-0.0009765625, 0.00390625, -1.0205078125], [0, -0.0146484375, -1.009765625], [-0.0009765625, -0.0078125, -1.0029296875], [0.0078125, -0.005859375, -1.0283203125], [0.0029296875, -0.0107421875, -1.0107421875], [0.0029296875, -0.01171875, -1.0126953125], [-0.0009765625, -0.0126953125, -1.0068359375], [0.0048828125, -0.0087890625, -1.0166015625], [0.001953125, -0.0048828125, -1.0185546875], [0.0029296875, -0.00390625, -1.0029296875], [0.0009765625, -0.00390625, -1.015625], [-0.00390625, -0.0087890625, -1.017578125], [0.001953125, -0.013671875, -1.0166015625], [0.0087890625, -0.0078125, -1.013671875], [-0.0087890625, -0.0087890625, -1.0283203125], [0.0009765625, -0.0068359375, -1.0244140625], [-0.0029296875, -0.00390625, -1.0322265625], [0.0029296875, -0.013671875, -1.0341796875], [-0.00390625, -0.0126953125, -1.021484375], [0.005859375, -0.0068359375, -1.0283203125], [0.00390625, -0.0078125, -1.0078125], [-0.0009765625, -0.0068359375, -1.0302734375], [0.0009765625, -0.0068359375, -1.0224609375], [-0.001953125, -0.0068359375, -1.017578125], [0, -0.009765625, -1.0068359375], [-0.001953125, -0.0146484375, -1.01953125], [0.005859375, -0.0107421875, -1.0234375], [0, 0.001953125, -1.0302734375], [-0.005859375, -0.0068359375, -1.00390625], [-0.0048828125, -0.0078125, -1.025390625], [-0.0009765625, -0.00390625, -1.009765625], [0.0078125, -0.0107421875, -1.02734375], [0.001953125, -0.0146484375, -1.0078125], [0.001953125, -0.0078125, -1.0234375], [-0.001953125, -0.0087890625, -1.017578125], [0.00390625, -0.0068359375, -1.017578125], [0, -0.009765625, -1.01953125]]\n",
      "loaded 4288\n",
      "stacked (4288, 50, 3)\n",
      "X: ['total_acc_x_train_50_50.csv', 'total_acc_y_train_50_50.csv', 'total_acc_z_train_50_50.csv']\n",
      "y: ../data/processed/train/state_train_50_50.csv\n",
      "(4288, 50, 3) (4288, 1)\n",
      "loaded 1207\n",
      "stacked (1207, 50, 3)\n",
      "X: ['total_acc_x_test_50_50.csv', 'total_acc_y_test_50_50.csv', 'total_acc_z_test_50_50.csv']\n",
      "y: ../data/processed/test/state_test_50_50.csv\n",
      "(1207, 50, 3) (1207, 1)\n",
      "(4288, 50, 3) (4288, 4) (1207, 50, 3) (1207, 4)\n",
      "[[1.7189440e-01 7.6459265e-01 3.7627310e-02 2.5885688e-02]\n",
      " [2.8169519e-01 6.3698608e-01 4.4660129e-02 3.6658596e-02]\n",
      " [2.1760201e-01 7.0112598e-01 4.9808927e-02 3.1463068e-02]\n",
      " ...\n",
      " [6.0900825e-04 9.7425205e-01 1.9950500e-02 5.1884912e-03]\n",
      " [5.0121546e-04 9.7589171e-01 1.8889934e-02 4.7171237e-03]\n",
      " [5.7513476e-04 9.7393268e-01 2.0464137e-02 5.0280415e-03]]\n",
      "[[-0.0234375  -0.10253906  0.98632812]\n",
      " [-0.01855469 -0.1015625   0.99023438]\n",
      " [-0.0234375  -0.09179688  0.98828125]\n",
      " [-0.02734375 -0.10058594  0.99804688]\n",
      " [-0.01367188 -0.09082031  0.98242188]\n",
      " [-0.02929688 -0.09082031  0.9921875 ]\n",
      " [-0.02148438 -0.09863281  0.99121094]\n",
      " [-0.01953125 -0.09179688  0.98730469]\n",
      " [-0.0234375  -0.09765625  0.98925781]\n",
      " [-0.01464844 -0.09570312  0.99609375]\n",
      " [-0.0234375  -0.09667969  0.99414062]\n",
      " [-0.01367188 -0.09765625  0.984375  ]\n",
      " [-0.02148438 -0.10058594  0.97753906]\n",
      " [-0.02050781 -0.09765625  0.97460938]\n",
      " [-0.01855469 -0.10058594  0.99414062]\n",
      " [-0.02734375 -0.10449219  0.99511719]\n",
      " [-0.02441406 -0.1015625   0.98828125]\n",
      " [-0.01171875 -0.10058594  0.99316406]\n",
      " [-0.02636719 -0.09375     0.97753906]\n",
      " [-0.01464844 -0.09667969  0.99121094]\n",
      " [-0.02539062 -0.10058594  0.99609375]\n",
      " [-0.0234375  -0.10449219  0.99316406]\n",
      " [-0.03027344 -0.09960938  0.98535156]\n",
      " [-0.01953125 -0.09960938  0.98632812]\n",
      " [-0.02148438 -0.09570312  1.        ]\n",
      " [-0.02246094 -0.09960938  0.99609375]\n",
      " [-0.02539062 -0.1015625   0.98535156]\n",
      " [-0.0234375  -0.09960938  0.99414062]\n",
      " [-0.01171875 -0.1015625   0.99707031]\n",
      " [-0.03027344 -0.10546875  0.984375  ]\n",
      " [-0.01367188 -0.09765625  0.98144531]\n",
      " [-0.02246094 -0.09765625  0.97851562]\n",
      " [-0.01855469 -0.09863281  0.99121094]\n",
      " [-0.02929688 -0.09765625  0.99023438]\n",
      " [-0.03027344 -0.10253906  0.98828125]\n",
      " [-0.02246094 -0.09765625  0.98046875]\n",
      " [-0.01855469 -0.10449219  0.98632812]\n",
      " [-0.015625   -0.10253906  0.97949219]\n",
      " [-0.015625   -0.09765625  0.98730469]\n",
      " [-0.01953125 -0.09082031  0.98925781]\n",
      " [-0.02929688 -0.09277344  0.98339844]\n",
      " [-0.01660156 -0.1015625   0.97460938]\n",
      " [-0.01757812 -0.09863281  1.00097656]\n",
      " [-0.02929688 -0.10253906  0.98046875]\n",
      " [-0.01074219 -0.1015625   0.98535156]\n",
      " [-0.02734375 -0.09960938  0.99121094]\n",
      " [-0.01953125 -0.09863281  0.9921875 ]\n",
      " [-0.0234375  -0.09960938  0.99414062]\n",
      " [-0.02050781 -0.09667969  0.98046875]\n",
      " [-0.01953125 -0.09863281  0.96191406]]\n"
     ]
    }
   ],
   "source": [
    "sample = [[ [ 0.0078125, -0.015625, -1.013671875 ],[ -0.00390625, -0.017578125, -1.02734375 ],[ 0.0087890625, -0.0078125, -1.015625 ],[ 0.0009765625, -0.009765625, -1.0234375 ],  [ 0.009765625, -0.00390625, -1.0224609375 ],  [ -0.001953125, -0.01171875, -1.013671875 ],  [ -0.00390625, -0.013671875, -1.013671875 ],  [ -0.0009765625, -0.00390625, -1.0166015625 ],  [ -0.0009765625, -0.0078125, -1.013671875 ],  [ 0.0078125, 0, -1.01171875 ],  [ -0.0029296875, 0, -1.0302734375 ],  [ 0, 0.0029296875, -1.0078125 ],  [ 0.001953125, -0.005859375, -1.009765625 ],  [ -0.0009765625, 0.00390625, -1.0205078125 ],  [ 0, -0.0146484375, -1.009765625 ],  [ -0.0009765625, -0.0078125, -1.0029296875 ],  [ 0.0078125, -0.005859375, -1.0283203125 ],  [ 0.0029296875, -0.0107421875, -1.0107421875 ],  [ 0.0029296875, -0.01171875, -1.0126953125 ],  [ -0.0009765625, -0.0126953125, -1.0068359375 ],  [ 0.0048828125, -0.0087890625, -1.0166015625 ],  [ 0.001953125, -0.0048828125, -1.0185546875 ],  [ 0.0029296875, -0.00390625, -1.0029296875 ],  [ 0.0009765625, -0.00390625, -1.015625 ],  [ -0.00390625, -0.0087890625, -1.017578125 ],  [ 0.001953125, -0.013671875, -1.0166015625 ],  [ 0.0087890625, -0.0078125, -1.013671875 ],  [ -0.0087890625, -0.0087890625, -1.0283203125 ],  [ 0.0009765625, -0.0068359375, -1.0244140625 ],  [ -0.0029296875, -0.00390625, -1.0322265625 ],  [ 0.0029296875, -0.013671875, -1.0341796875 ],  [ -0.00390625, -0.0126953125, -1.021484375 ],  [ 0.005859375, -0.0068359375, -1.0283203125 ],  [ 0.00390625, -0.0078125, -1.0078125 ],  [ -0.0009765625, -0.0068359375, -1.0302734375 ],  [ 0.0009765625, -0.0068359375, -1.0224609375 ],  [ -0.001953125, -0.0068359375, -1.017578125 ],  [ 0, -0.009765625, -1.0068359375 ],  [ -0.001953125, -0.0146484375, -1.01953125 ],  [ 0.005859375, -0.0107421875, -1.0234375 ],  [ 0, 0.001953125, -1.0302734375 ],  [ -0.005859375, -0.0068359375, -1.00390625 ],  [ -0.0048828125, -0.0078125, -1.025390625 ],  [ -0.0009765625, -0.00390625, -1.009765625 ],  [ 0.0078125, -0.0107421875, -1.02734375 ],  [ 0.001953125, -0.0146484375, -1.0078125 ],  [ 0.001953125, -0.0078125, -1.0234375 ],  [ -0.001953125, -0.0087890625, -1.017578125 ],  [ 0.00390625, -0.0068359375, -1.017578125 ],  [ 0, -0.009765625, -1.01953125 ]]]\n",
    "print(sample[0])\n",
    "\n",
    "trainX, trainy, testX, testy, y_true = load_dataset(freq=freq, win=win, prefix='../data/processed/')\n",
    "probs = model.predict_proba(testX)\n",
    "\n",
    "print(probs)\n",
    "print(testX[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded 24481\n",
      "stacked (24481, 50, 3)\n",
      "X: ['total_acc_x_train_50_50.csv', 'total_acc_y_train_50_50.csv', 'total_acc_z_train_50_50.csv']\n",
      "y: ../data/processed/train/state_train_50_50.csv\n",
      "(24481, 50, 3) (24481, 1)\n",
      "loaded 2985\n",
      "stacked (2985, 50, 3)\n",
      "X: ['total_acc_x_test_50_50.csv', 'total_acc_y_test_50_50.csv', 'total_acc_z_test_50_50.csv']\n",
      "y: ../data/processed/test/state_test_50_50.csv\n",
      "(2985, 50, 3) (2985, 1)\n",
      "(24481, 50, 3) (24481, 4) (2985, 50, 3) (2985, 4)\n",
      "Saved model to disk\n",
      "Loaded model from disk\n",
      "2985/2985 [==============================] - 15s 5ms/step\n",
      ">#1: 0.901\n"
     ]
    }
   ],
   "source": [
    "##### from keras.models import model_from_json\n",
    "import os\n",
    "\n",
    "trainX, trainy, testX, testy, y_true = load_dataset(freq=freq, win=win, prefix='../data/processed/')\n",
    "\n",
    "# Saving model\n",
    "# serialize model to JSON\n",
    "model_json = model.to_json()\n",
    "with open(\"model.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "# serialize weights to HDF5\n",
    "model.save_weights(\"model.h5\")\n",
    "print(\"Saved model to disk\")\n",
    "\n",
    "# Loading model\n",
    "json_file = open('model.json', 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "loaded_model = model_from_json(loaded_model_json)\n",
    "# load weights into new model\n",
    "loaded_model.load_weights(\"model.h5\")\n",
    "print(\"Loaded model from disk\")\n",
    "\n",
    "# evaluate loaded model on test data\n",
    "loaded_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['categorical_accuracy'])\n",
    "#loaded_model.compile(loss='binary_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
    "# score = loaded_model.evaluate(X, Y, verbose=0)\n",
    "# print(\"%s: %.2f%%\" % (loaded_model.metrics_names[1], score[1]*100))\n",
    "\n",
    "_, accuracy = model.evaluate(testX, testy, batch_size=1, verbose=1)\n",
    "print('>#%d: %.3f' % (1, accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to disk\n"
     ]
    }
   ],
   "source": [
    "# save model and architecture to single file\n",
    "model.save(\"model.h5\")\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/elizabeth/fun/ml_examples/keras_examples/venv/lib/python3.5/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /home/elizabeth/fun/ml_examples/keras_examples/venv/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From /home/elizabeth/fun/ml_examples/keras_examples/venv/lib/python3.5/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "model = load_model('model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [2]\n",
      " [2]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [3]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [2]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [3]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [2]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [3]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [2]\n",
      " [2]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [3]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [2]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [3]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [2]\n",
      " [2]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [3]\n",
      " [3]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [2]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [3]\n",
      " [3]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [2]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [3]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [2]\n",
      " [2]\n",
      " [0]\n",
      " [0]\n",
      " [3]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [2]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [3]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [2]\n",
      " [2]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [3]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]]\n"
     ]
    }
   ],
   "source": [
    "print(y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded 27474\n",
      "loaded [array([[-0.00585938, -0.0078125 ,  0.00390625, ...,  0.01367188,\n",
      "         0.01855469,  0.01367188],\n",
      "       [ 0.00097656, -0.00878906, -0.00292969, ...,  0.01855469,\n",
      "         0.00976562,  0.0078125 ],\n",
      "       [-0.02246094, -0.01953125, -0.02246094, ...,  0.0234375 ,\n",
      "         0.0078125 ,  0.00976562],\n",
      "       ...,\n",
      "       [-0.015625  , -0.00683594, -0.01367188, ..., -0.01464844,\n",
      "        -0.00976562, -0.01269531],\n",
      "       [-0.00683594, -0.00976562, -0.0078125 , ..., -0.01074219,\n",
      "        -0.00976562, -0.00976562],\n",
      "       [-0.01660156, -0.01074219, -0.00683594, ..., -0.00585938,\n",
      "        -0.00097656, -0.015625  ]]), array([[-0.09472656, -0.08496094, -0.08984375, ..., -0.08105469,\n",
      "        -0.07128906, -0.06933594],\n",
      "       [-0.08496094, -0.09179688, -0.09082031, ..., -0.08007812,\n",
      "        -0.08984375, -0.08496094],\n",
      "       [-0.08886719, -0.08886719, -0.09082031, ..., -0.07421875,\n",
      "        -0.07910156, -0.07324219],\n",
      "       ...,\n",
      "       [-0.11328125, -0.10253906, -0.10839844, ..., -0.10839844,\n",
      "        -0.11035156, -0.11035156],\n",
      "       [-0.11328125, -0.10742188, -0.109375  , ..., -0.11523438,\n",
      "        -0.11230469, -0.109375  ],\n",
      "       [-0.10839844, -0.11523438, -0.11230469, ..., -0.10644531,\n",
      "        -0.11132812, -0.10742188]]), array([[1.00097656, 0.99023438, 0.99902344, ..., 0.98339844, 0.98535156,\n",
      "        1.        ],\n",
      "       [0.98632812, 0.97363281, 0.99707031, ..., 0.99121094, 1.00195312,\n",
      "        1.00390625],\n",
      "       [0.99511719, 1.00097656, 0.98535156, ..., 1.00292969, 0.98144531,\n",
      "        0.99609375],\n",
      "       ...,\n",
      "       [0.98828125, 0.98925781, 0.98339844, ..., 0.98925781, 0.98046875,\n",
      "        0.97558594],\n",
      "       [0.98046875, 0.99902344, 0.98925781, ..., 0.98632812, 0.98828125,\n",
      "        0.98925781],\n",
      "       [0.99121094, 0.9765625 , 0.98339844, ..., 0.99023438, 1.00390625,\n",
      "        0.98339844]])]\n",
      "stacked (27474, 50, 3)\n",
      "stacked [[[-5.85937500e-03 -9.47265625e-02  1.00097656e+00]\n",
      "  [-7.81250000e-03 -8.49609375e-02  9.90234375e-01]\n",
      "  [ 3.90625000e-03 -8.98437500e-02  9.99023438e-01]\n",
      "  ...\n",
      "  [ 1.36718750e-02 -8.10546875e-02  9.83398438e-01]\n",
      "  [ 1.85546875e-02 -7.12890625e-02  9.85351562e-01]\n",
      "  [ 1.36718750e-02 -6.93359375e-02  1.00000000e+00]]\n",
      "\n",
      " [[ 9.76562500e-04 -8.49609375e-02  9.86328125e-01]\n",
      "  [-8.78906250e-03 -9.17968750e-02  9.73632812e-01]\n",
      "  [-2.92968750e-03 -9.08203125e-02  9.97070312e-01]\n",
      "  ...\n",
      "  [ 1.85546875e-02 -8.00781250e-02  9.91210938e-01]\n",
      "  [ 9.76562500e-03 -8.98437500e-02  1.00195312e+00]\n",
      "  [ 7.81250000e-03 -8.49609375e-02  1.00390625e+00]]\n",
      "\n",
      " [[-2.24609375e-02 -8.88671875e-02  9.95117188e-01]\n",
      "  [-1.95312500e-02 -8.88671875e-02  1.00097656e+00]\n",
      "  [-2.24609375e-02 -9.08203125e-02  9.85351562e-01]\n",
      "  ...\n",
      "  [ 2.34375000e-02 -7.42187500e-02  1.00292969e+00]\n",
      "  [ 7.81250000e-03 -7.91015625e-02  9.81445312e-01]\n",
      "  [ 9.76562500e-03 -7.32421875e-02  9.96093750e-01]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[-1.56250000e-02 -1.13281250e-01  9.88281250e-01]\n",
      "  [-6.83593750e-03 -1.02539062e-01  9.89257812e-01]\n",
      "  [-1.36718750e-02 -1.08398438e-01  9.83398438e-01]\n",
      "  ...\n",
      "  [-1.46484375e-02 -1.08398438e-01  9.89257812e-01]\n",
      "  [-9.76562500e-03 -1.10351562e-01  9.80468750e-01]\n",
      "  [-1.26953125e-02 -1.10351562e-01  9.75585938e-01]]\n",
      "\n",
      " [[-6.83593750e-03 -1.13281250e-01  9.80468750e-01]\n",
      "  [-9.76562500e-03 -1.07421875e-01  9.99023438e-01]\n",
      "  [-7.81250000e-03 -1.09375000e-01  9.89257812e-01]\n",
      "  ...\n",
      "  [-1.07421875e-02 -1.15234375e-01  9.86328125e-01]\n",
      "  [-9.76562500e-03 -1.12304688e-01  9.88281250e-01]\n",
      "  [-9.76562500e-03 -1.09375000e-01  9.89257812e-01]]\n",
      "\n",
      " [[-1.66015625e-02 -1.08398438e-01  9.91210938e-01]\n",
      "  [-1.07421875e-02 -1.15234375e-01  9.76562500e-01]\n",
      "  [-6.83593750e-03 -1.12304688e-01  9.83398438e-01]\n",
      "  ...\n",
      "  [-5.85937500e-03 -1.06445312e-01  9.90234375e-01]\n",
      "  [-9.76562500e-04 -1.11328125e-01  1.00390625e+00]\n",
      "  [-1.56250000e-02 -1.07421875e-01  9.83398438e-01]]]\n",
      "X: ['total_acc_x_train_50_50.csv', 'total_acc_y_train_50_50.csv', 'total_acc_z_train_50_50.csv']\n",
      "y: ../data/processed/train/state_train_50_50.csv\n",
      "(27474, 50, 3) (27474, 1)\n",
      "loaded 368\n",
      "loaded [array([[-0.01269531, -0.01757812, -0.01269531, ..., -0.00976562,\n",
      "        -0.01855469, -0.01660156],\n",
      "       [-0.015625  , -0.00683594, -0.0234375 , ..., -0.00878906,\n",
      "        -0.0234375 , -0.01074219],\n",
      "       [-0.01855469, -0.02148438, -0.00683594, ..., -0.01953125,\n",
      "        -0.0234375 , -0.02441406],\n",
      "       ...,\n",
      "       [-0.00195312, -0.00683594, -0.01171875, ..., -0.01367188,\n",
      "        -0.015625  ,  0.        ],\n",
      "       [-0.01074219, -0.01367188, -0.01269531, ..., -0.01757812,\n",
      "        -0.01464844, -0.01464844],\n",
      "       [-0.01171875, -0.01464844, -0.015625  , ..., -0.01464844,\n",
      "        -0.00878906, -0.01269531]]), array([[0.05273438, 0.05371094, 0.04882812, ..., 0.03710938, 0.04199219,\n",
      "        0.04296875],\n",
      "       [0.05761719, 0.05175781, 0.05664062, ..., 0.04101562, 0.04785156,\n",
      "        0.04296875],\n",
      "       [0.04882812, 0.05175781, 0.04101562, ..., 0.04296875, 0.04980469,\n",
      "        0.04785156],\n",
      "       ...,\n",
      "       [0.02832031, 0.03320312, 0.02148438, ..., 0.05371094, 0.03710938,\n",
      "        0.04589844],\n",
      "       [0.02246094, 0.0234375 , 0.02246094, ..., 0.04492188, 0.04394531,\n",
      "        0.05371094],\n",
      "       [0.03320312, 0.02734375, 0.03027344, ..., 0.046875  , 0.03808594,\n",
      "        0.0546875 ]]), array([[1.01171875, 0.98925781, 0.99316406, ..., 0.99609375, 0.99316406,\n",
      "        1.00292969],\n",
      "       [1.01074219, 1.00390625, 0.99511719, ..., 0.99511719, 0.99707031,\n",
      "        1.00488281],\n",
      "       [0.98339844, 0.99804688, 0.99511719, ..., 1.00976562, 1.00976562,\n",
      "        1.00097656],\n",
      "       ...,\n",
      "       [1.00488281, 0.99414062, 0.99511719, ..., 1.00488281, 1.06542969,\n",
      "        1.00585938],\n",
      "       [0.98535156, 1.0078125 , 0.99707031, ..., 0.99804688, 0.99804688,\n",
      "        0.99316406],\n",
      "       [0.99804688, 0.99414062, 0.99902344, ..., 1.015625  , 1.00683594,\n",
      "        1.00488281]])]\n",
      "stacked (368, 50, 3)\n",
      "stacked [[[-0.01269531  0.05273438  1.01171875]\n",
      "  [-0.01757812  0.05371094  0.98925781]\n",
      "  [-0.01269531  0.04882812  0.99316406]\n",
      "  ...\n",
      "  [-0.00976562  0.03710938  0.99609375]\n",
      "  [-0.01855469  0.04199219  0.99316406]\n",
      "  [-0.01660156  0.04296875  1.00292969]]\n",
      "\n",
      " [[-0.015625    0.05761719  1.01074219]\n",
      "  [-0.00683594  0.05175781  1.00390625]\n",
      "  [-0.0234375   0.05664062  0.99511719]\n",
      "  ...\n",
      "  [-0.00878906  0.04101562  0.99511719]\n",
      "  [-0.0234375   0.04785156  0.99707031]\n",
      "  [-0.01074219  0.04296875  1.00488281]]\n",
      "\n",
      " [[-0.01855469  0.04882812  0.98339844]\n",
      "  [-0.02148438  0.05175781  0.99804688]\n",
      "  [-0.00683594  0.04101562  0.99511719]\n",
      "  ...\n",
      "  [-0.01953125  0.04296875  1.00976562]\n",
      "  [-0.0234375   0.04980469  1.00976562]\n",
      "  [-0.02441406  0.04785156  1.00097656]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[-0.00195312  0.02832031  1.00488281]\n",
      "  [-0.00683594  0.03320312  0.99414062]\n",
      "  [-0.01171875  0.02148438  0.99511719]\n",
      "  ...\n",
      "  [-0.01367188  0.05371094  1.00488281]\n",
      "  [-0.015625    0.03710938  1.06542969]\n",
      "  [ 0.          0.04589844  1.00585938]]\n",
      "\n",
      " [[-0.01074219  0.02246094  0.98535156]\n",
      "  [-0.01367188  0.0234375   1.0078125 ]\n",
      "  [-0.01269531  0.02246094  0.99707031]\n",
      "  ...\n",
      "  [-0.01757812  0.04492188  0.99804688]\n",
      "  [-0.01464844  0.04394531  0.99804688]\n",
      "  [-0.01464844  0.05371094  0.99316406]]\n",
      "\n",
      " [[-0.01171875  0.03320312  0.99804688]\n",
      "  [-0.01464844  0.02734375  0.99414062]\n",
      "  [-0.015625    0.03027344  0.99902344]\n",
      "  ...\n",
      "  [-0.01464844  0.046875    1.015625  ]\n",
      "  [-0.00878906  0.03808594  1.00683594]\n",
      "  [-0.01269531  0.0546875   1.00488281]]]\n",
      "X: ['total_acc_x_test_50_50.csv', 'total_acc_y_test_50_50.csv', 'total_acc_z_test_50_50.csv']\n",
      "y: ../data/processed/test/state_test_50_50.csv\n",
      "(368, 50, 3) (368, 1)\n",
      "(27474, 50, 3) (27474, 4) (368, 50, 3) (368, 4)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "       3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "       3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "       3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "       3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "       3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "       3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "       3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "       3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "       3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "       3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "       3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "       3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "       3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "       3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "       3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "       3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freq='50'\n",
    "win='50'\n",
    "trainX, trainy, testX, testy, y_true = load_dataset(freq=freq, win=win, prefix='../data/processed/')\n",
    "\n",
    "model.predict_classes(testX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.3814168e-02, 3.8795219e-15, 5.5544578e-18, 9.7618586e-01]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example = []\n",
    "for i in range(0,50):\n",
    "    example.append([1,0,-0.5])\n",
    "# print([example][0])\n",
    "model.predict_proba([[example]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded 24481\n",
      "stacked (24481, 50, 3)\n",
      "X: ['total_acc_x_train_50_50.csv', 'total_acc_y_train_50_50.csv', 'total_acc_z_train_50_50.csv']\n",
      "y: ../data/processed/train/state_train_50_50.csv\n",
      "(24481, 50, 3) (24481, 1)\n",
      "loaded 2985\n",
      "stacked (2985, 50, 3)\n",
      "X: ['total_acc_x_test_50_50.csv', 'total_acc_y_test_50_50.csv', 'total_acc_z_test_50_50.csv']\n",
      "y: ../data/processed/test/state_test_50_50.csv\n",
      "(2985, 50, 3) (2985, 1)\n",
      "(24481, 50, 3) (24481, 4) (2985, 50, 3) (2985, 4)\n",
      "[[ 8.20312500e-02 -4.58984375e-02  9.87304688e-01]\n",
      " [ 8.59375000e-02 -5.56640625e-02  1.00976562e+00]\n",
      " [ 8.39843750e-02 -4.29687500e-02  9.99023438e-01]\n",
      " [ 8.59375000e-02 -4.49218750e-02  9.96093750e-01]\n",
      " [ 8.49609375e-02 -4.68750000e-02  1.00292969e+00]\n",
      " [ 8.69140625e-02 -3.61328125e-02  9.94140625e-01]\n",
      " [ 8.20312500e-02 -4.39453125e-02  9.91210938e-01]\n",
      " [ 9.17968750e-02 -3.71093750e-02  9.96093750e-01]\n",
      " [ 8.30078125e-02 -3.80859375e-02  1.00097656e+00]\n",
      " [ 8.98437500e-02 -5.07812500e-02  9.91210938e-01]\n",
      " [ 8.69140625e-02 -3.41796875e-02  9.98046875e-01]\n",
      " [ 9.37500000e-02 -4.00390625e-02  1.00292969e+00]\n",
      " [ 8.20312500e-02 -3.41796875e-02  1.00097656e+00]\n",
      " [ 8.59375000e-02 -3.32031250e-02  9.92187500e-01]\n",
      " [ 9.17968750e-02 -4.49218750e-02  9.89257812e-01]\n",
      " [ 8.00781250e-02 -3.51562500e-02  9.98046875e-01]\n",
      " [ 9.17968750e-02 -2.44140625e-02  1.00585938e+00]\n",
      " [ 8.69140625e-02 -2.24609375e-02  1.00976562e+00]\n",
      " [ 8.30078125e-02 -1.75781250e-02  9.84375000e-01]\n",
      " [ 7.71484375e-02 -2.83203125e-02  9.92187500e-01]\n",
      " [ 8.59375000e-02 -1.07421875e-02  9.94140625e-01]\n",
      " [ 8.39843750e-02  0.00000000e+00  9.86328125e-01]\n",
      " [ 8.49609375e-02 -1.75781250e-02  9.85351562e-01]\n",
      " [ 8.39843750e-02 -1.56250000e-02  9.84375000e-01]\n",
      " [ 8.78906250e-02 -9.76562500e-03  9.89257812e-01]\n",
      " [ 9.57031250e-02  1.95312500e-03  9.90234375e-01]\n",
      " [ 8.20312500e-02 -8.78906250e-03  9.99023438e-01]\n",
      " [ 8.88671875e-02  9.76562500e-04  9.85351562e-01]\n",
      " [ 9.57031250e-02 -2.92968750e-03  9.85351562e-01]\n",
      " [ 8.69140625e-02  4.88281250e-03  9.95117188e-01]\n",
      " [ 8.88671875e-02 -9.76562500e-04  1.00097656e+00]\n",
      " [ 8.98437500e-02 -1.95312500e-03  9.89257812e-01]\n",
      " [ 8.30078125e-02 -9.76562500e-04  9.79492188e-01]\n",
      " [ 9.47265625e-02  4.88281250e-03  1.00976562e+00]\n",
      " [ 9.08203125e-02  7.81250000e-03  9.90234375e-01]\n",
      " [ 8.69140625e-02  1.26953125e-02  1.01464844e+00]\n",
      " [ 8.30078125e-02  1.85546875e-02  9.96093750e-01]\n",
      " [ 8.88671875e-02  1.46484375e-02  9.98046875e-01]\n",
      " [ 8.69140625e-02  9.76562500e-03  9.95117188e-01]\n",
      " [ 8.10546875e-02  1.07421875e-02  9.80468750e-01]\n",
      " [ 9.08203125e-02  1.46484375e-02  9.86328125e-01]\n",
      " [ 8.69140625e-02  1.85546875e-02  1.00781250e+00]\n",
      " [ 8.39843750e-02  1.85546875e-02  9.95117188e-01]\n",
      " [ 7.22656250e-02  1.56250000e-02  9.81445312e-01]\n",
      " [ 8.59375000e-02  1.95312500e-02  9.83398438e-01]\n",
      " [ 7.71484375e-02  1.46484375e-02  9.84375000e-01]\n",
      " [ 8.59375000e-02  2.34375000e-02  9.86328125e-01]\n",
      " [ 7.91015625e-02  1.85546875e-02  9.91210938e-01]\n",
      " [ 7.81250000e-02  3.22265625e-02  1.00488281e+00]\n",
      " [ 8.20312500e-02  2.14843750e-02  1.00781250e+00]]\n"
     ]
    }
   ],
   "source": [
    "trainX, trainy, testX, testy, y_true = load_dataset(freq=freq, win=win, prefix='../data/processed/')\n",
    "print(testX[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named 'tensorflowjs'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-686419c4aa76>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Save model in tfjs layer format\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflowjs\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtfjs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mtfjs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverters\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_keras_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"./\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: No module named 'tensorflowjs'"
     ]
    }
   ],
   "source": [
    "# # Save model in tfjs layer format\n",
    "# import tensorflowjs as tfjs\n",
    "\n",
    "# tfjs.converters.save_keras_model(model, \"./\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded 22952\n",
      "stacked (22952, 50, 3)\n",
      "X: ['total_acc_x_train_50_50.csv', 'total_acc_y_train_50_50.csv', 'total_acc_z_train_50_50.csv']\n",
      "y: ../data/processed/train/state_train_50_50.csv\n",
      "(22952, 50, 3) (22952, 1)\n",
      "loaded 4514\n",
      "stacked (4514, 50, 3)\n",
      "X: ['total_acc_x_test_50_50.csv', 'total_acc_y_test_50_50.csv', 'total_acc_z_test_50_50.csv']\n",
      "y: ../data/processed/test/state_test_50_50.csv\n",
      "(4514, 50, 3) (4514, 1)\n",
      "(22952, 50, 3) (22952, 4) (4514, 50, 3) (4514, 4)\n",
      "Epoch 1/15\n",
      "22952/22952 [==============================] - 44s 2ms/step - loss: 0.6862 - categorical_accuracy: 0.7197\n",
      "Epoch 2/15\n",
      "22952/22952 [==============================] - 42s 2ms/step - loss: 0.3934 - categorical_accuracy: 0.8586\n",
      "Epoch 3/15\n",
      "22952/22952 [==============================] - 42s 2ms/step - loss: 0.3613 - categorical_accuracy: 0.8688\n",
      "Epoch 4/15\n",
      "22952/22952 [==============================] - 42s 2ms/step - loss: 0.3318 - categorical_accuracy: 0.8788\n",
      "Epoch 5/15\n",
      "22952/22952 [==============================] - 42s 2ms/step - loss: 0.3141 - categorical_accuracy: 0.8867\n",
      "Epoch 6/15\n",
      "22952/22952 [==============================] - 42s 2ms/step - loss: 0.3054 - categorical_accuracy: 0.8896\n",
      "Epoch 7/15\n",
      "22952/22952 [==============================] - 42s 2ms/step - loss: 0.2918 - categorical_accuracy: 0.8946\n",
      "Epoch 8/15\n",
      "22952/22952 [==============================] - 42s 2ms/step - loss: 0.2816 - categorical_accuracy: 0.8973\n",
      "Epoch 9/15\n",
      "22952/22952 [==============================] - 42s 2ms/step - loss: 0.2674 - categorical_accuracy: 0.9041\n",
      "Epoch 10/15\n",
      "22952/22952 [==============================] - 42s 2ms/step - loss: 0.2626 - categorical_accuracy: 0.9047\n",
      "Epoch 11/15\n",
      "22952/22952 [==============================] - 42s 2ms/step - loss: 0.2635 - categorical_accuracy: 0.9058\n",
      "Epoch 12/15\n",
      "22952/22952 [==============================] - 42s 2ms/step - loss: 0.2460 - categorical_accuracy: 0.9111\n",
      "Epoch 13/15\n",
      "22952/22952 [==============================] - 42s 2ms/step - loss: 0.2412 - categorical_accuracy: 0.9122\n",
      "Epoch 14/15\n",
      "22952/22952 [==============================] - 44s 2ms/step - loss: 0.2427 - categorical_accuracy: 0.9132\n",
      "Epoch 15/15\n",
      "22952/22952 [==============================] - 43s 2ms/step - loss: 0.2319 - categorical_accuracy: 0.9146\n",
      "4514/4514 [==============================] - 2s 452us/step\n",
      ">#1: 88.901\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.96      0.93      1677\n",
      "           1       0.92      0.95      0.93      1980\n",
      "           2       0.73      0.55      0.63       401\n",
      "           3       0.81      0.66      0.73       456\n",
      "\n",
      "   micro avg       0.89      0.89      0.89      4514\n",
      "   macro avg       0.84      0.78      0.80      4514\n",
      "weighted avg       0.88      0.89      0.88      4514\n",
      "\n",
      "[[1609   24   27   17]\n",
      " [  49 1883   20   28]\n",
      " [  63   92  221   25]\n",
      " [  68   52   36  300]]\n",
      "[88.90119611946258]\n",
      "Accuracy: 88.901% (+/-0.000)\n"
     ]
    }
   ],
   "source": [
    "# cnn-lstm model\n",
    "\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from numpy import dstack\n",
    "from pandas import read_csv\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import TimeDistributed\n",
    "from keras.layers.convolutional import Conv1D\n",
    "from keras.layers.convolutional import MaxPooling1D\n",
    "from keras.utils import to_categorical\n",
    "from matplotlib import pyplot\n",
    "\n",
    "# fit and evaluate a model\n",
    "def evaluate_model(trainX, trainy, testX, testy):\n",
    "    # define model\n",
    "    verbose, epochs, batch_size = 1, 15, 10\n",
    "    n_timesteps, n_features, n_outputs = trainX.shape[1], trainX.shape[2], trainy.shape[1]\n",
    "    \n",
    "    #splitting windows into blocks because cnn learns features from the blocks,\n",
    "    #and the window timesteps have dependencies we want to learn\n",
    "    # reshape data into time steps of sub-sequences\n",
    "    n_steps, n_length = 1, 50\n",
    "    trainX = trainX.reshape((trainX.shape[0], n_steps, n_length, n_features))\n",
    "    testX = testX.reshape((testX.shape[0], n_steps, n_length, n_features))\n",
    "    # define model\n",
    "    model = Sequential()\n",
    "    model.add(TimeDistributed(Conv1D(filters=64, kernel_size=3, activation='relu'), input_shape=(None,n_length,n_features)))\n",
    "    model.add(TimeDistributed(Conv1D(filters=64, kernel_size=3, activation='relu')))\n",
    "    model.add(TimeDistributed(Dropout(0.5)))\n",
    "    model.add(TimeDistributed(MaxPooling1D(pool_size=2)))\n",
    "    model.add(TimeDistributed(Flatten()))\n",
    "    model.add(LSTM(100))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(100, activation='relu'))\n",
    "    model.add(Dense(n_outputs, activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['categorical_accuracy'])\n",
    "    # fit network\n",
    "    model.fit(trainX, trainy, epochs=epochs, batch_size=batch_size, verbose=verbose)\n",
    "    # evaluate model\n",
    "    _, accuracy = model.evaluate(testX, testy, batch_size=batch_size, verbose=1)\n",
    "    prediction = model.predict_classes(testX)\n",
    "    return prediction, accuracy\n",
    "\n",
    "# run an experiment\n",
    "def run_experiment(freq, win, repeats=1):\n",
    "    # load data\n",
    "    trainX, trainy, testX, testy, y_true = load_dataset(freq=freq, win=win, prefix='../data/processed/')\n",
    "#     score = evaluate_model(trainX, trainy, testX, testy)\n",
    "#     print(score)\n",
    "    # repeat experiment\n",
    "    scores = list()\n",
    "    for r in range(repeats):\n",
    "        pred_classes, score = evaluate_model(trainX, trainy, testX, testy)\n",
    "        score = score * 100.0\n",
    "        print('>#%d: %.3f' % (r+1, score))\n",
    "        scores.append(score)\n",
    "        print(classification_report(y_true, pred_classes))\n",
    "        print(confusion_matrix(y_true, pred_classes))\n",
    "    # summarize results\n",
    "    summarize_results(scores)\n",
    "\n",
    "# run the experiment\n",
    "freq = '50'\n",
    "win = '50'\n",
    "run_experiment(freq, win)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded 9182\n",
      "stacked (9182, 50, 3)\n",
      "X: ['total_acc_x_train_50_50.csv', 'total_acc_y_train_50_50.csv', 'total_acc_z_train_50_50.csv']\n",
      "y: ../data/processed/train/state_train_50_50.csv\n",
      "(9182, 50, 3) (9182, 1)\n",
      "loaded 1806\n",
      "stacked (1806, 50, 3)\n",
      "X: ['total_acc_x_test_50_50.csv', 'total_acc_y_test_50_50.csv', 'total_acc_z_test_50_50.csv']\n",
      "y: ../data/processed/test/state_test_50_50.csv\n",
      "(1806, 50, 3) (1806, 1)\n",
      "(9182, 50, 3) (9182, 4) (1806, 50, 3) (1806, 4)\n",
      "Epoch 1/15\n",
      "9182/9182 [==============================] - 11s 1ms/step - loss: 1.1147 - categorical_accuracy: 0.4720\n",
      "Epoch 2/15\n",
      "9182/9182 [==============================] - 10s 1ms/step - loss: 0.7306 - categorical_accuracy: 0.7487\n",
      "Epoch 3/15\n",
      "9182/9182 [==============================] - 10s 1ms/step - loss: 0.5211 - categorical_accuracy: 0.8093\n",
      "Epoch 4/15\n",
      "9182/9182 [==============================] - 10s 1ms/step - loss: 0.4582 - categorical_accuracy: 0.8404\n",
      "Epoch 5/15\n",
      "9182/9182 [==============================] - 10s 1ms/step - loss: 0.4269 - categorical_accuracy: 0.8561\n",
      "Epoch 6/15\n",
      "9182/9182 [==============================] - 10s 1ms/step - loss: 0.4006 - categorical_accuracy: 0.8607\n",
      "Epoch 7/15\n",
      "9182/9182 [==============================] - 10s 1ms/step - loss: 0.3790 - categorical_accuracy: 0.8684\n",
      "Epoch 8/15\n",
      "9182/9182 [==============================] - 10s 1ms/step - loss: 0.3704 - categorical_accuracy: 0.8702\n",
      "Epoch 9/15\n",
      "9182/9182 [==============================] - 10s 1ms/step - loss: 0.3565 - categorical_accuracy: 0.8780\n",
      "Epoch 10/15\n",
      "9182/9182 [==============================] - 10s 1ms/step - loss: 0.3456 - categorical_accuracy: 0.8801\n",
      "Epoch 11/15\n",
      "9182/9182 [==============================] - 10s 1ms/step - loss: 0.3338 - categorical_accuracy: 0.8795\n",
      "Epoch 12/15\n",
      "9182/9182 [==============================] - 10s 1ms/step - loss: 0.3200 - categorical_accuracy: 0.8858\n",
      "Epoch 13/15\n",
      "9182/9182 [==============================] - 10s 1ms/step - loss: 0.3162 - categorical_accuracy: 0.8870\n",
      "Epoch 14/15\n",
      "9182/9182 [==============================] - 10s 1ms/step - loss: 0.3121 - categorical_accuracy: 0.8884\n",
      "Epoch 15/15\n",
      "9182/9182 [==============================] - 10s 1ms/step - loss: 0.2940 - categorical_accuracy: 0.8977\n",
      "1806/1806 [==============================] - 1s 363us/step\n",
      ">#1: 86.268\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.96      0.93       676\n",
      "           1       0.93      0.92      0.93       790\n",
      "           2       0.48      0.50      0.49       157\n",
      "           3       0.73      0.56      0.63       183\n",
      "\n",
      "   micro avg       0.86      0.86      0.86      1806\n",
      "   macro avg       0.76      0.74      0.74      1806\n",
      "weighted avg       0.86      0.86      0.86      1806\n",
      "\n",
      "[[648   0  21   7]\n",
      " [ 34 729  25   2]\n",
      " [ 16  33  79  29]\n",
      " [ 22  18  41 102]]\n",
      "[86.26799506866523]\n",
      "Accuracy: 86.268% (+/-0.000)\n"
     ]
    }
   ],
   "source": [
    "# convlstm model\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from numpy import dstack\n",
    "from pandas import read_csv\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import TimeDistributed\n",
    "from keras.layers import ConvLSTM2D\n",
    "from keras.utils import to_categorical\n",
    "from matplotlib import pyplot\n",
    "\n",
    "# fit and evaluate a model\n",
    "def evaluate_model(trainX, trainy, testX, testy):\n",
    "    # define model\n",
    "    verbose, epochs, batch_size = 1, 15, 10\n",
    "    n_timesteps, n_features, n_outputs = trainX.shape[1], trainX.shape[2], trainy.shape[1]\n",
    "    # reshape into subsequences (samples, time steps, rows, cols, channels)\n",
    "    n_steps, n_length = 1, 50\n",
    "    trainX = trainX.reshape((trainX.shape[0], n_steps, 1, n_length, n_features))\n",
    "    testX = testX.reshape((testX.shape[0], n_steps, 1, n_length, n_features))\n",
    "#     print('reshaped')\n",
    "#     print(trainX.shape)\n",
    "    # define model\n",
    "    model = Sequential()\n",
    "    model.add(ConvLSTM2D(filters=64, kernel_size=(1,3), activation='relu', input_shape=(n_steps, 1, n_length, n_features)))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(100, activation='relu'))\n",
    "    model.add(Dense(n_outputs, activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['categorical_accuracy'])\n",
    "    # fit network\n",
    "    model.fit(trainX, trainy, epochs=epochs, batch_size=batch_size, verbose=verbose)\n",
    "    # evaluate model\n",
    "    _, accuracy = model.evaluate(testX, testy, batch_size=batch_size, verbose=1)\n",
    "    prediction = model.predict_classes(testX)\n",
    "    return prediction, accuracy\n",
    "\n",
    "# run an experiment\n",
    "def run_experiment(freq, win, repeats=1):\n",
    "    # load data\n",
    "    trainX, trainy, testX, testy, y_true = load_dataset(freq=freq, win=win, prefix='../data/processed/')\n",
    "#     score = evaluate_model(trainX, trainy, testX, testy)\n",
    "#     print(score)\n",
    "    # repeat experiment\n",
    "    scores = list()\n",
    "    for r in range(repeats):\n",
    "        pred_classes, score = evaluate_model(trainX, trainy, testX, testy)\n",
    "        score = score * 100.0\n",
    "        print('>#%d: %.3f' % (r+1, score))\n",
    "        scores.append(score)\n",
    "        print(classification_report(y_true, pred_classes))\n",
    "        print(confusion_matrix(y_true, pred_classes))\n",
    "    # summarize results\n",
    "    summarize_results(scores)\n",
    "\n",
    "# run the experiment\n",
    "freq = '50'\n",
    "win = '50'\n",
    "run_experiment(freq, win)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
