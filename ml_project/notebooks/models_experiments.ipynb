{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Code running experiments with different models and parameters\n",
    "import pandas as pd\n",
    "from pandas import read_csv\n",
    "from pandas import DataFrame\n",
    "from sklearn.metrics import balanced_accuracy_score, f1_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.naive_bayes import ComplementNB\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from numpy import argmax\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "## A separate test set is kept for consistent comparison of models (eg. its semi-supervised counterpart)\n",
    "\n",
    "train_df = pd.read_csv('../data/processed/train.csv')\n",
    "# test_df = pd.read_csv('../data/processed/test.csv')\n",
    "\n",
    "X_train = train_df.drop(['state', 'name'], axis=1)\n",
    "y_train = pd.DataFrame(train_df['state'])\n",
    "\n",
    "# X_test = test_df.drop(['state', 'name'], axis=1)\n",
    "# y_test = pd.DataFrame(test_df['state'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_models(models=dict()):\n",
    "    # nonlinear models\n",
    "#     models['knn'] = KNeighborsClassifier()\n",
    "#     models['cart'] = DecisionTreeClassifier()\n",
    "#     models['svm'] = SVC()\n",
    "    models['bayes'] = GaussianNB()\n",
    "# #     models['mnb'] = MultinomialNB()\n",
    "# #     models['cnb'] = ComplementNB()\n",
    "#     # ensemble models\n",
    "#     models['rf'] = RandomForestClassifier()\n",
    "#     models['et'] = ExtraTreesClassifier()\n",
    "#     models['gbm'] = GradientBoostingClassifier()\n",
    "#     models['bag'] = BaggingClassifier()\n",
    "    print('Defined %d models' % len(models))\n",
    "    return models\n",
    "\n",
    "# print and plot the results\n",
    "def summarize_results(results, maximize=True):\n",
    "    # create a list of (name, mean(scores)) tuples\n",
    "    mean_scores = [(k,v) for k,v in results.items()]\n",
    "    # sort tuples by mean score\n",
    "    mean_scores = sorted(mean_scores, key=lambda x: x[1])\n",
    "    # reverse for descending order (e.g. for accuracy)\n",
    "    if maximize:\n",
    "        mean_scores = list(reversed(mean_scores))\n",
    "    print()\n",
    "    for name, score in mean_scores:\n",
    "        print('Name=%s, Score=%.3f' % (name, score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defined 1 models\n"
     ]
    }
   ],
   "source": [
    "models = define_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import LeaveOneGroupOut\n",
    "\n",
    "def evaluate_model(trainX, trainy, testX, testy, name):\n",
    "    trainy, testy = trainy[:,0], testy[:,0]\n",
    "    # define the models\n",
    "    models = define_models()\n",
    "    model = models[name]\n",
    "    # fit the model\n",
    "    model.fit(trainX, trainy)\n",
    "    # make predictions\n",
    "    yhat = model.predict(testX)\n",
    "\n",
    "#     hat, test = 0,0\n",
    "#     for i in range(len(yhat)):\n",
    "#         if yhat[i] == 0:\n",
    "#             hat += 1\n",
    "#         if testy[i][0] == 0:\n",
    "#             test += 1\n",
    "#     print('hat', hat)\n",
    "#     print('test', test)\n",
    "    # evaluate predictions\n",
    "#     accuracy = balanced_accuracy_score(testy, yhat)\n",
    "    f1_macro = f1_score(testy, yhat, average='macro')\n",
    "    f1_micro = f1_score(testy, yhat, average='micro')\n",
    "    f1 = f1_score(testy, yhat, average=None)\n",
    "\n",
    "#     print('accuracy:', accuracy)\n",
    "#     print(classification_report(testy, yhat))\n",
    "#     print(confusion_matrix(testy, yhat))\n",
    "    return f1, f1_macro, f1_micro\n",
    "\n",
    "def run_logo(name, X_all, y_all, groups):\n",
    "    logo = LeaveOneGroupOut()\n",
    "    group = 0\n",
    "    \n",
    "    f1s = []\n",
    "    f1_macros = []\n",
    "    f1_micros = []\n",
    "    for train_index, test_index in logo.split(X_all, groups=groups):\n",
    "        group += 1\n",
    "        X_train, X_test = X_all.values[train_index], X_all.values[test_index]\n",
    "        y_train, y_test = y_all.values[train_index], y_all.values[test_index]\n",
    "        f1, f1_macro, f1_micro = evaluate_model(X_train, y_train, X_test, y_test,name)\n",
    "        f1s.append(f1)\n",
    "        f1_macros.append(f1_macro)\n",
    "        f1_micros.append(f1_micro)\n",
    "#         print(\"Group {0} f1-scores: {1}\".format(group, f1))\n",
    "#         print(f1_macros)\n",
    "#         print(f1_micros)\n",
    "        \n",
    "#     return np.average(f1s, axis=0).tolist()\n",
    "    return np.average(f1s, axis=0).tolist(), [np.average(f1_macros).tolist()], [np.average(f1_micros).tolist()]\n",
    "\n",
    "def evaluate_models(trainX, trainy, models, groups):\n",
    "    results = dict()\n",
    "\n",
    "    for name, model in models.items():\n",
    "#         results[name] = run_logo(model, trainX, trainy, groups)\n",
    "        results[name] = run_logo(name, trainX, trainy, groups)\n",
    "        # show process\n",
    "        print(name, results[name])\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Run LOGO CV for all models with no hyperparameter tuning and show f1-scores\n",
    "## These results serves as a baseline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 out of 79 files\n",
      "Reading file train30_15_4.csv\n",
      "class frequencies [7527, 8556, 1307, 1350]\n",
      "Defined 1 models\n",
      "Defined 1 models\n",
      "Defined 1 models\n",
      "Defined 1 models\n",
      "Defined 1 models\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/elizabeth/education/chair_sensor/ml_project/venv/lib/python3.5/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defined 1 models\n",
      "Defined 1 models\n",
      "Defined 1 models\n",
      "Defined 1 models\n",
      "gbm ([0.7405489385911024, 0.7568258056728152, 0.49630639995542, 0.5399469674619097], [0.6334070279203119], [0.7517663521678026])\n",
      "1 out of 79 files\n",
      "Reading file train10_5_1.csv\n",
      "class frequencies [7262, 8260, 1252, 1264]\n",
      "Defined 1 models\n",
      "Defined 1 models\n",
      "Defined 1 models\n",
      "Defined 1 models\n",
      "Defined 1 models\n",
      "Defined 1 models\n",
      "Defined 1 models\n",
      "Defined 1 models\n",
      "Defined 1 models\n",
      "gbm ([0.7112216987511695, 0.7392083146322354, 0.49284377835043813, 0.46219092449283683], [0.60136617905667], [0.7267335353817379])\n",
      "1 out of 79 files\n",
      "Reading file train5_3_2.csv\n",
      "class frequencies [14494, 16500, 2524, 2556]\n",
      "Defined 1 models\n",
      "Defined 1 models\n",
      "Defined 1 models\n",
      "Defined 1 models\n",
      "Defined 1 models\n",
      "Defined 1 models\n",
      "Defined 1 models\n",
      "Defined 1 models\n",
      "Defined 1 models\n",
      "gbm ([0.7000798610786642, 0.7254081455053895, 0.4515442770475049, 0.4550738441960862], [0.5830265319569112], [0.7148534711353396])\n",
      "1 out of 79 files\n",
      "Reading file train60_30_8.csv\n",
      "class frequencies [8764, 10004, 1535, 1561]\n",
      "Defined 1 models\n",
      "Defined 1 models\n",
      "Defined 1 models\n",
      "Defined 1 models\n",
      "Defined 1 models\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/elizabeth/education/chair_sensor/ml_project/venv/lib/python3.5/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defined 1 models\n",
      "Defined 1 models\n",
      "Defined 1 models\n",
      "Defined 1 models\n",
      "gbm ([0.7481898894859236, 0.7797022698672053, 0.5376292863351166, 0.5296067439581732], [0.6487820474116046], [0.7623476932530181])\n",
      "1 out of 79 files\n",
      "Reading file train60_90_0.csv\n",
      "class frequencies [2154, 2445, 369, 373]\n",
      "Defined 1 models\n",
      "Defined 1 models\n",
      "Defined 1 models\n",
      "Defined 1 models\n",
      "Defined 1 models\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/elizabeth/education/chair_sensor/ml_project/venv/lib/python3.5/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defined 1 models\n",
      "Defined 1 models\n",
      "Defined 1 models\n",
      "Defined 1 models\n",
      "gbm ([0.7412096730097816, 0.7626668049684675, 0.43499185400056706, 0.5254749404223293], [0.6160858181002864], [0.7480609613290956])\n",
      "1 out of 79 files\n",
      "Reading file train5_5_4.csv\n",
      "class frequencies [14494, 16482, 2524, 2556]\n",
      "Defined 1 models\n",
      "Defined 1 models\n",
      "Defined 1 models\n",
      "Defined 1 models\n",
      "Defined 1 models\n",
      "Defined 1 models\n",
      "Defined 1 models\n",
      "Defined 1 models\n",
      "Defined 1 models\n",
      "gbm ([0.7085011475279849, 0.7239660647806576, 0.47004574304125085, 0.5025895825727834], [0.6012756344806692], [0.7232703148308255])\n",
      "1 out of 79 files\n",
      "Reading file train30_45_23.csv\n",
      "class frequencies [3771, 4274, 650, 665]\n",
      "Defined 1 models\n",
      "Defined 1 models\n",
      "Defined 1 models\n",
      "Defined 1 models\n",
      "Defined 1 models\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/elizabeth/education/chair_sensor/ml_project/venv/lib/python3.5/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defined 1 models\n",
      "Defined 1 models\n",
      "Defined 1 models\n",
      "Defined 1 models\n",
      "gbm ([0.7383894346181783, 0.7520559588540318, 0.47817085395073516, 0.5459513335716587], [0.628641895248651], [0.7529066801998572])\n",
      "1 out of 79 files\n",
      "Reading file train5_5_0.csv\n",
      "class frequencies [2894, 3297, 521, 503]\n",
      "Defined 1 models\n",
      "Defined 1 models\n",
      "Defined 1 models\n",
      "Defined 1 models\n",
      "Defined 1 models\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/elizabeth/education/chair_sensor/ml_project/venv/lib/python3.5/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defined 1 models\n",
      "Defined 1 models\n",
      "Defined 1 models\n",
      "Defined 1 models\n",
      "gbm ([0.7046040110613851, 0.730780456964527, 0.5022977145823684, 0.47305038718209835], [0.6026831424475946], [0.7231910312317104])\n",
      "1 out of 79 files\n",
      "Reading file train30_30_8.csv\n",
      "class frequencies [3759, 4295, 649, 662]\n",
      "Defined 1 models\n",
      "Defined 1 models\n",
      "Defined 1 models\n",
      "Defined 1 models\n",
      "Defined 1 models\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/elizabeth/education/chair_sensor/ml_project/venv/lib/python3.5/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defined 1 models\n",
      "Defined 1 models\n",
      "Defined 1 models\n",
      "Defined 1 models\n",
      "gbm ([0.7436286683302841, 0.7532451586620303, 0.5067840918671569, 0.5368175997764415], [0.6351188796589783], [0.7532189631968709])\n",
      "1 out of 79 files\n",
      "Reading file train60_90_68.csv\n",
      "class frequencies [8784, 9967, 1525, 1563]\n",
      "Defined 1 models\n",
      "Defined 1 models\n",
      "Defined 1 models\n",
      "Defined 1 models\n",
      "Defined 1 models\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/elizabeth/education/chair_sensor/ml_project/venv/lib/python3.5/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defined 1 models\n",
      "Defined 1 models\n",
      "Defined 1 models\n",
      "Defined 1 models\n",
      "gbm ([0.7501786744617731, 0.7610974834031232, 0.5323483741804607, 0.5675000602443089], [0.6527811480724165], [0.764618115407653])\n",
      "1 out of 79 files\n",
      "Reading file train50_100_75.csv\n",
      "class frequencies [5804, 6574, 992, 1034]\n",
      "Defined 1 models\n",
      "Defined 1 models\n",
      "Defined 1 models\n",
      "Defined 1 models\n",
      "Defined 1 models\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/elizabeth/education/chair_sensor/ml_project/venv/lib/python3.5/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defined 1 models\n",
      "Defined 1 models\n",
      "Defined 1 models\n",
      "Defined 1 models\n",
      "gbm ([0.7466405234700213, 0.7679311364210049, 0.5231239186158061, 0.5501078106032042], [0.6469508472775092], [0.763830827996032])\n",
      "1 out of 79 files\n",
      "Reading file train30_30_15.csv\n",
      "class frequencies [5517, 6272, 970, 974]\n",
      "Defined 1 models\n",
      "Defined 1 models\n",
      "Defined 1 models\n",
      "Defined 1 models\n",
      "Defined 1 models\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/elizabeth/education/chair_sensor/ml_project/venv/lib/python3.5/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defined 1 models\n",
      "Defined 1 models\n",
      "Defined 1 models\n",
      "Defined 1 models\n",
      "gbm ([0.7460875010293356, 0.7660259543608513, 0.5090061356937073, 0.5735148752750818], [0.648658616589744], [0.7593059956024454])\n",
      "1 out of 79 files\n",
      "Reading file train60_120_90.csv\n",
      "class frequencies [6436, 7294, 1134, 1144]\n",
      "Defined 1 models\n",
      "Defined 1 models\n",
      "Defined 1 models\n",
      "Defined 1 models\n",
      "Defined 1 models\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/elizabeth/education/chair_sensor/ml_project/venv/lib/python3.5/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defined 1 models\n",
      "Defined 1 models\n",
      "Defined 1 models\n",
      "Defined 1 models\n",
      "gbm ([0.7384627675145388, 0.7511763642145225, 0.5369250675837024, 0.5759952707405348], [0.6506398675133247], [0.7580259686327103])\n",
      "1 out of 79 files\n",
      "Reading file train10_10_8.csv\n",
      "class frequencies [14483, 16477, 2512, 2580]\n",
      "Defined 1 models\n",
      "Defined 1 models\n",
      "Defined 1 models\n",
      "Defined 1 models\n",
      "Defined 1 models\n",
      "Defined 1 models\n",
      "Defined 1 models\n",
      "Defined 1 models\n",
      "Defined 1 models\n",
      "gbm ([0.7262810584543908, 0.7423509220314013, 0.5176772147394004, 0.5577496450863837], [0.636014710077894], [0.7448245114932832])\n",
      "1 out of 79 files\n",
      "Reading file train10_20_0.csv\n",
      "class frequencies [1446, 1638, 265, 256]\n",
      "Defined 1 models\n",
      "Defined 1 models\n",
      "Defined 1 models\n",
      "Defined 1 models\n",
      "Defined 1 models\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/elizabeth/education/chair_sensor/ml_project/venv/lib/python3.5/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defined 1 models\n",
      "Defined 1 models\n",
      "Defined 1 models\n",
      "Defined 1 models\n",
      "gbm ([0.709576732700937, 0.7432686585225794, 0.4721498081194423, 0.49827045548438065], [0.6058164137068349], [0.7329630025796976])\n",
      "1 out of 79 files\n",
      "Reading file train30_15_0.csv\n",
      "class frequencies [5517, 6281, 970, 974]\n",
      "Defined 1 models\n",
      "Defined 1 models\n",
      "Defined 1 models\n",
      "Defined 1 models\n",
      "Defined 1 models\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/elizabeth/education/chair_sensor/ml_project/venv/lib/python3.5/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defined 1 models\n",
      "Defined 1 models\n",
      "Defined 1 models\n",
      "Defined 1 models\n",
      "gbm ([0.7413981899342289, 0.763973356628991, 0.5043996110270492, 0.5203313151528816], [0.6325256181857877], [0.7519661014780262])\n",
      "1 out of 79 files\n",
      "Reading file train60_30_23.csv\n",
      "class frequencies [27622, 31408, 4786, 4890]\n",
      "Defined 1 models\n",
      "Defined 1 models\n",
      "Defined 1 models\n",
      "Defined 1 models\n",
      "Defined 1 models\n",
      "Defined 1 models\n",
      "Defined 1 models\n",
      "Defined 1 models\n",
      "Defined 1 models\n",
      "gbm ([0.7403863576271684, 0.7733024225401989, 0.5667899769583633, 0.5752921521926342], [0.6639427273295911], [0.7628070213076769])\n",
      "1 out of 79 files\n",
      "Reading file train50_25_0.csv\n",
      "class frequencies [5804, 6600, 993, 1034]\n",
      "Defined 1 models\n",
      "Defined 1 models\n",
      "Defined 1 models\n",
      "Defined 1 models\n",
      "Defined 1 models\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/elizabeth/education/chair_sensor/ml_project/venv/lib/python3.5/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defined 1 models\n",
      "Defined 1 models\n",
      "Defined 1 models\n",
      "Defined 1 models\n",
      "gbm ([0.7297838284775631, 0.7609942606744756, 0.5184443165947025, 0.5498692398462658], [0.639772911398252], [0.7510973920532246])\n",
      "1 out of 79 files\n",
      "Reading file train50_25_6.csv\n",
      "class frequencies [7626, 8681, 1332, 1347]\n",
      "Defined 1 models\n",
      "Defined 1 models\n",
      "Defined 1 models\n",
      "Defined 1 models\n",
      "Defined 1 models\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/elizabeth/education/chair_sensor/ml_project/venv/lib/python3.5/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defined 1 models\n",
      "Defined 1 models\n",
      "Defined 1 models\n",
      "Defined 1 models\n",
      "gbm ([0.7447242085636194, 0.7651970336166231, 0.5467411267694523, 0.5699728364025396], [0.6566588013380585], [0.7598071651800434])\n",
      "1 out of 79 files\n",
      "Reading file train30_45_0.csv\n",
      "class frequencies [1849, 2091, 322, 316]\n",
      "Defined 1 models\n",
      "Defined 1 models\n",
      "Defined 1 models\n",
      "Defined 1 models\n",
      "Defined 1 models\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/elizabeth/education/chair_sensor/ml_project/venv/lib/python3.5/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defined 1 models\n",
      "Defined 1 models\n",
      "Defined 1 models\n",
      "Defined 1 models\n",
      "gbm ([0.7340905549697551, 0.7406050907422528, 0.4265673616971186, 0.4870596195959745], [0.5970806567512752], [0.7377184094340633])\n",
      "1 out of 79 files\n",
      "Reading file train5_10_8.csv\n",
      "class frequencies [7232, 8213, 1272, 1292]\n",
      "Defined 1 models\n",
      "Defined 1 models\n",
      "Defined 1 models\n",
      "Defined 1 models\n",
      "Defined 1 models\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/elizabeth/education/chair_sensor/ml_project/venv/lib/python3.5/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defined 1 models\n",
      "Defined 1 models\n",
      "Defined 1 models\n",
      "Defined 1 models\n",
      "gbm ([0.725232445223662, 0.7311828980493338, 0.5243183918448426, 0.5516849417255151], [0.6331046692108383], [0.741629989448393])\n",
      "1 out of 79 files\n",
      "Reading file train30_15_11.csv\n",
      "class frequencies [20722, 23555, 3576, 3674]\n",
      "Defined 1 models\n",
      "Defined 1 models\n",
      "Defined 1 models\n",
      "Defined 1 models\n",
      "Defined 1 models\n",
      "Defined 1 models\n",
      "Defined 1 models\n",
      "Defined 1 models\n",
      "Defined 1 models\n",
      "gbm ([0.7414750555109857, 0.7623630832011614, 0.5396049223563043, 0.5522451243362148], [0.6489220463511666], [0.757640964691721])\n",
      "1 out of 79 files\n",
      "Reading file train30_60_30.csv\n",
      "class frequencies [2770, 3125, 484, 482]\n",
      "Defined 1 models\n",
      "Defined 1 models\n",
      "Defined 1 models\n",
      "Defined 1 models\n",
      "Defined 1 models\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/elizabeth/education/chair_sensor/ml_project/venv/lib/python3.5/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defined 1 models\n",
      "Defined 1 models\n",
      "Defined 1 models\n",
      "Defined 1 models\n",
      "gbm ([0.7578198727433736, 0.7707557107328468, 0.5195040825000979, 0.5786834898636681], [0.6566907889599966], [0.767266965233939])\n",
      "1 out of 79 files\n",
      "Reading file train10_5_0.csv\n",
      "class frequencies [5813, 6610, 993, 1017]\n",
      "Defined 1 models\n",
      "Defined 1 models\n",
      "Defined 1 models\n",
      "Defined 1 models\n",
      "Defined 1 models\n",
      "Defined 1 models\n",
      "Defined 1 models\n",
      "Defined 1 models\n",
      "Defined 1 models\n",
      "gbm ([0.7122224848959636, 0.7445307942062585, 0.48213647072413807, 0.47738644139661385], [0.6040690478057436], [0.7295129236584253])\n",
      "1 out of 79 files\n",
      "Reading file train60_60_15.csv\n",
      "class frequencies [4286, 4875, 758, 766]\n",
      "Defined 1 models\n",
      "Defined 1 models\n",
      "Defined 1 models\n",
      "Defined 1 models\n",
      "Defined 1 models\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/elizabeth/education/chair_sensor/ml_project/venv/lib/python3.5/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defined 1 models\n",
      "Defined 1 models\n",
      "Defined 1 models\n",
      "Defined 1 models\n",
      "gbm ([0.7563988276929889, 0.7646744885085578, 0.535372788265486, 0.5853979145294153], [0.660461004749112], [0.7668191121591135])\n",
      "1 out of 79 files\n",
      "Reading file train10_10_0.csv\n",
      "class frequencies [2903, 3283, 513, 515]\n",
      "Defined 1 models\n",
      "Defined 1 models\n",
      "Defined 1 models\n",
      "Defined 1 models\n",
      "Defined 1 models\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/elizabeth/education/chair_sensor/ml_project/venv/lib/python3.5/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defined 1 models\n",
      "Defined 1 models\n",
      "Defined 1 models\n",
      "Defined 1 models\n",
      "gbm ([0.704485074541635, 0.7358937421057973, 0.4527251131600225, 0.5237713505783079], [0.6042188200964407], [0.7281360015216891])\n",
      "1 out of 79 files\n",
      "Reading file train50_100_50.csv\n",
      "class frequencies [2900, 3273, 513, 518]\n",
      "Defined 1 models\n",
      "Defined 1 models\n",
      "Defined 1 models\n",
      "Defined 1 models\n",
      "Defined 1 models\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/elizabeth/education/chair_sensor/ml_project/venv/lib/python3.5/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defined 1 models\n",
      "Defined 1 models\n",
      "Defined 1 models\n",
      "Defined 1 models\n",
      "gbm ([0.7398902382156486, 0.746412604339715, 0.5025517673493487, 0.5716171793000746], [0.6401179473011968], [0.7518635407222134])\n",
      "1 out of 79 files\n",
      "Reading file train30_60_15.csv\n",
      "class frequencies [1828, 2084, 330, 332]\n",
      "Defined 1 models\n",
      "Defined 1 models\n",
      "Defined 1 models\n",
      "Defined 1 models\n",
      "Defined 1 models\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/elizabeth/education/chair_sensor/ml_project/venv/lib/python3.5/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defined 1 models\n",
      "Defined 1 models\n",
      "Defined 1 models\n",
      "Defined 1 models\n",
      "gbm ([0.7434042680013266, 0.7608834517332156, 0.48021440504910945, 0.5487006297528463], [0.6333006886341245], [0.7534439256231382])\n",
      "1 out of 79 files\n",
      "Reading file train60_60_0.csv\n",
      "class frequencies [3216, 3668, 567, 565]\n",
      "Defined 1 models\n",
      "Defined 1 models\n",
      "Defined 1 models\n",
      "Defined 1 models\n",
      "Defined 1 models\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/elizabeth/education/chair_sensor/ml_project/venv/lib/python3.5/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defined 1 models\n",
      "Defined 1 models\n",
      "Defined 1 models\n",
      "Defined 1 models\n",
      "gbm ([0.7391385332542031, 0.7551532082517832, 0.4907057955513292, 0.5336754587307035], [0.6296682489470048], [0.7500582390089745])\n",
      "1 out of 79 files\n",
      "Reading file train10_20_5.csv\n",
      "class frequencies [1932, 2204, 322, 345]\n",
      "Defined 1 models\n",
      "Defined 1 models\n",
      "Defined 1 models\n",
      "Defined 1 models\n",
      "Defined 1 models\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/elizabeth/education/chair_sensor/ml_project/venv/lib/python3.5/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defined 1 models\n",
      "Defined 1 models\n",
      "Defined 1 models\n",
      "Defined 1 models\n",
      "gbm ([0.713383313218397, 0.7314576652546981, 0.48102873226330317, 0.49140185347443044], [0.6043178910527071], [0.731292275819317])\n",
      "1 out of 79 files\n",
      "Reading file train5_10_0.csv\n",
      "class frequencies [1440, 1641, 271, 253]\n",
      "Defined 1 models\n",
      "Defined 1 models\n",
      "Defined 1 models\n",
      "Defined 1 models\n",
      "Defined 1 models\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/elizabeth/education/chair_sensor/ml_project/venv/lib/python3.5/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defined 1 models\n",
      "Defined 1 models\n",
      "Defined 1 models\n",
      "Defined 1 models\n",
      "gbm ([0.7100429685650536, 0.7305611603446964, 0.5170604812937801, 0.5321683022097351], [0.6224582281033162], [0.7280147117808136])\n",
      "1 out of 79 files\n",
      "Reading file train50_75_19.csv\n",
      "class frequencies [2582, 2926, 465, 463]\n",
      "Defined 1 models\n",
      "Defined 1 models\n",
      "Defined 1 models\n",
      "Defined 1 models\n",
      "Defined 1 models\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/elizabeth/education/chair_sensor/ml_project/venv/lib/python3.5/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defined 1 models\n",
      "Defined 1 models\n",
      "Defined 1 models\n",
      "Defined 1 models\n",
      "gbm ([0.7455429071467847, 0.7647215072816969, 0.48487495668667574, 0.5065872455470388], [0.625431654165549], [0.7524147544713107])\n",
      "1 out of 79 files\n",
      "Reading file train10_15_11.csv\n",
      "class frequencies [7232, 8222, 1272, 1292]\n",
      "Defined 1 models\n",
      "Defined 1 models\n",
      "Defined 1 models\n",
      "Defined 1 models\n",
      "Defined 1 models\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/elizabeth/education/chair_sensor/ml_project/venv/lib/python3.5/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defined 1 models\n",
      "Defined 1 models\n",
      "Defined 1 models\n",
      "Defined 1 models\n",
      "gbm ([0.7262274106189601, 0.7484842742221942, 0.5195427297329333, 0.5553891926237711], [0.6374109017994646], [0.7477228210823427])\n",
      "1 out of 79 files\n",
      "Reading file train5_3_0.csv\n",
      "class frequencies [4825, 5500, 842, 860]\n",
      "Defined 1 models\n",
      "Defined 1 models\n",
      "Defined 1 models\n",
      "Defined 1 models\n",
      "Defined 1 models\n",
      "Defined 1 models\n",
      "Defined 1 models\n",
      "Defined 1 models\n",
      "Defined 1 models\n",
      "gbm ([0.7017340375882555, 0.722056149822796, 0.45678415446173204, 0.45600786949224115], [0.5841455528412562], [0.7143011527209131])\n",
      "1 out of 79 files\n",
      "Reading file train30_45_11.csv\n",
      "class frequencies [2443, 2760, 417, 437]\n",
      "Defined 1 models\n",
      "Defined 1 models\n",
      "Defined 1 models\n",
      "Defined 1 models\n",
      "Defined 1 models\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/elizabeth/education/chair_sensor/ml_project/venv/lib/python3.5/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defined 1 models\n",
      "Defined 1 models\n",
      "Defined 1 models\n",
      "Defined 1 models\n",
      "gbm ([0.7423015704303728, 0.764248933791855, 0.4958446667078707, 0.5770577335423414], [0.6448632261181099], [0.7581772337506707])\n",
      "1 out of 79 files\n",
      "Reading file train60_120_0.csv\n",
      "class frequencies [1612, 1827, 292, 275]\n",
      "Defined 1 models\n",
      "Defined 1 models\n",
      "Defined 1 models\n",
      "Defined 1 models\n",
      "Defined 1 models\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/elizabeth/education/chair_sensor/ml_project/venv/lib/python3.5/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defined 1 models\n",
      "Defined 1 models\n",
      "Defined 1 models\n",
      "Defined 1 models\n",
      "gbm ([0.7423393894003838, 0.7484632383788765, 0.5120034707039753, 0.5139434501096252], [0.6291873871482152], [0.7465678169607642])\n",
      "1 out of 79 files\n",
      "Reading file train10_20_10.csv\n",
      "class frequencies [2903, 3274, 513, 515]\n",
      "Defined 1 models\n",
      "Defined 1 models\n",
      "Defined 1 models\n",
      "Defined 1 models\n",
      "Defined 1 models\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/elizabeth/education/chair_sensor/ml_project/venv/lib/python3.5/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defined 1 models\n",
      "Defined 1 models\n",
      "Defined 1 models\n",
      "Defined 1 models\n",
      "gbm ([0.7227845507813446, 0.7501174199169128, 0.48666618447098453, 0.5266496430403237], [0.6215544495523915], [0.7427821392517022])\n",
      "1 out of 79 files\n",
      "Reading file train5_10_3.csv\n",
      "class frequencies [2095, 2361, 344, 348]\n",
      "Defined 1 models\n",
      "Defined 1 models\n",
      "Defined 1 models\n",
      "Defined 1 models\n",
      "Defined 1 models\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/elizabeth/education/chair_sensor/ml_project/venv/lib/python3.5/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defined 1 models\n",
      "Defined 1 models\n",
      "Defined 1 models\n",
      "Defined 1 models\n",
      "gbm ([0.7168707044564896, 0.7357416658071105, 0.4342509883786646, 0.5145124302056825], [0.6003439472119868], [0.7308048542558735])\n",
      "1 out of 79 files\n",
      "Reading file train10_15_0.csv\n",
      "class frequencies [1931, 2199, 346, 334]\n",
      "Defined 1 models\n",
      "Defined 1 models\n",
      "Defined 1 models\n",
      "Defined 1 models\n",
      "Defined 1 models\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/elizabeth/education/chair_sensor/ml_project/venv/lib/python3.5/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defined 1 models\n",
      "Defined 1 models\n",
      "Defined 1 models\n",
      "Defined 1 models\n",
      "gbm ([0.7141841323671712, 0.7380886315751601, 0.4687902573616859, 0.5424564468673645], [0.6158798670428455], [0.7348623524518062])\n",
      "1 out of 79 files\n",
      "Reading file train10_15_4.csv\n",
      "class frequencies [2626, 3007, 456, 464]\n",
      "Defined 1 models\n",
      "Defined 1 models\n",
      "Defined 1 models\n",
      "Defined 1 models\n",
      "Defined 1 models\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/elizabeth/education/chair_sensor/ml_project/venv/lib/python3.5/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defined 1 models\n",
      "Defined 1 models\n",
      "Defined 1 models\n",
      "Defined 1 models\n",
      "gbm ([0.7221347315059456, 0.7529711233712062, 0.48941176585362417, 0.4894677575759327], [0.6134963445766773], [0.7394598080735224])\n",
      "opening existing file results/gbm.csv\n",
      "2 out of 79 files\n",
      "Reading file train60_60_45.csv\n",
      "class frequencies [12875, 14631, 2249, 2292]\n",
      "Defined 1 models\n",
      "Defined 1 models\n",
      "Defined 1 models\n",
      "Defined 1 models\n",
      "Defined 1 models\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/elizabeth/education/chair_sensor/ml_project/venv/lib/python3.5/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defined 1 models\n",
      "Defined 1 models\n",
      "Defined 1 models\n",
      "Defined 1 models\n",
      "gbm ([0.7517810867919553, 0.7671225291613132, 0.5466860955702288, 0.5882112822262575], [0.6634502484374388], [0.7675424987467597])\n",
      "opening existing file results/gbm.csv\n",
      "3 out of 79 files\n",
      "Reading file train30_60_0.csv\n",
      "class frequencies [1379, 1575, 237, 242]\n",
      "Defined 1 models\n",
      "Defined 1 models\n",
      "Defined 1 models\n",
      "Defined 1 models\n",
      "Defined 1 models\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/elizabeth/education/chair_sensor/ml_project/venv/lib/python3.5/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defined 1 models\n",
      "Defined 1 models\n",
      "Defined 1 models\n",
      "Defined 1 models\n",
      "gbm ([0.7449325156419029, 0.7778313788221167, 0.4643203607574391, 0.5133927756333472], [0.6251192577137015], [0.7569023595785268])\n",
      "opening existing file results/gbm.csv\n",
      "4 out of 79 files\n",
      "Reading file train10_10_5.csv\n",
      "class frequencies [5813, 6601, 993, 1017]\n",
      "Defined 1 models\n",
      "Defined 1 models\n",
      "Defined 1 models\n",
      "Defined 1 models\n",
      "Defined 1 models\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/elizabeth/education/chair_sensor/ml_project/venv/lib/python3.5/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defined 1 models\n",
      "Defined 1 models\n",
      "Defined 1 models\n",
      "Defined 1 models\n",
      "gbm ([0.7160097880200582, 0.745424368813732, 0.5110043557989348, 0.5440208175626684], [0.6291148325488485], [0.7398604235873117])\n",
      "opening existing file results/gbm.csv\n",
      "5 out of 79 files\n",
      "Reading file train50_75_0.csv\n",
      "class frequencies [1917, 2198, 348, 346]\n",
      "Defined 1 models\n",
      "Defined 1 models\n",
      "Defined 1 models\n",
      "Defined 1 models\n",
      "Defined 1 models\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/elizabeth/education/chair_sensor/ml_project/venv/lib/python3.5/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defined 1 models\n",
      "Defined 1 models\n",
      "Defined 1 models\n",
      "Defined 1 models\n",
      "gbm ([0.7346068260902814, 0.7593119460032347, 0.4870805147861077, 0.5059797838859281], [0.6217447676913881], [0.7484279932494308])\n",
      "opening existing file results/gbm.csv\n",
      "6 out of 79 files\n",
      "Reading file train30_45_34.csv\n",
      "class frequencies [7533, 8559, 1304, 1320]\n",
      "Defined 1 models\n",
      "Defined 1 models\n",
      "Defined 1 models\n",
      "Defined 1 models\n",
      "Defined 1 models\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/elizabeth/education/chair_sensor/ml_project/venv/lib/python3.5/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defined 1 models\n",
      "Defined 1 models\n",
      "Defined 1 models\n",
      "Defined 1 models\n",
      "gbm ([0.7419490152920271, 0.7519274043539765, 0.5213400097025427, 0.5559833265618017], [0.642799938977587], [0.757221363207842])\n",
      "opening existing file results/gbm.csv\n",
      "7 out of 79 files\n",
      "Reading file train50_25_13.csv\n",
      "class frequencies [12078, 13746, 2083, 2152]\n",
      "Defined 1 models\n",
      "Defined 1 models\n",
      "Defined 1 models\n",
      "Defined 1 models\n",
      "Defined 1 models\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/elizabeth/education/chair_sensor/ml_project/venv/lib/python3.5/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defined 1 models\n",
      "Defined 1 models\n",
      "Defined 1 models\n",
      "Defined 1 models\n",
      "gbm ([0.7505919179884323, 0.7824816757696285, 0.5616619142670465, 0.576917293718488], [0.6679132004358987], [0.7694672780622348])\n",
      "opening existing file results/gbm.csv\n",
      "8 out of 79 files\n",
      "Reading file train50_50_0.csv\n",
      "class frequencies [2900, 3282, 513, 518]\n",
      "Defined 1 models\n",
      "Defined 1 models\n",
      "Defined 1 models\n",
      "Defined 1 models\n",
      "Defined 1 models\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/elizabeth/education/chair_sensor/ml_project/venv/lib/python3.5/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defined 1 models\n",
      "Defined 1 models\n",
      "Defined 1 models\n",
      "Defined 1 models\n",
      "gbm ([0.7377302230678817, 0.7521089441059852, 0.4959087379319265, 0.5661739835935422], [0.6379804721748338], [0.7477888374569326])\n",
      "opening existing file results/gbm.csv\n",
      "9 out of 79 files\n",
      "Reading file train10_5_3.csv\n",
      "class frequencies [14494, 16500, 2524, 2556]\n",
      "Defined 1 models\n",
      "Defined 1 models\n",
      "Defined 1 models\n",
      "Defined 1 models\n",
      "Defined 1 models\n",
      "Defined 1 models\n",
      "Defined 1 models\n",
      "Defined 1 models\n",
      "Defined 1 models\n",
      "gbm ([0.713641981135747, 0.7499051675916466, 0.49520996589106253, 0.5007840605632025], [0.6148852937954147], [0.7331024228235266])\n",
      "opening existing file results/gbm.csv\n",
      "10 out of 79 files\n",
      "Reading file train30_30_22.csv\n",
      "class frequencies [10348, 11764, 1799, 1839]\n",
      "Defined 1 models\n",
      "Defined 1 models\n",
      "Defined 1 models\n",
      "Defined 1 models\n",
      "Defined 1 models\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/elizabeth/education/chair_sensor/ml_project/venv/lib/python3.5/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defined 1 models\n",
      "Defined 1 models\n",
      "Defined 1 models\n",
      "Defined 1 models\n",
      "gbm ([0.7404780920282651, 0.7616805563737663, 0.5308982953596577, 0.5618602925636753], [0.6487293090813412], [0.7584964184921232])\n",
      "opening existing file results/gbm.csv\n",
      "11 out of 79 files\n",
      "Reading file train60_90_45.csv\n",
      "class frequencies [4302, 4881, 744, 752]\n",
      "Defined 1 models\n",
      "Defined 1 models\n",
      "Defined 1 models\n",
      "Defined 1 models\n",
      "Defined 1 models\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/elizabeth/education/chair_sensor/ml_project/venv/lib/python3.5/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defined 1 models\n",
      "Defined 1 models\n",
      "Defined 1 models\n",
      "Defined 1 models\n",
      "gbm ([0.741609474755982, 0.7571157436433316, 0.47798742120368803, 0.5486721748949358], [0.6313462036244843], [0.7540226447147446])\n",
      "opening existing file results/gbm.csv\n",
      "12 out of 79 files\n",
      "Reading file train60_30_0.csv\n",
      "class frequencies [6436, 7321, 1134, 1144]\n",
      "Defined 1 models\n",
      "Defined 1 models\n",
      "Defined 1 models\n",
      "Defined 1 models\n",
      "Defined 1 models\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/elizabeth/education/chair_sensor/ml_project/venv/lib/python3.5/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defined 1 models\n",
      "Defined 1 models\n",
      "Defined 1 models\n",
      "Defined 1 models\n",
      "gbm ([0.7357496169439229, 0.7662578414053552, 0.5267244500084882, 0.540947033454827], [0.6424197354531482], [0.7533287851191499])\n",
      "opening existing file results/gbm.csv\n",
      "13 out of 79 files\n",
      "Reading file train10_5_4.csv\n",
      "class frequencies [28977, 32995, 5036, 5136]\n",
      "Defined 1 models\n",
      "Defined 1 models\n",
      "Defined 1 models\n",
      "Defined 1 models\n",
      "Defined 1 models\n",
      "Defined 1 models\n",
      "Defined 1 models\n",
      "Defined 1 models\n",
      "Defined 1 models\n",
      "gbm ([0.7175392001779284, 0.7477625940878418, 0.5117900671981827, 0.5148219582708807], [0.6229784549337084], [0.7365490768676352])\n",
      "opening existing file results/gbm.csv\n",
      "14 out of 79 files\n",
      "Reading file train30_15_8.csv\n",
      "class frequencies [11825, 13460, 2052, 2107]\n",
      "Defined 1 models\n",
      "Defined 1 models\n",
      "Defined 1 models\n",
      "Defined 1 models\n",
      "Defined 1 models\n",
      "Defined 1 models\n",
      "Defined 1 models\n",
      "Defined 1 models\n",
      "Defined 1 models\n",
      "gbm ([0.7407272261222687, 0.761713481324882, 0.5364367981957693, 0.5607979731568556], [0.649918869699944], [0.7564548856047443])\n",
      "opening existing file results/gbm.csv\n",
      "15 out of 79 files\n",
      "Reading file train60_30_15.csv\n",
      "class frequencies [12875, 14649, 2249, 2292]\n",
      "Defined 1 models\n",
      "Defined 1 models\n",
      "Defined 1 models\n",
      "Defined 1 models\n",
      "Defined 1 models\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/elizabeth/education/chair_sensor/ml_project/venv/lib/python3.5/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defined 1 models\n",
      "Defined 1 models\n",
      "Defined 1 models\n",
      "Defined 1 models\n",
      "gbm ([0.7470034557777154, 0.7745156607128826, 0.5533002693227109, 0.5603852144101666], [0.6588011500558689], [0.7630291336758352])\n",
      "opening existing file results/gbm.csv\n",
      "16 out of 79 files\n",
      "Reading file train60_120_60.csv\n",
      "class frequencies [3216, 3659, 567, 565]\n",
      "Defined 1 models\n",
      "Defined 1 models\n",
      "Defined 1 models\n",
      "Defined 1 models\n",
      "Defined 1 models\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/elizabeth/education/chair_sensor/ml_project/venv/lib/python3.5/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defined 1 models\n",
      "Defined 1 models\n",
      "Defined 1 models\n",
      "Defined 1 models\n",
      "gbm ([0.7392663276786681, 0.7608900966154688, 0.4999442464668235, 0.5498102783074068], [0.6374777372670918], [0.756494643796961])\n",
      "opening existing file results/gbm.csv\n",
      "17 out of 79 files\n",
      "Reading file train50_25_19.csv\n",
      "class frequencies [24157, 27482, 4176, 4300]\n",
      "Defined 1 models\n",
      "Defined 1 models\n",
      "Defined 1 models\n",
      "Defined 1 models\n",
      "Defined 1 models\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/elizabeth/education/chair_sensor/ml_project/venv/lib/python3.5/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defined 1 models\n",
      "Defined 1 models\n",
      "Defined 1 models\n",
      "Defined 1 models\n",
      "gbm ([0.743166688229345, 0.7632004017572542, 0.5698387453036295, 0.5917674090748024], [0.6669933110912578], [0.7632708475236756])\n",
      "opening existing file results/gbm.csv\n",
      "18 out of 79 files\n",
      "Reading file train5_8_0.csv\n",
      "class frequencies [1804, 2061, 323, 320]\n",
      "Defined 1 models\n",
      "Defined 1 models\n",
      "Defined 1 models\n",
      "Defined 1 models\n",
      "Defined 1 models\n",
      "Defined 1 models\n",
      "Defined 1 models\n",
      "Defined 1 models\n",
      "Defined 1 models\n",
      "gbm ([0.7123238838095518, 0.7318561481779734, 0.4724678617810139, 0.5335682773517652], [0.6125540427800761], [0.7281816112048668])\n",
      "opening existing file results/gbm.csv\n",
      "19 out of 79 files\n",
      "Reading file train5_5_1.csv\n",
      "class frequencies [3631, 4124, 621, 642]\n",
      "Defined 1 models\n",
      "Defined 1 models\n",
      "Defined 1 models\n",
      "Defined 1 models\n",
      "Defined 1 models\n",
      "Defined 1 models\n",
      "Defined 1 models\n",
      "Defined 1 models\n",
      "Defined 1 models\n",
      "gbm ([0.7014610291918767, 0.7301502048431945, 0.4332206523214656, 0.4979751484212785], [0.5907017586944538], [0.7199369611390029])\n",
      "opening existing file results/gbm.csv\n",
      "20 out of 79 files\n",
      "Reading file train50_100_0.csv\n",
      "class frequencies [1450, 1639, 263, 252]\n",
      "Defined 1 models\n",
      "Defined 1 models\n",
      "Defined 1 models\n",
      "Defined 1 models\n",
      "Defined 1 models\n",
      "Defined 1 models\n",
      "Defined 1 models\n",
      "Defined 1 models\n",
      "Defined 1 models\n",
      "gbm ([0.7367079496136354, 0.7533891989361138, 0.49877106206654254, 0.5011997129451122], [0.622516980890351], [0.7454973262458687])\n",
      "opening existing file results/gbm.csv\n",
      "21 out of 79 files\n",
      "Reading file train10_15_8.csv\n",
      "class frequencies [4143, 4712, 720, 723]\n",
      "Defined 1 models\n",
      "Defined 1 models\n",
      "Defined 1 models\n",
      "Defined 1 models\n",
      "Defined 1 models\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/elizabeth/education/chair_sensor/ml_project/venv/lib/python3.5/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defined 1 models\n",
      "Defined 1 models\n",
      "Defined 1 models\n",
      "Defined 1 models\n",
      "gbm ([0.7169370271079719, 0.7457881058342117, 0.48847876076205565, 0.5569644631935042], [0.6270420892244358], [0.7412480805564357])\n",
      "opening existing file results/gbm.csv\n",
      "22 out of 79 files\n",
      "Reading file train50_50_13.csv\n",
      "class frequencies [3908, 4453, 679, 705]\n",
      "Defined 1 models\n",
      "Defined 1 models\n",
      "Defined 1 models\n",
      "Defined 1 models\n",
      "Defined 1 models\n",
      "Defined 1 models\n",
      "Defined 1 models\n",
      "Defined 1 models\n",
      "Defined 1 models\n",
      "gbm ([0.7479940747507836, 0.756933576884499, 0.5082539814669118, 0.521370895721842], [0.6336381322060092], [0.755224499132357])\n",
      "opening existing file results/gbm.csv\n",
      "23 out of 79 files\n",
      "Reading file train50_50_25.csv\n",
      "class frequencies [5804, 6591, 993, 1034]\n",
      "Defined 1 models\n",
      "Defined 1 models\n",
      "Defined 1 models\n",
      "Defined 1 models\n",
      "Defined 1 models\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/elizabeth/education/chair_sensor/ml_project/venv/lib/python3.5/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defined 1 models\n",
      "Defined 1 models\n",
      "Defined 1 models\n",
      "Defined 1 models\n",
      "gbm ([0.7363625423132579, 0.7529430222399554, 0.5222231576636909, 0.5451520828895848], [0.6391702012766224], [0.7537895420799363])\n",
      "opening existing file results/gbm.csv\n",
      "24 out of 79 files\n",
      "Reading file train5_8_2.csv\n",
      "class frequencies [2406, 2742, 422, 439]\n",
      "Defined 1 models\n",
      "Defined 1 models\n",
      "Defined 1 models\n",
      "Defined 1 models\n",
      "Defined 1 models\n",
      "Defined 1 models\n",
      "Defined 1 models\n",
      "Defined 1 models\n",
      "Defined 1 models\n",
      "gbm ([0.7197569272831474, 0.725908955769777, 0.519565941913908, 0.5300407429594404], [0.6238181419815682], [0.7329204306163414])\n",
      "opening existing file results/gbm.csv\n",
      "25 out of 79 files\n",
      "Reading file train50_75_38.csv\n",
      "class frequencies [3911, 4451, 689, 689]\n",
      "Defined 1 models\n",
      "Defined 1 models\n",
      "Defined 1 models\n",
      "Defined 1 models\n",
      "Defined 1 models\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/elizabeth/education/chair_sensor/ml_project/venv/lib/python3.5/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defined 1 models\n",
      "Defined 1 models\n",
      "Defined 1 models\n",
      "Defined 1 models\n",
      "gbm ([0.7336796713590041, 0.7531566570587429, 0.5075081660329156, 0.5296083217520372], [0.6309882040506749], [0.7539007242849881])\n",
      "opening existing file results/gbm.csv\n",
      "26 out of 79 files\n",
      "Reading file train60_120_30.csv\n",
      "class frequencies [2151, 2433, 376, 380]\n",
      "Defined 1 models\n",
      "Defined 1 models\n",
      "Defined 1 models\n",
      "Defined 1 models\n",
      "Defined 1 models\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/elizabeth/education/chair_sensor/ml_project/venv/lib/python3.5/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defined 1 models\n",
      "Defined 1 models\n",
      "Defined 1 models\n",
      "Defined 1 models\n",
      "gbm ([0.7555834784053789, 0.7662160756325975, 0.4793196263574953, 0.5386984041538073], [0.6349543961373197], [0.7611667612290062])\n",
      "opening existing file results/gbm.csv\n",
      "27 out of 79 files\n",
      "Reading file train5_10_5.csv\n",
      "class frequencies [2894, 3288, 521, 503]\n",
      "Defined 1 models\n",
      "Defined 1 models\n",
      "Defined 1 models\n",
      "Defined 1 models\n",
      "Defined 1 models\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/elizabeth/education/chair_sensor/ml_project/venv/lib/python3.5/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defined 1 models\n",
      "Defined 1 models\n",
      "Defined 1 models\n",
      "Defined 1 models\n",
      "gbm ([0.7091575361945724, 0.7309185745403539, 0.5258940218851496, 0.49413484424960885], [0.6150262442174211], [0.7302580486570088])\n",
      "opening existing file results/gbm.csv\n",
      "28 out of 79 files\n",
      "Reading file train10_10_3.csv\n",
      "class frequencies [4130, 4709, 731, 733]\n",
      "Defined 1 models\n",
      "Defined 1 models\n",
      "Defined 1 models\n",
      "Defined 1 models\n",
      "Defined 1 models\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/elizabeth/education/chair_sensor/ml_project/venv/lib/python3.5/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defined 1 models\n",
      "Defined 1 models\n",
      "Defined 1 models\n",
      "Defined 1 models\n",
      "gbm ([0.7150464410551693, 0.7464240040139853, 0.4837244404790322, 0.4884231808581964], [0.6084045166015959], [0.7348485832880676])\n",
      "opening existing file results/gbm.csv\n",
      "29 out of 79 files\n",
      "Reading file train5_3_1.csv\n",
      "class frequencies [7262, 8260, 1252, 1264]\n",
      "Defined 1 models\n",
      "Defined 1 models\n",
      "Defined 1 models\n",
      "Defined 1 models\n",
      "Defined 1 models\n",
      "Defined 1 models\n",
      "Defined 1 models\n",
      "Defined 1 models\n",
      "Defined 1 models\n",
      "gbm ([0.6944393104458347, 0.7342030804687678, 0.4535918094857444, 0.4146617830176463], [0.5742239958544982], [0.7117241711587025])\n",
      "opening existing file results/gbm.csv\n",
      "30 out of 79 files\n",
      "Reading file train30_30_0.csv\n",
      "class frequencies [2770, 3134, 484, 482]\n",
      "Defined 1 models\n",
      "Defined 1 models\n",
      "Defined 1 models\n",
      "Defined 1 models\n",
      "Defined 1 models\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/elizabeth/education/chair_sensor/ml_project/venv/lib/python3.5/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defined 1 models\n",
      "Defined 1 models\n",
      "Defined 1 models\n",
      "Defined 1 models\n",
      "gbm ([0.74152265613701, 0.7597408426035424, 0.5065525467552161, 0.5932370136101088], [0.6502632647764693], [0.7559842006468565])\n",
      "opening existing file results/gbm.csv\n",
      "31 out of 79 files\n",
      "Reading file train50_50_38.csv\n",
      "class frequencies [12080, 13726, 2087, 2148]\n",
      "Defined 1 models\n",
      "Defined 1 models\n",
      "Defined 1 models\n",
      "Defined 1 models\n",
      "Defined 1 models\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/elizabeth/education/chair_sensor/ml_project/venv/lib/python3.5/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defined 1 models\n",
      "Defined 1 models\n",
      "Defined 1 models\n",
      "Defined 1 models\n",
      "gbm ([0.7382944581437194, 0.7605561297328263, 0.5452207976775927, 0.5594910708049866], [0.6508906140897812], [0.7604815678050766])\n",
      "opening existing file results/gbm.csv\n",
      "32 out of 79 files\n",
      "Reading file train60_90_23.csv\n",
      "class frequencies [2877, 3283, 512, 503]\n",
      "Defined 1 models\n",
      "Defined 1 models\n",
      "Defined 1 models\n",
      "Defined 1 models\n",
      "Defined 1 models\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/elizabeth/education/chair_sensor/ml_project/venv/lib/python3.5/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defined 1 models\n",
      "Defined 1 models\n",
      "Defined 1 models\n",
      "Defined 1 models\n",
      "gbm ([0.7404550884887664, 0.7515981811387179, 0.4902707825170315, 0.5664327447240585], [0.6371891992171437], [0.7540676926750716])\n",
      "opening existing file results/gbm.csv\n",
      "33 out of 79 files\n",
      "Reading file train5_5_3.csv\n",
      "class frequencies [7262, 8251, 1252, 1264]\n",
      "Defined 1 models\n",
      "Defined 1 models\n",
      "Defined 1 models\n",
      "Defined 1 models\n",
      "Defined 1 models\n",
      "Defined 1 models\n",
      "Defined 1 models\n",
      "Defined 1 models\n",
      "Defined 1 models\n",
      "gbm ([0.7097680566067307, 0.7240593176100852, 0.47214547169080073, 0.4795645374910371], [0.5963843458496635], [0.721902661803581])\n",
      "opening existing file results/gbm.csv\n",
      "34 out of 79 files\n",
      "Reading file train5_8_6.csv\n",
      "class frequencies [7232, 8222, 1272, 1292]\n",
      "Defined 1 models\n",
      "Defined 1 models\n",
      "Defined 1 models\n",
      "Defined 1 models\n",
      "Defined 1 models\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/elizabeth/education/chair_sensor/ml_project/venv/lib/python3.5/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defined 1 models\n",
      "Defined 1 models\n",
      "Defined 1 models\n",
      "Defined 1 models\n",
      "gbm ([0.7177303297513823, 0.7286318232755927, 0.5060933355982475, 0.5383873935919423], [0.6227107205542911], [0.734878758565587])\n",
      "opening existing file results/gbm.csv\n",
      "35 out of 79 files\n",
      "Reading file train10_20_15.csv\n",
      "class frequencies [5813, 6583, 993, 1017]\n",
      "Defined 1 models\n",
      "Defined 1 models\n",
      "Defined 1 models\n",
      "Defined 1 models\n",
      "Defined 1 models\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/elizabeth/education/chair_sensor/ml_project/venv/lib/python3.5/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defined 1 models\n",
      "Defined 1 models\n",
      "Defined 1 models\n",
      "Defined 1 models\n",
      "gbm ([0.7207531473138337, 0.7497643463123898, 0.5175837319168086, 0.5375919001836029], [0.6314232814316587], [0.7475141309225045])\n",
      "opening existing file results/gbm.csv\n",
      "36 out of 79 files\n",
      "Reading file train50_100_25.csv\n",
      "class frequencies [1939, 2191, 322, 350]\n",
      "Defined 1 models\n",
      "Defined 1 models\n",
      "Defined 1 models\n",
      "Defined 1 models\n",
      "Defined 1 models\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/elizabeth/education/chair_sensor/ml_project/venv/lib/python3.5/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defined 1 models\n",
      "Defined 1 models\n",
      "Defined 1 models\n",
      "Defined 1 models\n",
      "gbm ([0.747353593473301, 0.7600791621242886, 0.5217083726762347, 0.550872674896185], [0.6450034507925023], [0.7599933687015772])\n",
      "opening existing file results/gbm.csv\n",
      "37 out of 79 files\n",
      "Reading file train30_60_45.csv\n",
      "class frequencies [5517, 6255, 969, 974]\n",
      "Defined 1 models\n",
      "Defined 1 models\n",
      "Defined 1 models\n",
      "Defined 1 models\n",
      "Defined 1 models\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/elizabeth/education/chair_sensor/ml_project/venv/lib/python3.5/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defined 1 models\n",
      "Defined 1 models\n",
      "Defined 1 models\n",
      "Defined 1 models\n",
      "gbm ([0.7568147776889984, 0.770576998200361, 0.5262294799179998, 0.5889347201012999], [0.6606389939771647], [0.769224739470794])\n",
      "opening existing file results/gbm.csv\n",
      "38 out of 79 files\n",
      "Reading file train50_75_56.csv\n",
      "class frequencies [7632, 8668, 1322, 1342]\n",
      "Defined 1 models\n",
      "Defined 1 models\n",
      "Defined 1 models\n",
      "Defined 1 models\n",
      "Defined 1 models\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/elizabeth/education/chair_sensor/ml_project/venv/lib/python3.5/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defined 1 models\n",
      "Defined 1 models\n",
      "Defined 1 models\n",
      "Defined 1 models\n",
      "gbm ([0.7520232412546531, 0.7744489355404353, 0.5684979401982759, 0.5615506875858666], [0.6641302011448077], [0.7712043911091829])\n",
      "opening existing file results/gbm.csv\n",
      "39 out of 79 files\n",
      "Reading file train5_8_4.csv\n",
      "class frequencies [3615, 4113, 645, 637]\n",
      "Defined 1 models\n",
      "Defined 1 models\n",
      "Defined 1 models\n",
      "Defined 1 models\n",
      "Defined 1 models\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/elizabeth/education/chair_sensor/ml_project/venv/lib/python3.5/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defined 1 models\n",
      "Defined 1 models\n",
      "Defined 1 models\n",
      "Defined 1 models\n",
      "gbm ([0.7101746021688045, 0.7195456005926437, 0.5079670093017778, 0.5207477074855947], [0.614608729887205], [0.7297240725583076])\n",
      "opening existing file results/gbm.csv\n",
      "40 out of 79 files\n",
      "Reading file train60_60_30.csv\n",
      "class frequencies [6436, 7312, 1134, 1144]\n",
      "Defined 1 models\n",
      "Defined 1 models\n",
      "Defined 1 models\n",
      "Defined 1 models\n",
      "Defined 1 models\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/elizabeth/education/chair_sensor/ml_project/venv/lib/python3.5/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defined 1 models\n",
      "Defined 1 models\n",
      "Defined 1 models\n",
      "Defined 1 models\n",
      "gbm ([0.738075971936053, 0.7545111495812145, 0.5288982762668147, 0.5975924246109174], [0.6547694555987499], [0.7563033390325895])\n",
      "opening existing file results/gbm.csv\n"
     ]
    }
   ],
   "source": [
    "from os import listdir\n",
    "from os import path\n",
    "import re\n",
    "import csv\n",
    "\n",
    "source = '../data/processed/sklearn'\n",
    "dest = 'results'\n",
    "i = 1\n",
    "\n",
    "done = ['30_15_4', '10_5_1', '5_3_2', '60_30_8', '60_90_0', '5_5_4', '30_45_23', '5_5_0', '30_30_8', '60_90_68',\n",
    "        '50_100_75', '30_30_15', '60_120_90', '10_10_8', '10_20_0', '30_15_0', '60_30_23',\n",
    "        '50_25_0', '50_25_6', '30_45_0', '5_10_8', '30_15_11', '30_60_30', '10_5_0', '60_60_15',\n",
    "        '10_10_0', '50_100_50', '30_60_15', '60_60_0', '10_20_5', '5_10_0', '50_75_19', '10_15_11',\n",
    "        '5_3_0', '30_45_11', '60_120_0', '10_20_10', '5_10_3', '10_15_0']\n",
    "\n",
    "for name in listdir(source):\n",
    "    filename = source + '/' + name\n",
    "    if not name.endswith('csv') or not name.startswith('train'):\n",
    "        continue\n",
    "    pattern = 'train' + '[0-9]*[0-9]_[0-9]*[0-9]_[0-9]*[0-9]' + '.csv'\n",
    "    match = re.search(pattern, name)\n",
    "    if not match:\n",
    "        continue\n",
    "        \n",
    "    print(i, 'out of 79 files')\n",
    "    print('Reading file', name)\n",
    "\n",
    "    train_df = pd.read_csv(filename)\n",
    "\n",
    "    X_train = train_df.drop(['state', 'name'], axis=1)\n",
    "    y_train = pd.DataFrame(train_df['state'])\n",
    "    groups = train_df['name']\n",
    "    \n",
    "    # counting the number of samples per class\n",
    "    freq = [0,0,0,0]\n",
    "    for val in y_train['state']:\n",
    "        freq[val] += 1\n",
    "    \n",
    "    print('class frequencies', freq)\n",
    "    \n",
    "    results = evaluate_models(X_train, y_train, models, groups)\n",
    "        \n",
    "    # save results and freq into file per model\n",
    "    combi = re.search('train(.+?).csv', name)\n",
    "    if combi:\n",
    "        combi = combi.group(1)\n",
    "    if combi in done:\n",
    "        continue\n",
    "        \n",
    "#     with open(dest + '/combis', 'a+') as outFile:\n",
    "#         row = [combi]\n",
    "#         row.extend(freq)\n",
    "#         writer = csv.writer(outFile)\n",
    "#         writer.writerow(row)\n",
    "    \n",
    "    header = ['comb', 'f1-0', 'f1-1', 'f1-2', 'f1-3', 'macro f1', 'micro f1']\n",
    "\n",
    "    for key in results:\n",
    "        row = [combi]\n",
    "        for e in results[key]:\n",
    "            row.extend(e)\n",
    "        \n",
    "        outFilename = dest + '/' + key + '.csv'\n",
    "        if not path.isfile(outFilename):\n",
    "            print('creating new file', outFilename)\n",
    "            with open(outFilename, 'w') as outFile:\n",
    "                writer = csv.writer(outFile)\n",
    "                writer.writerow(header)\n",
    "                writer.writerow(row)\n",
    "        else:\n",
    "#         row = [combi]\n",
    "#         row.extend(freq)\n",
    "#         writer = csv.writer(outFile)\n",
    "#         writer.writerow(row)\n",
    "            print('opening existing file', outFilename)\n",
    "            with open(outFilename, 'a+') as outFile:\n",
    "                writer = csv.writer(outFile)\n",
    "                writer.writerow(row)\n",
    "    i += 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# experiments keras neural network models\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from numpy import dstack\n",
    "import numpy as np\n",
    "from pandas import read_csv\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from keras.utils import to_categorical\n",
    "from keras.layers import Bidirectional\n",
    "\n",
    "from matplotlib import pyplot\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load a single file as a numpy array\n",
    "def load_file(filepath):\n",
    "    dataframe = read_csv(filepath, header=None)\n",
    "    return dataframe.values\n",
    "\n",
    "# load a list of files and return as a 3d numpy array\n",
    "def load_group(filenames, prefix=''):\n",
    "    loaded = list()\n",
    "    for name in filenames:\n",
    "        data = load_file(prefix + name)\n",
    "        loaded.append(data)\n",
    "    # stack group so that features are the 3rd dimension\n",
    "    print('loaded', len(loaded[0]))\n",
    "#     print('loaded', loaded)\n",
    "    loaded = dstack(loaded)\n",
    "    print('stacked', loaded.shape)\n",
    "#     print('stacked', loaded)\n",
    "    return loaded\n",
    "\n",
    "# load a dataset group, such as train or test\n",
    "def load_dataset_group(group, comb, prefix=''):\n",
    "#     filepath = prefix + group + '/keras/'\n",
    "    prefix = prefix + group + '/'\n",
    "    # load all 9 files as a single array\n",
    "    filenames = list()\n",
    "    # total acceleration\n",
    "    filenames += ['total_acc_x_'+group+'_'+comb+'.csv', 'total_acc_y_'+group+'_'+comb+'.csv', 'total_acc_z_'+group+'_'+comb+'.csv']\n",
    "    # load input data\n",
    "    X = load_group(filenames, prefix)\n",
    "    # load class output\n",
    "    y = load_file(prefix + 'state_'+group+'_'+comb+'.csv')\n",
    "    path = prefix + 'subjects_' + group + '_' +comb+'.csv'\n",
    "    print(path)\n",
    "    subjects = read_csv(path, header=None)\n",
    "    print('done')\n",
    "    return X, y, subjects\n",
    "\n",
    "# load the dataset, returns train and test X and y elements\n",
    "def load_dataset(comb,  prefix=''):\n",
    "    # load all train\n",
    "    trainX, trainy, subjects = load_dataset_group('train', comb, prefix)\n",
    "    print(trainX.shape, trainy.shape)\n",
    "    # load all test\n",
    "    testX, testy, subjects = load_dataset_group('test', comb, prefix)\n",
    "#     print(testX.shape, testy.shape)\n",
    "    # zero-offset class values\n",
    "#     trainy = trainy - 1\n",
    "#     testy = testy - 1\n",
    "    # one hot encode y\n",
    "#     trainy = to_categorical(trainy)\n",
    "#     y_true = testy\n",
    "#     testy = to_categorical(testy)\n",
    "#     print(trainX.shape, trainy.shape)\n",
    "    return trainX, trainy, testX, testy, subjects\n",
    "\n",
    "# summarize scores\n",
    "def summarize_results(scores):\n",
    "    print(scores)\n",
    "    m, s = mean(scores), std(scores)\n",
    "    print('Accuracy: %.3f%% (+/-%.3f)' % (m, s))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define two neural networks: MLP and LSTM\n",
    "\n",
    "def define_nns(n_timesteps, n_features, n_outputs, models=dict()):    \n",
    "    mlp = Sequential()\n",
    "    mlp.add(Dense(n_features, input_shape=(n_timesteps,n_features), activation='relu'))\n",
    "#     mlp.add(Dropout(0.5))\n",
    "#     mlp.add(Dense(100, activation='relu'))\n",
    "    mlp.add(Flatten())\n",
    "    mlp.add(Dense(4, activation='softmax'))\n",
    "    mlp.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['categorical_accuracy'])\n",
    "    models['fnn'] = mlp\n",
    "    \n",
    "    lstm = Sequential()\n",
    "    lstm.add(LSTM(n_features, input_shape=(n_timesteps,n_features), activation='relu'))\n",
    "#     lstm.add(Dropout(0.5))\n",
    "#     lstm.add(Dense(100, activation='relu'))\n",
    "    lstm.add(Dense(n_outputs, activation='softmax'))\n",
    "    lstm.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['categorical_accuracy'])\n",
    "    models['lstm'] = lstm\n",
    "    \n",
    "    return models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import LeaveOneGroupOut\n",
    "\n",
    "def evaluate_model(trainX, trainy, testX, testy, y_true, model):\n",
    "    verbose, epochs = 1, 10\n",
    "#     trainy, testy = trainy[:,0], testy[:,0]\n",
    "    # fit the model\n",
    "    model.fit(trainX, trainy, epochs=epochs, verbose=verbose)\n",
    "#     # make predictions\n",
    "    yhat = model.predict_classes(testX)\n",
    "#     print('yhat', yhat)\n",
    "    f1_macro = f1_score(y_true, yhat, average='macro')\n",
    "    f1_micro = f1_score(y_true, yhat, average='micro')\n",
    "    f1 = f1_score(y_true, yhat, average=None)\n",
    "    _, accuracy = model.evaluate(testX, testy, verbose=verbose)\n",
    "\n",
    "#     _, accuracy = model.evaluate(testX, y_true, batch_size=batch_size, verbose=verbose)\n",
    "#     print('accuracy:', accuracy)\n",
    "#     print(classification_report(testy, yhat))\n",
    "#     print(confusion_matrix(testy, yhat))\n",
    "#     print(accuracy)\n",
    "    return f1, f1_macro, f1_micro\n",
    "#     return 0,0,0\n",
    "\n",
    "def run_logo(X_all, y_all, groups, X_dummy):\n",
    "    print(len(X_all))\n",
    "    print(len(y_all))\n",
    "    print(len(groups))\n",
    "    logo = LeaveOneGroupOut()\n",
    "    group = 0\n",
    "    \n",
    "    f1s = []\n",
    "    f1_macros = []\n",
    "    f1_micros = []\n",
    "\n",
    "    results = []\n",
    "    for train_indices, test_indices in logo.split(X_dummy, groups=groups[0:len(X_all)]):\n",
    "        group += 1\n",
    "        \n",
    "        X_train, X_test = X_all[train_indices], X_all[test_indices]\n",
    "        y_train, y_test = y_all[train_indices], y_all[test_indices]\n",
    "        y_train = to_categorical(y_train)\n",
    "        y_true = y_test\n",
    "        y_test = to_categorical(y_test)\n",
    "\n",
    "        key = 'lstm'\n",
    "#         n_timesteps, n_features, n_outputs = trainX.shape[1], trainX.shape[2], to_categorical(trainy).shape[1]\n",
    "        models = define_nns(n_timesteps=X_train.shape[1], n_features=X_train.shape[2], n_outputs=y_train.shape[1])\n",
    "        f1, f1_macro, f1_micro = evaluate_model(X_train, y_train, X_test, y_test, y_true, models[key])\n",
    "#         accuracy = evaluate_model(X_train, y_train, X_test, y_test, y_true, models['mlp'])\n",
    "        f1s.append(f1)\n",
    "        f1_macros.append(f1_macro)\n",
    "        f1_micros.append(f1_micro)\n",
    "#         print(\"Group {0} f1-scores: {1}\".format(group, f1))\n",
    "# #         print(f1_macros)\n",
    "# #         print(f1_micros)\n",
    "        \n",
    "# #     return np.average(f1s, axis=0).tolist()\n",
    "#         verbose, epochs, batch_size = 1, 100, 10\n",
    "#         print('prefit')\n",
    "#         clf.fit(X_train, y_train, epochs=epochs, batch_size=batch_size, verbose=verbose)\n",
    "#         clf.fit(X_train, y_train, epochs=epochs, batch_size=batch_size, verbose=verbose)\n",
    "#         print('fit')\n",
    "#         _, accuracy = clf.evaluate(X_test, y_test, batch_size=batch_size, verbose=verbose)\n",
    "# #         _, accuracy = clf.evaluate(X_test, y_test, batch_size=batch_size, verbose=verbose)\n",
    "#         print('accuracy', accuracy)\n",
    "#         results.append(accuracy)\n",
    "#     return np.average(results)\n",
    "    return {key: (np.average(f1s, axis=0).tolist(), [np.average(f1_macros).tolist()], [np.average(f1_micros).tolist()])}\n",
    "\n",
    "\n",
    "# result = run_logo(model, trainX, trainy, subjects.iloc[:,0], X_dummy)\n",
    "# print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded 32072\n",
      "stacked (32072, 60, 3)\n",
      "../data/processed/train/keras/subjects_train_60_60_45.csv\n",
      "done\n",
      "(32072, 60, 3) (32072, 1)\n",
      "32072\n",
      "32072\n",
      "32072\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0716 15:55:02.399233 139887819667200 deprecation.py:323] From /home/elizabeth/education/chair_sensor/ml_project/venv/lib/python3.5/site-packages/tensorflow_core/python/ops/math_grad.py:1251: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 26651 samples\n",
      "Epoch 1/10\n",
      "26651/26651 [==============================] - 10s 370us/sample - loss: 1.2464 - categorical_accuracy: 0.4145\n",
      "Epoch 2/10\n",
      "26651/26651 [==============================] - 9s 354us/sample - loss: 1.1201 - categorical_accuracy: 0.4433\n",
      "Epoch 3/10\n",
      "26651/26651 [==============================] - 9s 354us/sample - loss: 1.1013 - categorical_accuracy: 0.4444\n",
      "Epoch 4/10\n",
      "26651/26651 [==============================] - 9s 353us/sample - loss: 1.0776 - categorical_accuracy: 0.5473\n",
      "Epoch 5/10\n",
      "26651/26651 [==============================] - 9s 352us/sample - loss: 1.0304 - categorical_accuracy: 0.6306\n",
      "Epoch 6/10\n",
      "26651/26651 [==============================] - 10s 367us/sample - loss: 0.9871 - categorical_accuracy: 0.6562\n",
      "Epoch 7/10\n",
      "26651/26651 [==============================] - 10s 373us/sample - loss: 0.9652 - categorical_accuracy: 0.6523\n",
      "Epoch 8/10\n",
      "26651/26651 [==============================] - 10s 371us/sample - loss: 0.9489 - categorical_accuracy: 0.6556\n",
      "Epoch 9/10\n",
      "26651/26651 [==============================] - 10s 373us/sample - loss: 0.9396 - categorical_accuracy: 0.6565\n",
      "Epoch 10/10\n",
      "26651/26651 [==============================] - 10s 373us/sample - loss: 0.9333 - categorical_accuracy: 0.6560\n",
      "  32/5421 [..............................] - ETA: 16s - loss: 0.3210 - categorical_accuracy: 1.0000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/elizabeth/education/chair_sensor/ml_project/venv/lib/python3.5/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5421/5421 [==============================] - 1s 224us/sample - loss: 0.7845 - categorical_accuracy: 0.7761\n",
      "Train on 28587 samples\n",
      "Epoch 1/10\n",
      "28587/28587 [==============================] - 11s 387us/sample - loss: 1.1278 - categorical_accuracy: 0.4433\n",
      "Epoch 2/10\n",
      "28587/28587 [==============================] - 11s 369us/sample - loss: 1.0907 - categorical_accuracy: 0.4581\n",
      "Epoch 3/10\n",
      "28587/28587 [==============================] - 11s 370us/sample - loss: 1.0879 - categorical_accuracy: 0.4606\n",
      "Epoch 4/10\n",
      "28587/28587 [==============================] - 11s 368us/sample - loss: 1.0723 - categorical_accuracy: 0.5114\n",
      "Epoch 5/10\n",
      "28587/28587 [==============================] - 11s 369us/sample - loss: 0.9939 - categorical_accuracy: 0.6314\n",
      "Epoch 6/10\n",
      "28587/28587 [==============================] - 11s 370us/sample - loss: 0.9251 - categorical_accuracy: 0.6825\n",
      "Epoch 7/10\n",
      "28587/28587 [==============================] - 11s 369us/sample - loss: 0.9025 - categorical_accuracy: 0.6888\n",
      "Epoch 8/10\n",
      "28587/28587 [==============================] - 11s 371us/sample - loss: 0.8962 - categorical_accuracy: 0.6898\n",
      "Epoch 9/10\n",
      "28587/28587 [==============================] - 11s 373us/sample - loss: 0.8953 - categorical_accuracy: 0.6899\n",
      "Epoch 10/10\n",
      "28587/28587 [==============================] - 11s 373us/sample - loss: 0.8922 - categorical_accuracy: 0.6927\n",
      "3485/3485 [==============================] - 1s 241us/sample - loss: 1.1845 - categorical_accuracy: 0.4700\n",
      "Train on 29600 samples\n",
      "Epoch 1/10\n",
      "29600/29600 [==============================] - 12s 402us/sample - loss: 1.1495 - categorical_accuracy: 0.4637\n",
      "Epoch 2/10\n",
      "29600/29600 [==============================] - 11s 377us/sample - loss: 0.7867 - categorical_accuracy: 0.7314\n",
      "Epoch 3/10\n",
      "29600/29600 [==============================] - 11s 374us/sample - loss: 0.7128 - categorical_accuracy: 0.7670\n",
      "Epoch 4/10\n",
      "29600/29600 [==============================] - 11s 373us/sample - loss: 0.6998 - categorical_accuracy: 0.7685\n",
      "Epoch 5/10\n",
      "29600/29600 [==============================] - 11s 373us/sample - loss: 0.6930 - categorical_accuracy: 0.7691\n",
      "Epoch 6/10\n",
      "29600/29600 [==============================] - 11s 376us/sample - loss: 0.6879 - categorical_accuracy: 0.7706\n",
      "Epoch 7/10\n",
      "29600/29600 [==============================] - 11s 377us/sample - loss: 0.6843 - categorical_accuracy: 0.7720\n",
      "Epoch 8/10\n",
      "29600/29600 [==============================] - 11s 375us/sample - loss: 0.7008 - categorical_accuracy: 0.7626\n",
      "Epoch 9/10\n",
      "29600/29600 [==============================] - 11s 376us/sample - loss: 0.6861 - categorical_accuracy: 0.7688\n",
      "Epoch 10/10\n",
      "29600/29600 [==============================] - 11s 377us/sample - loss: 0.6817 - categorical_accuracy: 0.7712\n",
      "2472/2472 [==============================] - 1s 272us/sample - loss: 1.3688 - categorical_accuracy: 0.4175\n",
      "Train on 28052 samples\n",
      "Epoch 1/10\n",
      "28052/28052 [==============================] - 11s 400us/sample - loss: 1.2079 - categorical_accuracy: 0.4592\n",
      "Epoch 2/10\n",
      "28052/28052 [==============================] - 11s 384us/sample - loss: 1.0928 - categorical_accuracy: 0.4596\n",
      "Epoch 3/10\n",
      "28052/28052 [==============================] - 11s 382us/sample - loss: 1.0735 - categorical_accuracy: 0.4598\n",
      "Epoch 4/10\n",
      "28052/28052 [==============================] - 11s 382us/sample - loss: 1.0637 - categorical_accuracy: 0.4603\n",
      "Epoch 5/10\n",
      "28052/28052 [==============================] - 11s 382us/sample - loss: 1.0481 - categorical_accuracy: 0.4614\n",
      "Epoch 6/10\n",
      "28052/28052 [==============================] - 11s 384us/sample - loss: 1.0266 - categorical_accuracy: 0.4639\n",
      "Epoch 7/10\n",
      "28052/28052 [==============================] - 11s 385us/sample - loss: 1.0056 - categorical_accuracy: 0.4679\n",
      "Epoch 8/10\n",
      "28052/28052 [==============================] - 11s 383us/sample - loss: 0.9883 - categorical_accuracy: 0.4711\n",
      "Epoch 9/10\n",
      "28052/28052 [==============================] - 11s 385us/sample - loss: 0.9711 - categorical_accuracy: 0.5143\n",
      "Epoch 10/10\n",
      "28052/28052 [==============================] - 11s 383us/sample - loss: 0.9479 - categorical_accuracy: 0.5938\n",
      "4020/4020 [==============================] - 1s 240us/sample - loss: 0.9198 - categorical_accuracy: 0.7530\n",
      "Train on 28144 samples\n",
      "Epoch 1/10\n",
      "28144/28144 [==============================] - 12s 421us/sample - loss: 1.2217 - categorical_accuracy: 0.4514\n",
      "Epoch 2/10\n",
      "28144/28144 [==============================] - 11s 382us/sample - loss: 1.0696 - categorical_accuracy: 0.4838\n",
      "Epoch 3/10\n",
      "28144/28144 [==============================] - 11s 387us/sample - loss: 0.8901 - categorical_accuracy: 0.6952\n",
      "Epoch 4/10\n",
      "28144/28144 [==============================] - 11s 385us/sample - loss: 0.8403 - categorical_accuracy: 0.7035\n",
      "Epoch 5/10\n",
      "28144/28144 [==============================] - 11s 385us/sample - loss: 0.8275 - categorical_accuracy: 0.7042\n",
      "Epoch 6/10\n",
      "28144/28144 [==============================] - 11s 387us/sample - loss: 0.8222 - categorical_accuracy: 0.7042\n",
      "Epoch 7/10\n",
      "28144/28144 [==============================] - 11s 384us/sample - loss: 0.8152 - categorical_accuracy: 0.7064\n",
      "Epoch 8/10\n",
      "28144/28144 [==============================] - 11s 388us/sample - loss: 0.8092 - categorical_accuracy: 0.7054\n",
      "Epoch 9/10\n",
      "28144/28144 [==============================] - 11s 388us/sample - loss: 0.8005 - categorical_accuracy: 0.7072\n",
      "Epoch 10/10\n",
      "28144/28144 [==============================] - 11s 387us/sample - loss: 0.7879 - categorical_accuracy: 0.7081\n",
      "3928/3928 [==============================] - 1s 251us/sample - loss: 2.6771 - categorical_accuracy: 0.4692\n",
      "Train on 29411 samples\n",
      "Epoch 1/10\n",
      "29411/29411 [==============================] - 12s 402us/sample - loss: 1.2218 - categorical_accuracy: 0.4414\n",
      "Epoch 2/10\n",
      "29411/29411 [==============================] - 11s 387us/sample - loss: 1.1090 - categorical_accuracy: 0.4585\n",
      "Epoch 3/10\n",
      "29411/29411 [==============================] - 12s 392us/sample - loss: 1.0995 - categorical_accuracy: 0.4585\n",
      "Epoch 4/10\n",
      "29411/29411 [==============================] - 11s 390us/sample - loss: 1.0988 - categorical_accuracy: 0.4584\n",
      "Epoch 5/10\n",
      "29411/29411 [==============================] - 11s 385us/sample - loss: 1.0994 - categorical_accuracy: 0.4583\n",
      "Epoch 6/10\n",
      "29411/29411 [==============================] - 10s 337us/sample - loss: 1.0986 - categorical_accuracy: 0.4585\n",
      "Epoch 7/10\n",
      "29411/29411 [==============================] - 10s 337us/sample - loss: 1.0845 - categorical_accuracy: 0.4636\n",
      "Epoch 8/10\n",
      "29411/29411 [==============================] - 10s 338us/sample - loss: 0.8754 - categorical_accuracy: 0.6931\n",
      "Epoch 9/10\n",
      "29411/29411 [==============================] - 10s 337us/sample - loss: 0.8159 - categorical_accuracy: 0.7156\n",
      "Epoch 10/10\n",
      "29411/29411 [==============================] - 10s 337us/sample - loss: 0.7935 - categorical_accuracy: 0.7246\n",
      "2661/2661 [==============================] - 1s 248us/sample - loss: 0.6853 - categorical_accuracy: 0.7839\n",
      "Train on 28354 samples\n",
      "Epoch 1/10\n",
      "28354/28354 [==============================] - 10s 363us/sample - loss: 1.3333 - categorical_accuracy: 0.3900\n",
      "Epoch 2/10\n",
      "28354/28354 [==============================] - 10s 344us/sample - loss: 1.1083 - categorical_accuracy: 0.4628\n",
      "Epoch 3/10\n",
      "28354/28354 [==============================] - 9s 334us/sample - loss: 0.9215 - categorical_accuracy: 0.5946\n",
      "Epoch 4/10\n",
      "28354/28354 [==============================] - 10s 336us/sample - loss: 0.8975 - categorical_accuracy: 0.6019\n",
      "Epoch 5/10\n",
      "28354/28354 [==============================] - 10s 336us/sample - loss: 0.8672 - categorical_accuracy: 0.6323\n",
      "Epoch 6/10\n",
      "28354/28354 [==============================] - 10s 338us/sample - loss: 0.8567 - categorical_accuracy: 0.6511\n",
      "Epoch 7/10\n",
      "28354/28354 [==============================] - 10s 342us/sample - loss: 0.8772 - categorical_accuracy: 0.6190\n",
      "Epoch 8/10\n",
      "28354/28354 [==============================] - 10s 342us/sample - loss: 0.8379 - categorical_accuracy: 0.6714\n",
      "Epoch 9/10\n",
      "28354/28354 [==============================] - 10s 342us/sample - loss: 0.8357 - categorical_accuracy: 0.6737\n",
      "Epoch 10/10\n",
      "28354/28354 [==============================] - 10s 343us/sample - loss: 0.8186 - categorical_accuracy: 0.6946\n",
      "3718/3718 [==============================] - 1s 216us/sample - loss: 0.9453 - categorical_accuracy: 0.4554\n",
      "Train on 26705 samples\n",
      "Epoch 1/10\n",
      "26705/26705 [==============================] - 10s 369us/sample - loss: 1.1220 - categorical_accuracy: 0.4715\n",
      "Epoch 2/10\n",
      "26705/26705 [==============================] - 9s 350us/sample - loss: 1.0772 - categorical_accuracy: 0.5402\n",
      "Epoch 3/10\n",
      "26705/26705 [==============================] - 9s 350us/sample - loss: 1.0017 - categorical_accuracy: 0.6345\n",
      "Epoch 4/10\n",
      "26705/26705 [==============================] - 9s 349us/sample - loss: 0.9319 - categorical_accuracy: 0.6608\n",
      "Epoch 5/10\n",
      "26705/26705 [==============================] - 9s 350us/sample - loss: 0.8920 - categorical_accuracy: 0.6695\n",
      "Epoch 6/10\n",
      "26705/26705 [==============================] - 9s 351us/sample - loss: 0.8552 - categorical_accuracy: 0.6751\n",
      "Epoch 7/10\n",
      "26705/26705 [==============================] - 9s 352us/sample - loss: 0.8206 - categorical_accuracy: 0.6870\n",
      "Epoch 8/10\n",
      "26705/26705 [==============================] - 9s 350us/sample - loss: 0.7534 - categorical_accuracy: 0.7180\n",
      "Epoch 9/10\n",
      "26705/26705 [==============================] - 9s 350us/sample - loss: 0.7141 - categorical_accuracy: 0.7306\n",
      "Epoch 10/10\n",
      "26705/26705 [==============================] - 9s 350us/sample - loss: 0.6901 - categorical_accuracy: 0.7386\n",
      "5367/5367 [==============================] - 1s 201us/sample - loss: 0.6981 - categorical_accuracy: 0.7643\n",
      "Train on 31072 samples\n",
      "Epoch 1/10\n",
      "31072/31072 [==============================] - 11s 354us/sample - loss: 1.1950 - categorical_accuracy: 0.4069\n",
      "Epoch 2/10\n",
      "31072/31072 [==============================] - 11s 349us/sample - loss: 1.0984 - categorical_accuracy: 0.4721\n",
      "Epoch 3/10\n",
      "31072/31072 [==============================] - 11s 348us/sample - loss: 1.0869 - categorical_accuracy: 0.5330\n",
      "Epoch 4/10\n",
      "31072/31072 [==============================] - 11s 349us/sample - loss: 0.9670 - categorical_accuracy: 0.6450\n",
      "Epoch 5/10\n",
      "31072/31072 [==============================] - 11s 349us/sample - loss: 0.9090 - categorical_accuracy: 0.6679\n",
      "Epoch 6/10\n",
      "31072/31072 [==============================] - 10s 337us/sample - loss: 0.8969 - categorical_accuracy: 0.6717\n",
      "Epoch 7/10\n",
      "31072/31072 [==============================] - 10s 333us/sample - loss: 0.8906 - categorical_accuracy: 0.6705\n",
      "Epoch 8/10\n",
      "31072/31072 [==============================] - 10s 333us/sample - loss: 0.8874 - categorical_accuracy: 0.6721\n",
      "Epoch 9/10\n",
      "31072/31072 [==============================] - 10s 335us/sample - loss: 0.8837 - categorical_accuracy: 0.6717\n",
      "Epoch 10/10\n",
      "31072/31072 [==============================] - 10s 333us/sample - loss: 0.8797 - categorical_accuracy: 0.6731\n",
      "1000/1000 [==============================] - 0s 353us/sample - loss: 0.5108 - categorical_accuracy: 0.8800\n",
      "opening existing file results/lstm.csv\n",
      "loaded 10690\n",
      "stacked (10690, 90, 3)\n",
      "../data/processed/train/keras/subjects_train_60_90_45.csv\n",
      "done\n",
      "(10690, 90, 3) (10690, 1)\n",
      "10690\n",
      "10690\n",
      "10690\n",
      "Train on 8883 samples\n",
      "Epoch 1/10\n",
      "8883/8883 [==============================] - 5s 538us/sample - loss: 1.2578 - categorical_accuracy: 0.3671\n",
      "Epoch 2/10\n",
      "8883/8883 [==============================] - 5s 530us/sample - loss: 1.1231 - categorical_accuracy: 0.4314\n",
      "Epoch 3/10\n",
      "8883/8883 [==============================] - 5s 542us/sample - loss: 1.1089 - categorical_accuracy: 0.4431\n",
      "Epoch 4/10\n",
      "8883/8883 [==============================] - 5s 540us/sample - loss: 1.1069 - categorical_accuracy: 0.4431\n",
      "Epoch 5/10\n",
      "8883/8883 [==============================] - 5s 542us/sample - loss: 1.1061 - categorical_accuracy: 0.4465\n",
      "Epoch 6/10\n",
      "8883/8883 [==============================] - 5s 543us/sample - loss: 1.1062 - categorical_accuracy: 0.4432\n",
      "Epoch 7/10\n",
      "8883/8883 [==============================] - 5s 542us/sample - loss: 1.1058 - categorical_accuracy: 0.4447\n",
      "Epoch 8/10\n",
      "8883/8883 [==============================] - 5s 542us/sample - loss: 1.1055 - categorical_accuracy: 0.4479\n",
      "Epoch 9/10\n",
      "8883/8883 [==============================] - 5s 541us/sample - loss: 1.1047 - categorical_accuracy: 0.4455\n",
      "Epoch 10/10\n",
      "8883/8883 [==============================] - 5s 542us/sample - loss: 1.1041 - categorical_accuracy: 0.4536\n",
      "  32/1807 [..............................] - ETA: 5s - loss: 0.8889 - categorical_accuracy: 0.9688"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/elizabeth/education/chair_sensor/ml_project/venv/lib/python3.5/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1807/1807 [==============================] - 1s 362us/sample - loss: 1.0528 - categorical_accuracy: 0.5208\n",
      "Train on 9529 samples\n",
      "Epoch 1/10\n",
      "9529/9529 [==============================] - 5s 542us/sample - loss: 1.2183 - categorical_accuracy: 0.4125\n",
      "Epoch 2/10\n",
      "9529/9529 [==============================] - 5s 501us/sample - loss: 1.0993 - categorical_accuracy: 0.4570\n",
      "Epoch 3/10\n",
      "9529/9529 [==============================] - 5s 498us/sample - loss: 1.0916 - categorical_accuracy: 0.4569\n",
      "Epoch 4/10\n",
      "9529/9529 [==============================] - 5s 499us/sample - loss: 1.0889 - categorical_accuracy: 0.4573\n",
      "Epoch 5/10\n",
      "9529/9529 [==============================] - 5s 499us/sample - loss: 1.0840 - categorical_accuracy: 0.4885\n",
      "Epoch 6/10\n",
      "9529/9529 [==============================] - 5s 499us/sample - loss: 1.0892 - categorical_accuracy: 0.4758\n",
      "Epoch 7/10\n",
      "9529/9529 [==============================] - 5s 501us/sample - loss: 1.0909 - categorical_accuracy: 0.4765\n",
      "Epoch 8/10\n",
      "9529/9529 [==============================] - 5s 499us/sample - loss: 1.0882 - categorical_accuracy: 0.4569\n",
      "Epoch 9/10\n",
      "9529/9529 [==============================] - 5s 500us/sample - loss: 1.0866 - categorical_accuracy: 0.4604\n",
      "Epoch 10/10\n",
      "9529/9529 [==============================] - 5s 501us/sample - loss: 1.0799 - categorical_accuracy: 0.4815\n",
      "1161/1161 [==============================] - 1s 457us/sample - loss: 1.1379 - categorical_accuracy: 0.6830\n",
      "Train on 9866 samples\n",
      "Epoch 1/10\n",
      "9866/9866 [==============================] - 5s 536us/sample - loss: 1.3285 - categorical_accuracy: 0.3170\n",
      "Epoch 2/10\n",
      "9866/9866 [==============================] - 5s 501us/sample - loss: 1.1853 - categorical_accuracy: 0.4657\n",
      "Epoch 3/10\n",
      "9866/9866 [==============================] - 5s 502us/sample - loss: 1.1270 - categorical_accuracy: 0.4657\n",
      "Epoch 4/10\n",
      "9866/9866 [==============================] - 5s 509us/sample - loss: 1.0997 - categorical_accuracy: 0.4657\n",
      "Epoch 5/10\n",
      "9866/9866 [==============================] - 5s 499us/sample - loss: 1.0869 - categorical_accuracy: 0.4657\n",
      "Epoch 6/10\n",
      "9866/9866 [==============================] - 5s 500us/sample - loss: 1.0810 - categorical_accuracy: 0.4657\n",
      "Epoch 7/10\n",
      "9866/9866 [==============================] - 5s 500us/sample - loss: 1.0784 - categorical_accuracy: 0.4657\n",
      "Epoch 8/10\n",
      "9866/9866 [==============================] - 5s 503us/sample - loss: 1.0772 - categorical_accuracy: 0.4657\n",
      "Epoch 9/10\n",
      "9866/9866 [==============================] - 5s 500us/sample - loss: 1.0766 - categorical_accuracy: 0.4657\n",
      "Epoch 10/10\n",
      "9866/9866 [==============================] - 5s 500us/sample - loss: 1.0762 - categorical_accuracy: 0.4657\n",
      "824/824 [==============================] - 0s 482us/sample - loss: 1.3528 - categorical_accuracy: 0.3434\n",
      "Train on 9350 samples\n",
      "Epoch 1/10\n",
      "9350/9350 [==============================] - 5s 560us/sample - loss: 1.1711 - categorical_accuracy: 0.4559\n",
      "Epoch 2/10\n",
      "9350/9350 [==============================] - 5s 517us/sample - loss: 1.0877 - categorical_accuracy: 0.4589\n",
      "Epoch 3/10\n",
      "9350/9350 [==============================] - 5s 512us/sample - loss: 1.0849 - categorical_accuracy: 0.4589\n",
      "Epoch 4/10\n",
      "9350/9350 [==============================] - 5s 511us/sample - loss: 1.0845 - categorical_accuracy: 0.4589\n",
      "Epoch 5/10\n",
      "9350/9350 [==============================] - 5s 513us/sample - loss: 1.0842 - categorical_accuracy: 0.4589\n",
      "Epoch 6/10\n",
      "9350/9350 [==============================] - 5s 515us/sample - loss: 1.0841 - categorical_accuracy: 0.4589\n",
      "Epoch 7/10\n",
      "9350/9350 [==============================] - 5s 514us/sample - loss: 1.0840 - categorical_accuracy: 0.4589\n",
      "Epoch 8/10\n",
      "9350/9350 [==============================] - 5s 514us/sample - loss: 1.0879 - categorical_accuracy: 0.4590\n",
      "Epoch 9/10\n",
      "9350/9350 [==============================] - 5s 512us/sample - loss: 1.0835 - categorical_accuracy: 0.4589\n",
      "Epoch 10/10\n",
      "9350/9350 [==============================] - 5s 515us/sample - loss: 1.0836 - categorical_accuracy: 0.4589\n",
      "1340/1340 [==============================] - 1s 385us/sample - loss: 1.1934 - categorical_accuracy: 0.4381\n",
      "Train on 9381 samples\n",
      "Epoch 1/10\n",
      "9381/9381 [==============================] - 5s 542us/sample - loss: 1.1897 - categorical_accuracy: 0.4048\n",
      "Epoch 2/10\n",
      "9381/9381 [==============================] - 5s 507us/sample - loss: 1.1111 - categorical_accuracy: 0.4545\n",
      "Epoch 3/10\n",
      "9381/9381 [==============================] - 5s 520us/sample - loss: 1.1108 - categorical_accuracy: 0.4545\n",
      "Epoch 4/10\n",
      "9381/9381 [==============================] - 5s 516us/sample - loss: 1.1102 - categorical_accuracy: 0.4545\n",
      "Epoch 5/10\n",
      "9381/9381 [==============================] - 5s 501us/sample - loss: 1.1103 - categorical_accuracy: 0.4545\n",
      "Epoch 6/10\n",
      "9381/9381 [==============================] - 5s 498us/sample - loss: 1.1104 - categorical_accuracy: 0.4540\n",
      "Epoch 7/10\n",
      "9381/9381 [==============================] - 5s 500us/sample - loss: 1.1098 - categorical_accuracy: 0.4545\n",
      "Epoch 8/10\n",
      "9381/9381 [==============================] - 5s 500us/sample - loss: 1.1092 - categorical_accuracy: 0.4545\n",
      "Epoch 9/10\n",
      "9381/9381 [==============================] - 5s 501us/sample - loss: 1.1026 - categorical_accuracy: 0.4545\n",
      "Epoch 10/10\n",
      "9381/9381 [==============================] - 5s 499us/sample - loss: 1.1024 - categorical_accuracy: 0.4528\n",
      "1309/1309 [==============================] - 1s 384us/sample - loss: 1.0124 - categorical_accuracy: 0.4691\n",
      "Train on 9803 samples\n",
      "Epoch 1/10\n",
      "9803/9803 [==============================] - 5s 546us/sample - loss: 1.2371 - categorical_accuracy: 0.4580\n",
      "Epoch 2/10\n",
      "9803/9803 [==============================] - 5s 505us/sample - loss: 1.1293 - categorical_accuracy: 0.4580\n",
      "Epoch 3/10\n",
      "9803/9803 [==============================] - 5s 506us/sample - loss: 1.0980 - categorical_accuracy: 0.4580\n",
      "Epoch 4/10\n",
      "9803/9803 [==============================] - 5s 515us/sample - loss: 1.0974 - categorical_accuracy: 0.4580\n",
      "Epoch 5/10\n",
      "9803/9803 [==============================] - 5s 514us/sample - loss: 1.0901 - categorical_accuracy: 0.4580\n",
      "Epoch 6/10\n",
      "9803/9803 [==============================] - 5s 513us/sample - loss: 1.0789 - categorical_accuracy: 0.4769\n",
      "Epoch 7/10\n",
      "9803/9803 [==============================] - 5s 513us/sample - loss: 1.0867 - categorical_accuracy: 0.4523\n",
      "Epoch 8/10\n",
      "9803/9803 [==============================] - 5s 515us/sample - loss: 1.0557 - categorical_accuracy: 0.4862\n",
      "Epoch 9/10\n",
      "9803/9803 [==============================] - 5s 514us/sample - loss: 1.0911 - categorical_accuracy: 0.4516\n",
      "Epoch 10/10\n",
      "9803/9803 [==============================] - 5s 515us/sample - loss: 1.0962 - categorical_accuracy: 0.4580\n",
      "887/887 [==============================] - 0s 463us/sample - loss: 1.1002 - categorical_accuracy: 0.4374\n",
      "Train on 9450 samples\n",
      "Epoch 1/10\n",
      "9450/9450 [==============================] - 5s 542us/sample - loss: 1.2841 - categorical_accuracy: 0.4553\n",
      "Epoch 2/10\n",
      "9450/9450 [==============================] - 5s 501us/sample - loss: 1.1315 - categorical_accuracy: 0.4567\n",
      "Epoch 3/10\n",
      "9450/9450 [==============================] - 5s 503us/sample - loss: 1.1106 - categorical_accuracy: 0.4567\n",
      "Epoch 4/10\n",
      "9450/9450 [==============================] - 5s 502us/sample - loss: 1.1129 - categorical_accuracy: 0.4594\n",
      "Epoch 5/10\n",
      "9450/9450 [==============================] - 5s 503us/sample - loss: 1.1087 - categorical_accuracy: 0.4567\n",
      "Epoch 6/10\n",
      "9450/9450 [==============================] - 5s 500us/sample - loss: 1.1077 - categorical_accuracy: 0.4568\n",
      "Epoch 7/10\n",
      "9450/9450 [==============================] - 5s 503us/sample - loss: 1.1075 - categorical_accuracy: 0.4567\n",
      "Epoch 8/10\n",
      "9450/9450 [==============================] - 5s 510us/sample - loss: 1.1072 - categorical_accuracy: 0.4568\n",
      "Epoch 9/10\n",
      "9450/9450 [==============================] - 5s 503us/sample - loss: 1.1068 - categorical_accuracy: 0.4568\n",
      "Epoch 10/10\n",
      "9450/9450 [==============================] - 5s 505us/sample - loss: 1.1062 - categorical_accuracy: 0.4568\n",
      "1240/1240 [==============================] - 0s 397us/sample - loss: 1.0067 - categorical_accuracy: 0.4169\n",
      "Train on 8901 samples\n",
      "Epoch 1/10\n",
      "8901/8901 [==============================] - 5s 545us/sample - loss: 1.2087 - categorical_accuracy: 0.4057\n",
      "Epoch 2/10\n",
      "8901/8901 [==============================] - 4s 498us/sample - loss: 1.1034 - categorical_accuracy: 0.4590\n",
      "Epoch 3/10\n",
      "8901/8901 [==============================] - 4s 499us/sample - loss: 1.1010 - categorical_accuracy: 0.4590\n",
      "Epoch 4/10\n",
      "8901/8901 [==============================] - 4s 499us/sample - loss: 1.1005 - categorical_accuracy: 0.4590\n",
      "Epoch 5/10\n",
      "8901/8901 [==============================] - 4s 500us/sample - loss: 1.0994 - categorical_accuracy: 0.4589\n",
      "Epoch 6/10\n",
      "8901/8901 [==============================] - 4s 499us/sample - loss: 1.0980 - categorical_accuracy: 0.4622\n",
      "Epoch 7/10\n",
      "8901/8901 [==============================] - 4s 499us/sample - loss: 1.0964 - categorical_accuracy: 0.4589\n",
      "Epoch 8/10\n",
      "8901/8901 [==============================] - 4s 499us/sample - loss: 1.0934 - categorical_accuracy: 0.4710\n",
      "Epoch 9/10\n",
      "8901/8901 [==============================] - 4s 500us/sample - loss: 1.0682 - categorical_accuracy: 0.5388\n",
      "Epoch 10/10\n",
      "8901/8901 [==============================] - 4s 498us/sample - loss: 1.0121 - categorical_accuracy: 0.6252\n",
      "1789/1789 [==============================] - 1s 332us/sample - loss: 0.9581 - categorical_accuracy: 0.6842\n",
      "Train on 10357 samples\n",
      "Epoch 1/10\n",
      "10357/10357 [==============================] - 6s 543us/sample - loss: 1.3492 - categorical_accuracy: 0.4051\n",
      "Epoch 2/10\n",
      "10357/10357 [==============================] - 5s 503us/sample - loss: 1.1941 - categorical_accuracy: 0.4230\n",
      "Epoch 3/10\n",
      "10357/10357 [==============================] - 5s 509us/sample - loss: 1.1389 - categorical_accuracy: 0.4492\n",
      "Epoch 4/10\n",
      "10357/10357 [==============================] - 5s 502us/sample - loss: 1.1164 - categorical_accuracy: 0.4528\n",
      "Epoch 5/10\n",
      "10357/10357 [==============================] - 5s 500us/sample - loss: 1.1059 - categorical_accuracy: 0.4528\n",
      "Epoch 6/10\n",
      "10357/10357 [==============================] - 5s 500us/sample - loss: 1.0817 - categorical_accuracy: 0.4593\n",
      "Epoch 7/10\n",
      "10357/10357 [==============================] - 5s 499us/sample - loss: 1.0610 - categorical_accuracy: 0.4902\n",
      "Epoch 8/10\n",
      "10357/10357 [==============================] - 5s 504us/sample - loss: 1.0844 - categorical_accuracy: 0.4730\n",
      "Epoch 9/10\n",
      "10357/10357 [==============================] - 5s 503us/sample - loss: 1.0313 - categorical_accuracy: 0.5124\n",
      "Epoch 10/10\n",
      "10357/10357 [==============================] - 5s 490us/sample - loss: 1.0246 - categorical_accuracy: 0.5219\n",
      "333/333 [==============================] - 0s 775us/sample - loss: 0.7376 - categorical_accuracy: 0.8739\n",
      "opening existing file results/lstm.csv\n",
      "loaded 14433\n",
      "stacked (14433, 50, 3)\n",
      "../data/processed/train/keras/subjects_train_50_50_25.csv\n",
      "done\n",
      "(14433, 50, 3) (14433, 1)\n",
      "14433\n",
      "14433\n",
      "14433\n",
      "Train on 11994 samples\n",
      "Epoch 1/10\n",
      "11994/11994 [==============================] - 4s 324us/sample - loss: 1.2992 - categorical_accuracy: 0.3563\n",
      "Epoch 2/10\n",
      "11994/11994 [==============================] - 4s 293us/sample - loss: 1.1473 - categorical_accuracy: 0.4337\n",
      "Epoch 3/10\n",
      "11994/11994 [==============================] - 4s 295us/sample - loss: 1.1103 - categorical_accuracy: 0.4429\n",
      "Epoch 4/10\n",
      "11994/11994 [==============================] - 4s 295us/sample - loss: 1.1040 - categorical_accuracy: 0.4426\n",
      "Epoch 5/10\n",
      "11994/11994 [==============================] - 4s 294us/sample - loss: 1.1103 - categorical_accuracy: 0.4428\n",
      "Epoch 6/10\n",
      "11994/11994 [==============================] - 4s 296us/sample - loss: 1.1102 - categorical_accuracy: 0.4428\n",
      "Epoch 7/10\n",
      "11994/11994 [==============================] - 4s 296us/sample - loss: 1.1101 - categorical_accuracy: 0.4428\n",
      "Epoch 8/10\n",
      "11994/11994 [==============================] - 4s 295us/sample - loss: 1.1101 - categorical_accuracy: 0.4428\n",
      "Epoch 9/10\n",
      "11994/11994 [==============================] - 4s 294us/sample - loss: 1.1097 - categorical_accuracy: 0.4428\n",
      "Epoch 10/10\n",
      "11994/11994 [==============================] - 4s 296us/sample - loss: 1.1099 - categorical_accuracy: 0.4429\n",
      "  32/2439 [..............................] - ETA: 7s - loss: 0.7949 - categorical_accuracy: 1.0000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/elizabeth/education/chair_sensor/ml_project/venv/lib/python3.5/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2439/2439 [==============================] - 1s 223us/sample - loss: 1.0538 - categorical_accuracy: 0.5244\n",
      "Train on 12865 samples\n",
      "Epoch 1/10\n",
      "12865/12865 [==============================] - 4s 322us/sample - loss: 1.2922 - categorical_accuracy: 0.4141\n",
      "Epoch 2/10\n",
      "12865/12865 [==============================] - 4s 294us/sample - loss: 1.1644 - categorical_accuracy: 0.4574\n",
      "Epoch 3/10\n",
      "12865/12865 [==============================] - 4s 295us/sample - loss: 1.1186 - categorical_accuracy: 0.4574\n",
      "Epoch 4/10\n",
      "12865/12865 [==============================] - 4s 295us/sample - loss: 1.1025 - categorical_accuracy: 0.4574\n",
      "Epoch 5/10\n",
      "12865/12865 [==============================] - 4s 296us/sample - loss: 1.0952 - categorical_accuracy: 0.4573\n",
      "Epoch 6/10\n",
      "12865/12865 [==============================] - 4s 296us/sample - loss: 1.0883 - categorical_accuracy: 0.4574\n",
      "Epoch 7/10\n",
      "12865/12865 [==============================] - 4s 295us/sample - loss: 1.0774 - categorical_accuracy: 0.4575\n",
      "Epoch 8/10\n",
      "12865/12865 [==============================] - 4s 296us/sample - loss: 1.0570 - categorical_accuracy: 0.5182\n",
      "Epoch 9/10\n",
      "12865/12865 [==============================] - 4s 295us/sample - loss: 1.0306 - categorical_accuracy: 0.6549\n",
      "Epoch 10/10\n",
      "12865/12865 [==============================] - 4s 297us/sample - loss: 1.0124 - categorical_accuracy: 0.6187\n",
      "1568/1568 [==============================] - 0s 204us/sample - loss: 0.9893 - categorical_accuracy: 0.6677\n",
      "Train on 13319 samples\n",
      "Epoch 1/10\n",
      "13319/13319 [==============================] - 4s 325us/sample - loss: 1.2932 - categorical_accuracy: 0.4544\n",
      "Epoch 2/10\n",
      "13319/13319 [==============================] - 4s 295us/sample - loss: 1.1518 - categorical_accuracy: 0.4656\n",
      "Epoch 3/10\n",
      "13319/13319 [==============================] - 4s 294us/sample - loss: 1.1026 - categorical_accuracy: 0.4723\n",
      "Epoch 4/10\n",
      "13319/13319 [==============================] - 4s 294us/sample - loss: 1.0663 - categorical_accuracy: 0.5498\n",
      "Epoch 5/10\n",
      "13319/13319 [==============================] - 4s 294us/sample - loss: 0.9838 - categorical_accuracy: 0.6491\n",
      "Epoch 6/10\n",
      "13319/13319 [==============================] - 4s 294us/sample - loss: 0.9383 - categorical_accuracy: 0.6715\n",
      "Epoch 7/10\n",
      "13319/13319 [==============================] - 4s 295us/sample - loss: 0.9264 - categorical_accuracy: 0.6683\n",
      "Epoch 8/10\n",
      "13319/13319 [==============================] - 4s 296us/sample - loss: 0.9151 - categorical_accuracy: 0.6732\n",
      "Epoch 9/10\n",
      "13319/13319 [==============================] - 4s 297us/sample - loss: 0.9102 - categorical_accuracy: 0.6739\n",
      "Epoch 10/10\n",
      "13319/13319 [==============================] - 4s 294us/sample - loss: 0.9051 - categorical_accuracy: 0.6751\n",
      "1114/1114 [==============================] - 0s 301us/sample - loss: 1.1116 - categorical_accuracy: 0.6284\n",
      "Train on 12624 samples\n",
      "Epoch 1/10\n",
      "12624/12624 [==============================] - 4s 321us/sample - loss: 1.2246 - categorical_accuracy: 0.4061\n",
      "Epoch 2/10\n",
      "12624/12624 [==============================] - 4s 281us/sample - loss: 1.0864 - categorical_accuracy: 0.4575\n",
      "Epoch 3/10\n",
      "12624/12624 [==============================] - 4s 282us/sample - loss: 1.0583 - categorical_accuracy: 0.4667\n",
      "Epoch 4/10\n",
      "12624/12624 [==============================] - 4s 281us/sample - loss: 1.0371 - categorical_accuracy: 0.4985\n",
      "Epoch 5/10\n",
      "12624/12624 [==============================] - 4s 282us/sample - loss: 1.0116 - categorical_accuracy: 0.5452\n",
      "Epoch 6/10\n",
      "12624/12624 [==============================] - 4s 281us/sample - loss: 1.0061 - categorical_accuracy: 0.5543\n",
      "Epoch 7/10\n",
      "12624/12624 [==============================] - 4s 281us/sample - loss: 0.9938 - categorical_accuracy: 0.5765\n",
      "Epoch 8/10\n",
      "12624/12624 [==============================] - 4s 280us/sample - loss: 0.9663 - categorical_accuracy: 0.6327\n",
      "Epoch 9/10\n",
      "12624/12624 [==============================] - 4s 281us/sample - loss: 0.9833 - categorical_accuracy: 0.6286\n",
      "Epoch 10/10\n",
      "12624/12624 [==============================] - 4s 280us/sample - loss: 0.9131 - categorical_accuracy: 0.7028\n",
      "1809/1809 [==============================] - 0s 243us/sample - loss: 1.1754 - categorical_accuracy: 0.3698\n",
      "Train on 12666 samples\n",
      "Epoch 1/10\n",
      "12666/12666 [==============================] - 4s 313us/sample - loss: 1.2777 - categorical_accuracy: 0.4473\n",
      "Epoch 2/10\n",
      "12666/12666 [==============================] - 4s 281us/sample - loss: 1.1221 - categorical_accuracy: 0.4570\n",
      "Epoch 3/10\n",
      "12666/12666 [==============================] - 4s 283us/sample - loss: 1.0325 - categorical_accuracy: 0.6292\n",
      "Epoch 4/10\n",
      "12666/12666 [==============================] - 4s 283us/sample - loss: 1.0965 - categorical_accuracy: 0.4475\n",
      "Epoch 5/10\n",
      "12666/12666 [==============================] - 4s 283us/sample - loss: 1.0948 - categorical_accuracy: 0.4430\n",
      "Epoch 6/10\n",
      "12666/12666 [==============================] - 4s 283us/sample - loss: 1.0073 - categorical_accuracy: 0.5691\n",
      "Epoch 7/10\n",
      "12666/12666 [==============================] - 4s 283us/sample - loss: 0.9913 - categorical_accuracy: 0.5996\n",
      "Epoch 8/10\n",
      "12666/12666 [==============================] - 4s 282us/sample - loss: 0.9658 - categorical_accuracy: 0.6208\n",
      "Epoch 9/10\n",
      "12666/12666 [==============================] - 4s 283us/sample - loss: 0.9921 - categorical_accuracy: 0.6176\n",
      "Epoch 10/10\n",
      "12666/12666 [==============================] - 4s 283us/sample - loss: 0.9270 - categorical_accuracy: 0.6773\n",
      "1767/1767 [==============================] - 0s 253us/sample - loss: 3.2274 - categorical_accuracy: 0.4714\n",
      "Train on 13236 samples\n",
      "Epoch 1/10\n",
      "13236/13236 [==============================] - 4s 323us/sample - loss: 1.2829 - categorical_accuracy: 0.3989\n",
      "Epoch 2/10\n",
      "13236/13236 [==============================] - 4s 294us/sample - loss: 1.1405 - categorical_accuracy: 0.4260\n",
      "Epoch 3/10\n",
      "13236/13236 [==============================] - 4s 295us/sample - loss: 1.0560 - categorical_accuracy: 0.5808\n",
      "Epoch 4/10\n",
      "13236/13236 [==============================] - 4s 290us/sample - loss: 1.0031 - categorical_accuracy: 0.6379\n",
      "Epoch 5/10\n",
      "13236/13236 [==============================] - 4s 282us/sample - loss: 0.9638 - categorical_accuracy: 0.6670\n",
      "Epoch 6/10\n",
      "13236/13236 [==============================] - 4s 281us/sample - loss: 0.9353 - categorical_accuracy: 0.6803\n",
      "Epoch 7/10\n",
      "13236/13236 [==============================] - 4s 282us/sample - loss: 0.9162 - categorical_accuracy: 0.6822\n",
      "Epoch 8/10\n",
      "13236/13236 [==============================] - 4s 283us/sample - loss: 0.9066 - categorical_accuracy: 0.6824\n",
      "Epoch 9/10\n",
      "13236/13236 [==============================] - 4s 282us/sample - loss: 0.8980 - categorical_accuracy: 0.6907\n",
      "Epoch 10/10\n",
      "13236/13236 [==============================] - 4s 281us/sample - loss: 0.8996 - categorical_accuracy: 0.6866\n",
      "1197/1197 [==============================] - 0s 291us/sample - loss: 1.1147 - categorical_accuracy: 0.5171\n",
      "Train on 12760 samples\n",
      "Epoch 1/10\n",
      "12760/12760 [==============================] - 4s 326us/sample - loss: 1.1540 - categorical_accuracy: 0.4186\n",
      "Epoch 2/10\n",
      "12760/12760 [==============================] - 4s 301us/sample - loss: 1.1075 - categorical_accuracy: 0.4575\n",
      "Epoch 3/10\n",
      "12760/12760 [==============================] - 4s 292us/sample - loss: 1.0467 - categorical_accuracy: 0.4828\n",
      "Epoch 4/10\n",
      "12760/12760 [==============================] - 4s 281us/sample - loss: 0.9664 - categorical_accuracy: 0.5519\n",
      "Epoch 5/10\n",
      "12760/12760 [==============================] - 4s 280us/sample - loss: 0.9056 - categorical_accuracy: 0.6263\n",
      "Epoch 6/10\n",
      "12760/12760 [==============================] - 4s 283us/sample - loss: 0.8754 - categorical_accuracy: 0.6417\n",
      "Epoch 7/10\n",
      "12760/12760 [==============================] - 4s 282us/sample - loss: 0.8563 - categorical_accuracy: 0.6487\n",
      "Epoch 8/10\n",
      "12760/12760 [==============================] - 4s 281us/sample - loss: 0.8434 - categorical_accuracy: 0.6487\n",
      "Epoch 9/10\n",
      "12760/12760 [==============================] - 4s 282us/sample - loss: 0.8318 - categorical_accuracy: 0.6560\n",
      "Epoch 10/10\n",
      "12760/12760 [==============================] - 4s 283us/sample - loss: 0.8275 - categorical_accuracy: 0.6532\n",
      "1673/1673 [==============================] - 0s 251us/sample - loss: 0.6812 - categorical_accuracy: 0.7041\n",
      "Train on 12017 samples\n",
      "Epoch 1/10\n",
      "12017/12017 [==============================] - 4s 330us/sample - loss: 1.1498 - categorical_accuracy: 0.4563\n",
      "Epoch 2/10\n",
      "12017/12017 [==============================] - 4s 295us/sample - loss: 1.1045 - categorical_accuracy: 0.4602\n",
      "Epoch 3/10\n",
      "12017/12017 [==============================] - 4s 304us/sample - loss: 1.1025 - categorical_accuracy: 0.4602\n",
      "Epoch 4/10\n",
      "12017/12017 [==============================] - 4s 304us/sample - loss: 1.0978 - categorical_accuracy: 0.4825\n",
      "Epoch 5/10\n",
      "12017/12017 [==============================] - 4s 304us/sample - loss: 1.0247 - categorical_accuracy: 0.5957\n",
      "Epoch 6/10\n",
      "12017/12017 [==============================] - 4s 304us/sample - loss: 0.9537 - categorical_accuracy: 0.6489\n",
      "Epoch 7/10\n",
      "12017/12017 [==============================] - 4s 304us/sample - loss: 0.9363 - categorical_accuracy: 0.6599\n",
      "Epoch 8/10\n",
      "12017/12017 [==============================] - 4s 304us/sample - loss: 0.9357 - categorical_accuracy: 0.6571\n",
      "Epoch 9/10\n",
      "12017/12017 [==============================] - 4s 303us/sample - loss: 0.9315 - categorical_accuracy: 0.6588\n",
      "Epoch 10/10\n",
      "12017/12017 [==============================] - 4s 304us/sample - loss: 0.9297 - categorical_accuracy: 0.6622\n",
      "2416/2416 [==============================] - 1s 219us/sample - loss: 0.8862 - categorical_accuracy: 0.7111\n",
      "Train on 13983 samples\n",
      "Epoch 1/10\n",
      "13983/13983 [==============================] - 4s 321us/sample - loss: 1.2277 - categorical_accuracy: 0.3931\n",
      "Epoch 2/10\n",
      "13983/13983 [==============================] - 4s 296us/sample - loss: 1.1029 - categorical_accuracy: 0.4504\n",
      "Epoch 3/10\n",
      "13983/13983 [==============================] - 4s 297us/sample - loss: 1.0741 - categorical_accuracy: 0.4570\n",
      "Epoch 4/10\n",
      "13983/13983 [==============================] - 4s 297us/sample - loss: 1.0399 - categorical_accuracy: 0.4654\n",
      "Epoch 5/10\n",
      "13983/13983 [==============================] - 4s 297us/sample - loss: 0.9900 - categorical_accuracy: 0.4809\n",
      "Epoch 6/10\n",
      "13983/13983 [==============================] - 4s 297us/sample - loss: 0.9962 - categorical_accuracy: 0.4774\n",
      "Epoch 7/10\n",
      "13983/13983 [==============================] - 4s 298us/sample - loss: 0.9807 - categorical_accuracy: 0.4807\n",
      "Epoch 8/10\n",
      "13983/13983 [==============================] - 4s 297us/sample - loss: 0.9797 - categorical_accuracy: 0.4794\n",
      "Epoch 9/10\n",
      "13983/13983 [==============================] - 4s 297us/sample - loss: 0.9722 - categorical_accuracy: 0.4799\n",
      "Epoch 10/10\n",
      "13983/13983 [==============================] - 4s 297us/sample - loss: 1.0047 - categorical_accuracy: 0.4721\n",
      "450/450 [==============================] - 0s 548us/sample - loss: 1.0047 - categorical_accuracy: 0.5622\n",
      "opening existing file results/lstm.csv\n",
      "loaded 18741\n",
      "stacked (18741, 45, 3)\n",
      "../data/processed/train/keras/subjects_train_30_45_34.csv\n",
      "done\n",
      "(18741, 45, 3) (18741, 1)\n",
      "18741\n",
      "18741\n",
      "18741\n",
      "Train on 15573 samples\n",
      "Epoch 1/10\n",
      "15573/15573 [==============================] - 4s 275us/sample - loss: 1.3263 - categorical_accuracy: 0.3030\n",
      "Epoch 2/10\n",
      "15573/15573 [==============================] - 4s 253us/sample - loss: 1.1591 - categorical_accuracy: 0.4442\n",
      "Epoch 3/10\n",
      "15573/15573 [==============================] - 4s 255us/sample - loss: 1.1194 - categorical_accuracy: 0.4440\n",
      "Epoch 4/10\n",
      "15573/15573 [==============================] - 4s 253us/sample - loss: 1.1076 - categorical_accuracy: 0.4442\n",
      "Epoch 5/10\n",
      "15573/15573 [==============================] - 4s 256us/sample - loss: 1.0926 - categorical_accuracy: 0.4485\n",
      "Epoch 6/10\n",
      "15573/15573 [==============================] - 4s 254us/sample - loss: 1.0639 - categorical_accuracy: 0.4980\n",
      "Epoch 7/10\n",
      "15573/15573 [==============================] - 4s 255us/sample - loss: 1.0472 - categorical_accuracy: 0.5281\n",
      "Epoch 8/10\n",
      "15573/15573 [==============================] - 4s 254us/sample - loss: 1.0388 - categorical_accuracy: 0.5377\n",
      "Epoch 9/10\n",
      "15573/15573 [==============================] - 4s 255us/sample - loss: 1.0301 - categorical_accuracy: 0.5416\n",
      "Epoch 10/10\n",
      "15573/15573 [==============================] - 4s 256us/sample - loss: 1.0187 - categorical_accuracy: 0.5300\n",
      "  32/3168 [..............................] - ETA: 9s - loss: 0.8896 - categorical_accuracy: 0.0000e+00"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/elizabeth/education/chair_sensor/ml_project/venv/lib/python3.5/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3168/3168 [==============================] - 1s 165us/sample - loss: 0.8724 - categorical_accuracy: 0.6222\n",
      "Train on 16703 samples\n",
      "Epoch 1/10\n",
      "16703/16703 [==============================] - 5s 293us/sample - loss: 1.1923 - categorical_accuracy: 0.3914\n",
      "Epoch 2/10\n",
      "16703/16703 [==============================] - 5s 273us/sample - loss: 1.0855 - categorical_accuracy: 0.4700\n",
      "Epoch 3/10\n",
      "16703/16703 [==============================] - 5s 273us/sample - loss: 1.0143 - categorical_accuracy: 0.6277\n",
      "Epoch 4/10\n",
      "16703/16703 [==============================] - 5s 274us/sample - loss: 0.9644 - categorical_accuracy: 0.6562\n",
      "Epoch 5/10\n",
      "16703/16703 [==============================] - 5s 273us/sample - loss: 0.9409 - categorical_accuracy: 0.6674\n",
      "Epoch 6/10\n",
      "16703/16703 [==============================] - 4s 258us/sample - loss: 0.9299 - categorical_accuracy: 0.6693\n",
      "Epoch 7/10\n",
      "16703/16703 [==============================] - 4s 259us/sample - loss: 0.9182 - categorical_accuracy: 0.6790\n",
      "Epoch 8/10\n",
      "16703/16703 [==============================] - 4s 258us/sample - loss: 0.9146 - categorical_accuracy: 0.6756\n",
      "Epoch 9/10\n",
      "16703/16703 [==============================] - 4s 259us/sample - loss: 0.9133 - categorical_accuracy: 0.6763\n",
      "Epoch 10/10\n",
      "16703/16703 [==============================] - 4s 258us/sample - loss: 0.9083 - categorical_accuracy: 0.6763\n",
      "2038/2038 [==============================] - 0s 222us/sample - loss: 1.0471 - categorical_accuracy: 0.5020\n",
      "Train on 17295 samples\n",
      "Epoch 1/10\n",
      "17295/17295 [==============================] - 5s 291us/sample - loss: 1.1094 - categorical_accuracy: 0.4726\n",
      "Epoch 2/10\n",
      "17295/17295 [==============================] - 5s 268us/sample - loss: 0.9822 - categorical_accuracy: 0.6077\n",
      "Epoch 3/10\n",
      "17295/17295 [==============================] - 5s 271us/sample - loss: 0.9559 - categorical_accuracy: 0.6274\n",
      "Epoch 4/10\n",
      "17295/17295 [==============================] - 5s 271us/sample - loss: 0.9381 - categorical_accuracy: 0.6482\n",
      "Epoch 5/10\n",
      "17295/17295 [==============================] - 5s 272us/sample - loss: 0.9227 - categorical_accuracy: 0.6622\n",
      "Epoch 6/10\n",
      "17295/17295 [==============================] - 5s 272us/sample - loss: 0.9055 - categorical_accuracy: 0.6676\n",
      "Epoch 7/10\n",
      "17295/17295 [==============================] - 5s 275us/sample - loss: 0.8950 - categorical_accuracy: 0.6733\n",
      "Epoch 8/10\n",
      "17295/17295 [==============================] - 5s 269us/sample - loss: 0.8847 - categorical_accuracy: 0.6737\n",
      "Epoch 9/10\n",
      "17295/17295 [==============================] - 5s 268us/sample - loss: 0.8755 - categorical_accuracy: 0.6770\n",
      "Epoch 10/10\n",
      "17295/17295 [==============================] - 5s 268us/sample - loss: 0.8775 - categorical_accuracy: 0.6727\n",
      "1446/1446 [==============================] - 0s 254us/sample - loss: 1.0280 - categorical_accuracy: 0.6127\n",
      "Train on 16392 samples\n",
      "Epoch 1/10\n",
      "16392/16392 [==============================] - 5s 291us/sample - loss: 1.3375 - categorical_accuracy: 0.3350\n",
      "Epoch 2/10\n",
      "16392/16392 [==============================] - 4s 269us/sample - loss: 1.1405 - categorical_accuracy: 0.4600\n",
      "Epoch 3/10\n",
      "16392/16392 [==============================] - 4s 268us/sample - loss: 1.1002 - categorical_accuracy: 0.4601\n",
      "Epoch 4/10\n",
      "16392/16392 [==============================] - 4s 269us/sample - loss: 1.0883 - categorical_accuracy: 0.4601\n",
      "Epoch 5/10\n",
      "16392/16392 [==============================] - 4s 270us/sample - loss: 1.0851 - categorical_accuracy: 0.4601\n",
      "Epoch 6/10\n",
      "16392/16392 [==============================] - 4s 270us/sample - loss: 1.0842 - categorical_accuracy: 0.4601\n",
      "Epoch 7/10\n",
      "16392/16392 [==============================] - 4s 267us/sample - loss: 1.0841 - categorical_accuracy: 0.4601\n",
      "Epoch 8/10\n",
      "16392/16392 [==============================] - 4s 258us/sample - loss: 1.0840 - categorical_accuracy: 0.4601\n",
      "Epoch 9/10\n",
      "16392/16392 [==============================] - 4s 260us/sample - loss: 1.0756 - categorical_accuracy: 0.4822\n",
      "Epoch 10/10\n",
      "16392/16392 [==============================] - 4s 259us/sample - loss: 0.9989 - categorical_accuracy: 0.6265\n",
      "2349/2349 [==============================] - 0s 210us/sample - loss: 0.9564 - categorical_accuracy: 0.7143\n",
      "Train on 16449 samples\n",
      "Epoch 1/10\n",
      "16449/16449 [==============================] - 5s 292us/sample - loss: 1.1294 - categorical_accuracy: 0.4371\n",
      "Epoch 2/10\n",
      "16449/16449 [==============================] - 4s 269us/sample - loss: 1.0989 - categorical_accuracy: 0.4629\n",
      "Epoch 3/10\n",
      "16449/16449 [==============================] - 4s 273us/sample - loss: 1.0036 - categorical_accuracy: 0.6164\n",
      "Epoch 4/10\n",
      "16449/16449 [==============================] - 4s 273us/sample - loss: 0.8933 - categorical_accuracy: 0.6762\n",
      "Epoch 5/10\n",
      "16449/16449 [==============================] - 4s 269us/sample - loss: 0.8772 - categorical_accuracy: 0.6791\n",
      "Epoch 6/10\n",
      "16449/16449 [==============================] - 4s 268us/sample - loss: 0.8592 - categorical_accuracy: 0.6886\n",
      "Epoch 7/10\n",
      "16449/16449 [==============================] - 4s 268us/sample - loss: 0.8604 - categorical_accuracy: 0.6866\n",
      "Epoch 8/10\n",
      "16449/16449 [==============================] - 4s 268us/sample - loss: 0.8524 - categorical_accuracy: 0.6906\n",
      "Epoch 9/10\n",
      "16449/16449 [==============================] - 4s 269us/sample - loss: 0.8512 - categorical_accuracy: 0.6912\n",
      "Epoch 10/10\n",
      "16449/16449 [==============================] - 4s 269us/sample - loss: 0.8527 - categorical_accuracy: 0.6895\n",
      "2292/2292 [==============================] - 0s 212us/sample - loss: 2.4359 - categorical_accuracy: 0.4690\n",
      "Train on 17189 samples\n",
      "Epoch 1/10\n",
      "17189/17189 [==============================] - 5s 279us/sample - loss: 1.1588 - categorical_accuracy: 0.4313\n",
      "Epoch 2/10\n",
      "17189/17189 [==============================] - 4s 259us/sample - loss: 1.0325 - categorical_accuracy: 0.5737\n",
      "Epoch 3/10\n",
      "17189/17189 [==============================] - 4s 256us/sample - loss: 0.9612 - categorical_accuracy: 0.6572\n",
      "Epoch 4/10\n",
      "17189/17189 [==============================] - 4s 256us/sample - loss: 0.9415 - categorical_accuracy: 0.6605\n",
      "Epoch 5/10\n",
      "17189/17189 [==============================] - 4s 256us/sample - loss: 0.9267 - categorical_accuracy: 0.6710\n",
      "Epoch 6/10\n",
      "17189/17189 [==============================] - 4s 256us/sample - loss: 0.9098 - categorical_accuracy: 0.6809\n",
      "Epoch 7/10\n",
      "17189/17189 [==============================] - 4s 256us/sample - loss: 0.8883 - categorical_accuracy: 0.6792\n",
      "Epoch 8/10\n",
      "17189/17189 [==============================] - 4s 256us/sample - loss: 0.8544 - categorical_accuracy: 0.6899\n",
      "Epoch 9/10\n",
      "17189/17189 [==============================] - 4s 256us/sample - loss: 0.8427 - categorical_accuracy: 0.6890\n",
      "Epoch 10/10\n",
      "17189/17189 [==============================] - 4s 256us/sample - loss: 0.8377 - categorical_accuracy: 0.6906\n",
      "1552/1552 [==============================] - 0s 246us/sample - loss: 1.0931 - categorical_accuracy: 0.5180\n",
      "Train on 16567 samples\n",
      "Epoch 1/10\n",
      "16567/16567 [==============================] - 5s 292us/sample - loss: 1.2610 - categorical_accuracy: 0.4580\n",
      "Epoch 2/10\n",
      "16567/16567 [==============================] - 4s 270us/sample - loss: 1.1193 - categorical_accuracy: 0.4580\n",
      "Epoch 3/10\n",
      "16567/16567 [==============================] - 4s 270us/sample - loss: 1.1058 - categorical_accuracy: 0.4572\n",
      "Epoch 4/10\n",
      "16567/16567 [==============================] - 4s 265us/sample - loss: 1.1048 - categorical_accuracy: 0.4580\n",
      "Epoch 5/10\n",
      "16567/16567 [==============================] - 4s 257us/sample - loss: 1.0995 - categorical_accuracy: 0.4674\n",
      "Epoch 6/10\n",
      "16567/16567 [==============================] - 4s 256us/sample - loss: 1.0794 - categorical_accuracy: 0.4771\n",
      "Epoch 7/10\n",
      "16567/16567 [==============================] - 4s 255us/sample - loss: 1.0397 - categorical_accuracy: 0.5096\n",
      "Epoch 8/10\n",
      "16567/16567 [==============================] - 4s 257us/sample - loss: 0.9949 - categorical_accuracy: 0.5746\n",
      "Epoch 9/10\n",
      "16567/16567 [==============================] - 4s 256us/sample - loss: 0.8404 - categorical_accuracy: 0.6953\n",
      "Epoch 10/10\n",
      "16567/16567 [==============================] - 4s 256us/sample - loss: 0.7658 - categorical_accuracy: 0.7035\n",
      "2174/2174 [==============================] - 0s 214us/sample - loss: 0.8123 - categorical_accuracy: 0.5773\n",
      "Train on 15604 samples\n",
      "Epoch 1/10\n",
      "15604/15604 [==============================] - 5s 293us/sample - loss: 1.1822 - categorical_accuracy: 0.4551\n",
      "Epoch 2/10\n",
      "15604/15604 [==============================] - 4s 269us/sample - loss: 1.0986 - categorical_accuracy: 0.4608\n",
      "Epoch 3/10\n",
      "15604/15604 [==============================] - 4s 270us/sample - loss: 1.0975 - categorical_accuracy: 0.4612\n",
      "Epoch 4/10\n",
      "15604/15604 [==============================] - 4s 271us/sample - loss: 1.0945 - categorical_accuracy: 0.4608\n",
      "Epoch 5/10\n",
      "15604/15604 [==============================] - 4s 272us/sample - loss: 1.0797 - categorical_accuracy: 0.5273\n",
      "Epoch 6/10\n",
      "15604/15604 [==============================] - 4s 270us/sample - loss: 1.0171 - categorical_accuracy: 0.6100\n",
      "Epoch 7/10\n",
      "15604/15604 [==============================] - 4s 271us/sample - loss: 0.9736 - categorical_accuracy: 0.6405\n",
      "Epoch 8/10\n",
      "15604/15604 [==============================] - 4s 271us/sample - loss: 0.9469 - categorical_accuracy: 0.6518\n",
      "Epoch 9/10\n",
      "15604/15604 [==============================] - 4s 276us/sample - loss: 0.9155 - categorical_accuracy: 0.6622\n",
      "Epoch 10/10\n",
      "15604/15604 [==============================] - 4s 270us/sample - loss: 0.8986 - categorical_accuracy: 0.6712\n",
      "3137/3137 [==============================] - 1s 194us/sample - loss: 0.8641 - categorical_accuracy: 0.7019\n",
      "Train on 18156 samples\n",
      "Epoch 1/10\n",
      "18156/18156 [==============================] - 5s 290us/sample - loss: 1.2325 - categorical_accuracy: 0.4076\n",
      "Epoch 2/10\n",
      "18156/18156 [==============================] - 5s 268us/sample - loss: 0.9898 - categorical_accuracy: 0.6200\n",
      "Epoch 3/10\n",
      "18156/18156 [==============================] - 5s 269us/sample - loss: 0.9290 - categorical_accuracy: 0.6469\n",
      "Epoch 4/10\n",
      "18156/18156 [==============================] - 5s 270us/sample - loss: 0.9218 - categorical_accuracy: 0.6471\n",
      "Epoch 5/10\n",
      "18156/18156 [==============================] - 5s 270us/sample - loss: 0.9143 - categorical_accuracy: 0.6523\n",
      "Epoch 6/10\n",
      "18156/18156 [==============================] - 5s 269us/sample - loss: 0.9083 - categorical_accuracy: 0.6560\n",
      "Epoch 7/10\n",
      "18156/18156 [==============================] - 5s 269us/sample - loss: 0.9004 - categorical_accuracy: 0.6622\n",
      "Epoch 8/10\n",
      "18156/18156 [==============================] - 5s 269us/sample - loss: 0.8943 - categorical_accuracy: 0.6740\n",
      "Epoch 9/10\n",
      "18156/18156 [==============================] - 5s 269us/sample - loss: 0.8948 - categorical_accuracy: 0.6770\n",
      "Epoch 10/10\n",
      "18156/18156 [==============================] - 5s 269us/sample - loss: 0.8609 - categorical_accuracy: 0.6998\n",
      "585/585 [==============================] - 0s 439us/sample - loss: 0.7111 - categorical_accuracy: 0.8068\n",
      "opening existing file results/lstm.csv\n"
     ]
    }
   ],
   "source": [
    "from os import listdir\n",
    "from os import path\n",
    "import re\n",
    "import csv\n",
    "\n",
    "source = '../data/processed/train/keras/'\n",
    "dest = 'results'\n",
    "i = 1\n",
    "\n",
    "for name in listdir(source):\n",
    "    filename = source + '/' + name\n",
    "    if not name.endswith('csv') or not name.startswith('total_acc_x_train_'):\n",
    "        continue\n",
    "    pattern = 'total_acc_x_train_' + '[0-9]*[0-9]_[0-9]*[0-9]_[0-9]*[0-9]' + '.csv'\n",
    "    match = re.search(pattern, name)\n",
    "    if not match:\n",
    "        continue\n",
    "\n",
    "    combi = re.search('train_(.+?).csv', name)\n",
    "    if combi:\n",
    "        combi = combi.group(1)\n",
    "    \n",
    "    trainX, trainy, subjects = load_dataset(comb=combi, prefix=source)\n",
    "    # dummy dataset just for logo.split\n",
    "    X_dummy = np.arange(len(trainX))\n",
    "    \n",
    "    results = run_logo(trainX, trainy, subjects.iloc[:,0], X_dummy)\n",
    "\n",
    "    header = ['comb', 'f1-0', 'f1-1', 'f1-2', 'f1-2', 'macro f1', 'micro f1']\n",
    "    \n",
    "    for key in results:\n",
    "        row = [combi]\n",
    "        for e in results[key]:\n",
    "            row.extend(e)\n",
    "        \n",
    "        outFilename = dest + '/' + key + '.csv'\n",
    "        if not path.isfile(outFilename):\n",
    "            print('creating new file', outFilename)\n",
    "            with open(outFilename, 'w') as outFile:\n",
    "                writer = csv.writer(outFile)\n",
    "                writer.writerow(header)\n",
    "                writer.writerow(row)\n",
    "                outFile.close()\n",
    "        else:\n",
    "#         row = [combi]\n",
    "#         row.extend(freq)\n",
    "#         writer = csv.writer(outFile)\n",
    "#         writer.writerow(row)\n",
    "            print('opening existing file', outFilename)\n",
    "            with open(outFilename, 'a+') as outFile:\n",
    "                writer = csv.writer(outFile)\n",
    "                writer.writerow(row)\n",
    "                outFile.close()\n",
    "    i += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GridSearchCV with the best combination for all algorithms\n",
    "from sklearn.model_selection import LeaveOneGroupOut\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "def evaluate_model(trainX, trainy, testX, testy, model):\n",
    "    trainy, testy = trainy[:,0], testy[:,0]\n",
    "\n",
    "    # fit the model\n",
    "    model.fit(trainX, trainy)\n",
    "    # make predictions\n",
    "    yhat = model.predict(testX)\n",
    "\n",
    "#     hat, test = 0,0\n",
    "#     for i in range(len(yhat)):\n",
    "#         if yhat[i] == 0:\n",
    "#             hat += 1\n",
    "#         if testy[i][0] == 0:\n",
    "#             test += 1\n",
    "#     print('hat', hat)\n",
    "#     print('test', test)\n",
    "    # evaluate predictions\n",
    "#     accuracy = balanced_accuracy_score(testy, yhat)\n",
    "    f1_macro = f1_score(testy, yhat, average='macro')\n",
    "    f1_micro = f1_score(testy, yhat, average='micro')\n",
    "    f1 = f1_score(testy, yhat, average=None)\n",
    "\n",
    "#     print('accuracy:', accuracy)\n",
    "#     print(classification_report(testy, yhat))\n",
    "#     print(confusion_matrix(testy, yhat))\n",
    "    return f1, f1_macro, f1_micro, model\n",
    "\n",
    "def run_nested_logo(X_all, y_all, all_df, groups):\n",
    "    logo = LeaveOneGroupOut()\n",
    "    group = 0\n",
    "\n",
    "    f1s = []\n",
    "    f1_macros = []\n",
    "    f1_micros = []\n",
    "    best_params = []\n",
    "    best_scores = []\n",
    "\n",
    "#     clf = RandomForestClassifier()\n",
    "#     params = {'n_estimators': [10, 100, 200],\n",
    "#                'max_depth': [None, 50, 80],\n",
    "#                'min_samples_leaf': [1, 5],\n",
    "#                'min_samples_split': [2, 8, 10],\n",
    "#                'max_features': ['log2', 'sqrt','auto', None], \n",
    "#                'criterion': ['entropy', 'gini']}\n",
    "#     for train_index, test_index in logo.split(X_all, groups=groups):\n",
    "#         X_train, X_test = X_all.values[train_index], X_all.values[test_index]\n",
    "#         y_train, y_test = y_all.values[train_index], y_all.values[test_index]\n",
    "        \n",
    "#         inner_groups = all_df.iloc[all_df.index.isin(train_index)]['name']\n",
    "\n",
    "#         grid_obj = GridSearchCV(clf, params, scoring='f1_macro', cv=logo.split(X_train, groups=inner_groups), n_jobs=-1)\n",
    "#         f1, f1_macro, f1_micro, grid_obj = evaluate_model(X_train, y_train, X_test, y_test, grid_obj)\n",
    "#         print('Group', group)\n",
    "#         print(best_params_)\n",
    "#         print(best_score_)\n",
    "#         best_params.append(grid_obj.best_params_)\n",
    "#         best_scores.append(grid_obj.best_score_)\n",
    "#         group += 1\n",
    "        \n",
    "    grid_obj = GridSearchCV(clf, params, scoring='f1_macro', cv=logo.split(X_all, groups=groups), n_jobs=-1)\n",
    "#     f1, f1_macro, f1_micro, grid_obj = evaluate_model(X_all, y_all, X_test, y_test, grid_obj)\n",
    "    grid_obj.fit(X_all, y_all)\n",
    "    \n",
    "    print('best params', best_params_)\n",
    "    print('best score', best_score_)\n",
    "\n",
    "#     return np.average(f1s, axis=0).tolist(), [np.average(f1_macros).tolist()], [np.average(f1_micros).tolist()], best_params, best_scores\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-a7c9b78648b9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mgroups\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'name'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_nested_logo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_all\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_all\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-19-083741140ab8>\u001b[0m in \u001b[0;36mrun_nested_logo\u001b[0;34m(X_all, y_all, all_df, groups)\u001b[0m\n\u001b[1;32m     64\u001b[0m     \u001b[0mgrid_obj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'f1_macro'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_all\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgroups\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;31m#     f1, f1_macro, f1_micro, grid_obj = evaluate_model(X_all, y_all, X_test, y_test, grid_obj)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m     \u001b[0mgrid_obj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_all\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_all\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'best params'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbest_params_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/education/chair_sensor/ml_project/venv/lib/python3.5/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    685\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    686\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 687\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    688\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    689\u001b[0m         \u001b[0;31m# For multi-metric evaluation, store the best_index_, best_params_ and\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/education/chair_sensor/ml_project/venv/lib/python3.5/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1146\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1147\u001b[0m         \u001b[0;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1148\u001b[0;31m         \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1149\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/education/chair_sensor/ml_project/venv/lib/python3.5/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params)\u001b[0m\n\u001b[1;32m    664\u001b[0m                                \u001b[0;32mfor\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    665\u001b[0m                                in product(candidate_params,\n\u001b[0;32m--> 666\u001b[0;31m                                           cv.split(X, y, groups)))\n\u001b[0m\u001b[1;32m    667\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    668\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/education/chair_sensor/ml_project/venv/lib/python3.5/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    932\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    933\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 934\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    935\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    936\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/education/chair_sensor/ml_project/venv/lib/python3.5/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    831\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    832\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 833\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    834\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    835\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/education/chair_sensor/ml_project/venv/lib/python3.5/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[0;34m(future, timeout)\u001b[0m\n\u001b[1;32m    519\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[1;32m    520\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    522\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mLokyTimeoutError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.5/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    398\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    399\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 400\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_condition\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    401\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    402\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mCANCELLED\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCANCELLED_AND_NOTIFIED\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.5/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    291\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    292\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 293\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    294\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_df = pd.read_csv('../data/processed/sklearn/train50_50_38.csv')\n",
    "X_all = train_df.drop(['state', 'name'], axis=1)\n",
    "y_all = pd.DataFrame(train_df['state'])\n",
    "groups = train_df['name']\n",
    "\n",
    "results = run_nested_logo(X_all, y_all, train_df, groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'GridSearchCV' object has no attribute 'best_params_'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-daa77ebf4c4a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[0;31m# f1, f1_macro, f1_micro, grid_obj = evaluate_model(X_train, y_train, X_test, y_test, grid_obj)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrid_obj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_params_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     82\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrid_obj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_score_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'GridSearchCV' object has no attribute 'best_params_'"
     ]
    }
   ],
   "source": [
    "# Code running experiments with different models and parameters\n",
    "import pandas as pd\n",
    "from pandas import read_csv\n",
    "from pandas import DataFrame\n",
    "from sklearn.metrics import balanced_accuracy_score, f1_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.naive_bayes import ComplementNB\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from numpy import argmax\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "# GridSearchCV results for all algorithms\n",
    "# GridSearchCV with the best combination for all algorithms\n",
    "from sklearn.model_selection import LeaveOneGroupOut\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "train_df = pd.read_csv('../data/processed/train.csv')\n",
    "test_df = pd.read_csv('../data/processed/test.csv')\n",
    "\n",
    "X_train = train_df.drop(['state', 'name'], axis=1)\n",
    "y_train = pd.DataFrame(train_df['state'])\n",
    "\n",
    "X_test = test_df.drop(['state', 'name'], axis=1)\n",
    "y_test = pd.DataFrame(test_df['state'])\n",
    "\n",
    "groups = train_df['name']\n",
    "\n",
    "def evaluate_model(trainX, trainy, testX, testy, model):\n",
    "    trainy, testy = trainy[:,0], testy[:,0]\n",
    "\n",
    "    # fit the model\n",
    "    model.fit(trainX, trainy)\n",
    "    # make predictions\n",
    "    yhat = model.predict(testX)\n",
    "\n",
    "#     hat, test = 0,0\n",
    "#     for i in range(len(yhat)):\n",
    "#         if yhat[i] == 0:\n",
    "#             hat += 1\n",
    "#         if testy[i][0] == 0:\n",
    "#             test += 1\n",
    "#     print('hat', hat)\n",
    "#     print('test', test)\n",
    "    # evaluate predictions\n",
    "#     accuracy = balanced_accuracy_score(testy, yhat)\n",
    "    f1_macro = f1_score(testy, yhat, average='macro')\n",
    "    f1_micro = f1_score(testy, yhat, average='micro')\n",
    "    f1 = f1_score(testy, yhat, average=None)\n",
    "\n",
    "#     print('accuracy:', accuracy)\n",
    "#     print(classification_report(testy, yhat))\n",
    "#     print(confusion_matrix(testy, yhat))\n",
    "    return f1, f1_macro, f1_micro, model\n",
    "\n",
    "logo = LeaveOneGroupOut()\n",
    "clf = RandomForestClassifier()\n",
    "params = {'n_estimators': [10, 100, 200],\n",
    "           'max_depth': [None, 50, 80],\n",
    "           'min_samples_leaf': [1, 5],\n",
    "           'min_samples_split': [2, 8, 10],\n",
    "           'max_features': ['log2', 'sqrt','auto', None], \n",
    "           'criterion': ['entropy', 'gini']}\n",
    "\n",
    "grid_obj = GridSearchCV(clf, params, scoring='f1_macro', cv=logo.split(X_train, groups=groups), n_jobs=1)\n",
    "# grid_obj.fit(X_train, y_train)\n",
    "# f1, f1_macro, f1_micro, grid_obj = evaluate_model(X_train, y_train, X_test, y_test, grid_obj)\n",
    "\n",
    "print(grid_obj.best_params_)\n",
    "print(grid_obj.best_score_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded 34954\n",
      "stacked (34954, 50, 3)\n",
      "../data/processed/train/subjects_train_50_50_40.csv\n",
      "done\n",
      "(34954, 50, 3) (34954, 1)\n",
      "loaded 1117\n",
      "stacked (1117, 50, 3)\n",
      "../data/processed/test/subjects_test_50_50_40.csv\n",
      "done\n",
      "Train on 34954 samples\n",
      "Epoch 1/20\n",
      "34954/34954 [==============================] - 8s 242us/sample - loss: 0.8997 - categorical_accuracy: 0.6176\n",
      "Epoch 2/20\n",
      "34954/34954 [==============================] - 9s 246us/sample - loss: 0.5801 - categorical_accuracy: 0.7670\n",
      "Epoch 3/20\n",
      "34954/34954 [==============================] - 8s 222us/sample - loss: 0.5338 - categorical_accuracy: 0.8018\n",
      "Epoch 4/20\n",
      "34954/34954 [==============================] - 8s 217us/sample - loss: 0.5068 - categorical_accuracy: 0.8269\n",
      "Epoch 5/20\n",
      "34954/34954 [==============================] - 7s 205us/sample - loss: 0.4739 - categorical_accuracy: 0.8442\n",
      "Epoch 6/20\n",
      "34954/34954 [==============================] - 7s 210us/sample - loss: 0.4487 - categorical_accuracy: 0.8551\n",
      "Epoch 7/20\n",
      "34954/34954 [==============================] - 7s 206us/sample - loss: 0.4246 - categorical_accuracy: 0.8634\n",
      "Epoch 8/20\n",
      "34954/34954 [==============================] - 7s 213us/sample - loss: 0.4106 - categorical_accuracy: 0.8706\n",
      "Epoch 9/20\n",
      "34954/34954 [==============================] - 7s 214us/sample - loss: 0.4009 - categorical_accuracy: 0.8723\n",
      "Epoch 10/20\n",
      "34954/34954 [==============================] - 8s 218us/sample - loss: 0.3907 - categorical_accuracy: 0.8748\n",
      "Epoch 11/20\n",
      "34954/34954 [==============================] - 8s 217us/sample - loss: 0.3844 - categorical_accuracy: 0.8778\n",
      "Epoch 12/20\n",
      "34954/34954 [==============================] - 8s 215us/sample - loss: 0.3792 - categorical_accuracy: 0.8802\n",
      "Epoch 13/20\n",
      "34954/34954 [==============================] - 7s 210us/sample - loss: 0.3751 - categorical_accuracy: 0.8822\n",
      "Epoch 14/20\n",
      "34954/34954 [==============================] - 7s 213us/sample - loss: 0.3694 - categorical_accuracy: 0.8847\n",
      "Epoch 15/20\n",
      "34954/34954 [==============================] - 8s 218us/sample - loss: 0.3639 - categorical_accuracy: 0.8864\n",
      "Epoch 16/20\n",
      "34954/34954 [==============================] - 8s 217us/sample - loss: 0.3624 - categorical_accuracy: 0.8857\n",
      "Epoch 17/20\n",
      "34954/34954 [==============================] - 7s 210us/sample - loss: 0.3595 - categorical_accuracy: 0.8849\n",
      "Epoch 18/20\n",
      "34954/34954 [==============================] - 8s 215us/sample - loss: 0.3518 - categorical_accuracy: 0.8893\n",
      "Epoch 19/20\n",
      "34954/34954 [==============================] - 8s 217us/sample - loss: 0.3518 - categorical_accuracy: 0.8868\n",
      "Epoch 20/20\n",
      "34954/34954 [==============================] - 7s 212us/sample - loss: 0.3493 - categorical_accuracy: 0.8896\n",
      "1117/1117 [==============================] - 0s 135us/sample - loss: 0.3089 - categorical_accuracy: 0.9105\n"
     ]
    }
   ],
   "source": [
    "source = '../data/processed/'\n",
    "trainX, trainy, testX, testy, subjects = load_dataset(comb='50_50_40', prefix=source)\n",
    "trainy = to_categorical(trainy)\n",
    "y_true = testy\n",
    "testy = to_categorical(testy)\n",
    "n_timesteps, n_features, n_outputs = trainX.shape[1], trainX.shape[2], trainy.shape[1]\n",
    "\n",
    "# lstm = Sequential()\n",
    "# lstm.add(LSTM(100, input_shape=(n_timesteps,n_features)))\n",
    "# lstm.add(Dropout(0.5))\n",
    "# lstm.add(Dense(50, activation='relu'))\n",
    "# lstm.add(Dense(n_outputs, activation='softmax'))\n",
    "# lstm.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['categorical_accuracy'])\n",
    "\n",
    "mlp = Sequential()\n",
    "mlp.add(Dense(50, input_shape=(n_timesteps,n_features)))\n",
    "mlp.add(Dropout(0.5))\n",
    "mlp.add(Dense(50, activation='relu'))\n",
    "mlp.add(Flatten())\n",
    "mlp.add(Dense(n_outputs, activation='softmax'))\n",
    "mlp.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['categorical_accuracy'])\n",
    "\n",
    "verbose, epochs, batch_size = 1, 20, 10\n",
    "mlp.fit(trainX, trainy, epochs=epochs, batch_size=batch_size, verbose=verbose)\n",
    "# evaluate model\n",
    "_, accuracy = mlp.evaluate(testX, testy, batch_size=batch_size, verbose=1)\n",
    "prediction = mlp.predict_classes(testX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.95      0.95       389\n",
      "           1       0.98      0.93      0.96       633\n",
      "           2       0.50      0.75      0.60        53\n",
      "           3       0.35      0.45      0.40        42\n",
      "\n",
      "    accuracy                           0.91      1117\n",
      "   macro avg       0.70      0.77      0.73      1117\n",
      "weighted avg       0.93      0.91      0.92      1117\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_true, prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code running experiments with different models and parameters\n",
    "import pandas as pd\n",
    "from pandas import read_csv\n",
    "from pandas import DataFrame\n",
    "from sklearn.metrics import balanced_accuracy_score, f1_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.naive_bayes import ComplementNB\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from numpy import argmax\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "# GridSearchCV results for all algorithms\n",
    "# GridSearchCV with the best combination for all algorithms\n",
    "from sklearn.model_selection import LeaveOneGroupOut\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "def evaluate_model(trainX, trainy, testX, testy, model):\n",
    "    trainy, testy = trainy[:,0], testy[:,0]\n",
    "\n",
    "    # fit the model\n",
    "#     model.fit(trainX, trainy)\n",
    "    # make predictions\n",
    "    yhat = model.predict(testX)\n",
    "\n",
    "#     hat, test = 0,0\n",
    "#     for i in range(len(yhat)):\n",
    "#         if yhat[i] == 0:\n",
    "#             hat += 1\n",
    "#         if testy[i][0] == 0:\n",
    "#             test += 1\n",
    "#     print('hat', hat)\n",
    "#     print('test', test)\n",
    "    # evaluate predictions\n",
    "#     accuracy = balanced_accuracy_score(testy, yhat)\n",
    "    f1_macro = f1_score(testy, yhat, average='macro')\n",
    "    f1_micro = f1_score(testy, yhat, average='micro')\n",
    "    f1 = f1_score(testy, yhat, average=None)\n",
    "\n",
    "#     print('accuracy:', accuracy)\n",
    "#     print(classification_report(testy, yhat))\n",
    "#     print(confusion_matrix(testy, yhat))\n",
    "    return f1, f1_macro, f1_micro, model\n",
    "\n",
    "def run_nested_logo(X_all, y_all, all_df, groups):\n",
    "    logo = LeaveOneGroupOut()\n",
    "    group = 0\n",
    "\n",
    "    f1s = []\n",
    "    f1_macros = []\n",
    "    f1_micros = []\n",
    "    best_params = []\n",
    "    best_scores = []\n",
    "\n",
    "    clf = GradientBoostingClassifier()\n",
    "    params = {'n_estimators': [300],\n",
    "              'learning_rate': [0.1],\n",
    "              'min_samples_split': [2],\n",
    "              'max_features': ['auto'],\n",
    "              'min_samples_leaf': [10]}\n",
    "#               'max_samples': [1, 5, 10],\n",
    "#               'max_features': [50, 100]}\n",
    "#               'oob_score': [False, True]}\n",
    "#                'bootstrap': [True, False],\n",
    "#                'max_depth': [50],\n",
    "#                'min_samples_split': [2],\n",
    "#                'max_features': ['log2'], \n",
    "#                'criterion': ['gini']}\n",
    "    for train_index, test_index in logo.split(X_all, groups=groups):\n",
    "        group += 1\n",
    "        X_train, X_test = X_all.values[train_index], X_all.values[test_index]\n",
    "        y_train, y_test = y_all.values[train_index], y_all.values[test_index]\n",
    "        \n",
    "        inner_groups = all_df.iloc[all_df.index.isin(train_index)]['name']\n",
    "\n",
    "        grid_obj = GridSearchCV(clf, params, scoring='f1_macro', cv=logo.split(X_train, groups=inner_groups), n_jobs=-1)\n",
    "        f1, f1_macro, f1_micro, grid_obj = evaluate_model(X_train, y_train, X_test, y_test, grid_obj.best_estimator_)\n",
    "        best_params.append(grid_obj.best_params_)\n",
    "        best_scores.append(grid_obj.best_score_)\n",
    "    group += 1\n",
    "        \n",
    "    print(best_params)\n",
    "    print(best_scores)\n",
    "    return grid_obj, best_params, best_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/elizabeth/education/chair_sensor/ml_project/venv/lib/python3.5/site-packages/sklearn/model_selection/_search.py:813: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n",
      "/home/elizabeth/education/chair_sensor/ml_project/venv/lib/python3.5/site-packages/sklearn/model_selection/_search.py:813: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n",
      "/home/elizabeth/education/chair_sensor/ml_project/venv/lib/python3.5/site-packages/sklearn/model_selection/_search.py:813: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n",
      "/home/elizabeth/education/chair_sensor/ml_project/venv/lib/python3.5/site-packages/sklearn/model_selection/_search.py:813: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n",
      "/home/elizabeth/education/chair_sensor/ml_project/venv/lib/python3.5/site-packages/sklearn/model_selection/_search.py:813: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n",
      "/home/elizabeth/education/chair_sensor/ml_project/venv/lib/python3.5/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/elizabeth/education/chair_sensor/ml_project/venv/lib/python3.5/site-packages/sklearn/model_selection/_search.py:813: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n",
      "/home/elizabeth/education/chair_sensor/ml_project/venv/lib/python3.5/site-packages/sklearn/model_selection/_search.py:813: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n",
      "/home/elizabeth/education/chair_sensor/ml_project/venv/lib/python3.5/site-packages/sklearn/model_selection/_search.py:813: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n",
      "/home/elizabeth/education/chair_sensor/ml_project/venv/lib/python3.5/site-packages/sklearn/model_selection/_search.py:813: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'min_samples_leaf': 10, 'n_estimators': 300, 'min_samples_split': 2, 'learning_rate': 0.1, 'max_features': 'auto'}, {'min_samples_leaf': 10, 'n_estimators': 300, 'min_samples_split': 2, 'learning_rate': 0.1, 'max_features': 'auto'}, {'min_samples_leaf': 10, 'n_estimators': 300, 'min_samples_split': 2, 'learning_rate': 0.1, 'max_features': 'auto'}, {'min_samples_leaf': 10, 'n_estimators': 300, 'min_samples_split': 2, 'learning_rate': 0.1, 'max_features': 'auto'}, {'min_samples_leaf': 10, 'n_estimators': 300, 'min_samples_split': 2, 'learning_rate': 0.1, 'max_features': 'auto'}, {'min_samples_leaf': 10, 'n_estimators': 300, 'min_samples_split': 2, 'learning_rate': 0.1, 'max_features': 'auto'}, {'min_samples_leaf': 10, 'n_estimators': 300, 'min_samples_split': 2, 'learning_rate': 0.1, 'max_features': 'auto'}, {'min_samples_leaf': 10, 'n_estimators': 300, 'min_samples_split': 2, 'learning_rate': 0.1, 'max_features': 'auto'}, {'min_samples_leaf': 10, 'n_estimators': 300, 'min_samples_split': 2, 'learning_rate': 0.1, 'max_features': 'auto'}]\n",
      "[0.6362071273678369, 0.6805879727381103, 0.6660963299212236, 0.6636815756339224, 0.737430502932228, 0.6832686103392462, 0.6879097352507713, 0.6768014934834136, 0.6846125056903755]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "train_df = pd.read_csv('../data/processed/sklearn/train50_25_13.csv')\n",
    "X_all = train_df.drop(['state', 'name'], axis=1)\n",
    "y_all = pd.DataFrame(train_df['state'])\n",
    "groups = train_df['name']\n",
    "\n",
    "results = run_nested_logo(X_all, y_all, train_df, groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Correct way to do nested LOOCV\n",
    "# nested LOOCV with the all combis and hyperparameter tuning\n",
    "from sklearn.model_selection import LeaveOneGroupOut\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from os import listdir\n",
    "from os import path\n",
    "import re\n",
    "import csv\n",
    "\n",
    "def evaluate_model(trainX, trainy, testX, testy, model):\n",
    "    trainy, testy = trainy[:,0], testy[:,0]\n",
    "\n",
    "    # fit the model\n",
    "    model.fit(trainX, trainy)\n",
    "    # make predictions\n",
    "    yhat = model.predict(testX)\n",
    "\n",
    "#     hat, test = 0,0\n",
    "#     for i in range(len(yhat)):\n",
    "#         if yhat[i] == 0:\n",
    "#             hat += 1\n",
    "#         if testy[i][0] == 0:\n",
    "#             test += 1\n",
    "#     print('hat', hat)\n",
    "#     print('test', test)\n",
    "    # evaluate predictions\n",
    "#     accuracy = balanced_accuracy_score(testy, yhat)\n",
    "    f1_macro = f1_score(testy, yhat, average='macro')\n",
    "    f1 = f1_score(testy, yhat, average=None)\n",
    "\n",
    "#     print('accuracy:', accuracy)\n",
    "#     print(classification_report(testy, yhat))\n",
    "#     print(confusion_matrix(testy, yhat))\n",
    "    return f1, f1_macro, model\n",
    "\n",
    "def run_nested_logo(source, dest, key):\n",
    "    logo = LeaveOneGroupOut()\n",
    "\n",
    "    i = 1\n",
    "    \n",
    "    done = ['30_15_4', '10_5_1', '5_3_2', '60_30_8', '60_90_0', '5_5_4', '30_45_23',\n",
    "        '5_5_0', '30_30_8', '60_90_68', '50_100_75', '30_30_15', '60_120_90',\n",
    "        '10_10_8', '10_20_0', '30_15_0', '60_30_23', '50_25_0', '50_25_6', '30_45_0',\n",
    "        '5_10_8', '30_15_11']\n",
    "    \n",
    "    for name in listdir(source):\n",
    "        filename = source + '/' + name\n",
    "        if not name.endswith('csv') or not name.startswith('train'):\n",
    "            continue\n",
    "        pattern = 'train' + '[0-9]*[0-9]_[0-9]*[0-9]_[0-9]*[0-9]' + '.csv'\n",
    "        match = re.search(pattern, name)\n",
    "        if not match:\n",
    "            continue\n",
    "\n",
    "        combi = re.search('train(.+?).csv', name)\n",
    "        print(combi)\n",
    "        if combi:\n",
    "            combi = combi.group(1)\n",
    "        print(combi)            \n",
    "            \n",
    "        print(i, 'out of 79 files')\n",
    "        print('Reading file', name)\n",
    "\n",
    "        all_df = pd.read_csv(filename)\n",
    "\n",
    "        X_all = all_df.drop(['state', 'name'], axis=1)\n",
    "        y_all = pd.DataFrame(all_df['state'])\n",
    "        groups = all_df['name']\n",
    "\n",
    "        # counting the number of samples per class\n",
    "        freq = [0,0,0,0]\n",
    "        for val in y_all['state']:\n",
    "            freq[val] += 1\n",
    "\n",
    "        print('class frequencies', freq)\n",
    "    \n",
    "        group = 0\n",
    "        \n",
    "        f1s = []\n",
    "        f1_macros = []\n",
    "        best_params = []\n",
    "        best_scores = []\n",
    "    \n",
    "        for train_index, test_index in logo.split(X_all, groups=groups):\n",
    "            X_train, X_test = X_all.values[train_index], X_all.values[test_index]\n",
    "            y_train, y_test = y_all.values[train_index], y_all.values[test_index]\n",
    "\n",
    "            inner_groups = all_df.iloc[all_df.index.isin(train_index)]['name']\n",
    "\n",
    "            clf = GradientBoostingClassifier()\n",
    "            params={}\n",
    "#             params = {'learning_rate': [0.1, 0.2, 0.4],\n",
    "#                       'criterion': ['friedman_mse', 'mae'],\n",
    "#                       'max_depth': [3, 6, 9],\n",
    "#                       'max_features': ['auto', 'sqrt', 'log2', None],\n",
    "#                       'validation_fraction': [0.1, 0.3]}\n",
    "            grid_obj = RandomizedSearchCV(clf, params, scoring='f1_macro', cv=logo.split(X_train, groups=inner_groups), n_iter=5, n_jobs=-1)\n",
    "            f1, f1_macro, grid_obj = evaluate_model(X_train, y_train, X_test, y_test, grid_obj)\n",
    "            print('Group', group)\n",
    "            print(grid_obj.best_params_)\n",
    "            print(f1)\n",
    "            print('macro', f1_macro)\n",
    "            print(grid_obj.best_score_)\n",
    "            f1s.append(f1)\n",
    "            f1_macros.append(f1_macro)\n",
    "            best_params.append(grid_obj.best_params_)\n",
    "            best_scores.append(grid_obj.best_score_)\n",
    "                        \n",
    "            group += 1\n",
    "\n",
    "        header = ['comb']\n",
    "        row = [combi]\n",
    "        \n",
    "        # create header\n",
    "        for j in range(9):\n",
    "            header.append('f1-0'+'.'+str(j))\n",
    "            header.append('f1-1'+'.'+str(j))\n",
    "            header.append('f1-2'+'.'+str(j))\n",
    "            header.append('f1-3'+'.'+str(j))\n",
    "            header.append('macro'+'.'+str(j))\n",
    "            header.append('best_score_'+'.'+str())\n",
    "            header.append('hyper'+'.'+str(j))\n",
    "            \n",
    "            row.extend(f1s[j])\n",
    "            row.append(f1_macros[j])\n",
    "            row.append(best_scores[j])\n",
    "            row.append(best_params[j])\n",
    "\n",
    "        outFilename = dest + '/' + key + '.csv'\n",
    "        if not path.isfile(outFilename):\n",
    "            print('creating new file', outFilename)\n",
    "            with open(outFilename, 'w') as outFile:\n",
    "                writer = csv.writer(outFile)\n",
    "                writer.writerow(header)\n",
    "                writer.writerow(row)\n",
    "                outFile.close()\n",
    "        else:\n",
    "            print('opening existing file', outFilename)\n",
    "            with open(outFilename, 'a+') as outFile:\n",
    "                writer = csv.writer(outFile)\n",
    "                writer.writerow(row)\n",
    "                outFile.close()\n",
    "        i += 1\n",
    "#     return np.average(f1s, axis=0).tolist(), [np.average(f1_macros).tolist()], [np.average(f1_micros).tolist()], best_params, best_scores\n",
    "    return 0\n",
    "\n",
    "source = '../data/processed/sklearn/'\n",
    "dest = 'results/'\n",
    "run_nested_logo(source, dest, 'gbm')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# experiments keras neural network models\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from numpy import dstack\n",
    "import numpy as np\n",
    "from pandas import read_csv\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from keras.utils import to_categorical\n",
    "from keras.layers import Bidirectional\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
    "\n",
    "from matplotlib import pyplot\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load a single file as a numpy array\n",
    "def load_file(filepath):\n",
    "    dataframe = read_csv(filepath, header=None)\n",
    "    return dataframe.values\n",
    "\n",
    "# load a list of files and return as a 3d numpy array\n",
    "def load_group(filenames, prefix=''):\n",
    "    loaded = list()\n",
    "    for name in filenames:\n",
    "        data = load_file(prefix + name)\n",
    "        loaded.append(data)\n",
    "    # stack group so that features are the 3rd dimension\n",
    "    print('loaded', len(loaded[0]))\n",
    "#     print('loaded', loaded)\n",
    "    loaded = dstack(loaded)\n",
    "    print('stacked', loaded.shape)\n",
    "#     print('stacked', loaded)\n",
    "    return loaded\n",
    "\n",
    "# load a dataset group, such as train or test\n",
    "def load_dataset_group(group, comb, prefix=''):\n",
    "#     filepath = prefix + group + '/keras/'\n",
    "#     prefix = prefix + group + '/'\n",
    "    prefix = prefix + '/'\n",
    "    # load all 9 files as a single array\n",
    "    filenames = list()\n",
    "    # total acceleration\n",
    "    filenames += ['total_acc_x_'+group+'_'+comb+'.csv', 'total_acc_y_'+group+'_'+comb+'.csv', 'total_acc_z_'+group+'_'+comb+'.csv']\n",
    "    # load input data\n",
    "    X = load_group(filenames, prefix)\n",
    "    # load class output\n",
    "    y = load_file(prefix + 'state_'+group+'_'+comb+'.csv')\n",
    "    path = prefix + 'subjects_' + group + '_' +comb+'.csv'\n",
    "    print(path)\n",
    "    subjects = read_csv(path, header=None)\n",
    "    print('done')\n",
    "    return X, y, subjects\n",
    "\n",
    "# load the dataset, returns train and test X and y elements\n",
    "def load_dataset(comb,  prefix=''):\n",
    "    # load all train\n",
    "    trainX, trainy, subjects = load_dataset_group('train', comb, prefix)\n",
    "    print(trainX.shape, trainy.shape)\n",
    "    # load all test\n",
    "#     testX, testy, subjects = load_dataset_group('test', comb, prefix)\n",
    "#     print(testX.shape, testy.shape)\n",
    "    # zero-offset class values\n",
    "#     trainy = trainy - 1\n",
    "#     testy = testy - 1\n",
    "    # one hot encode y\n",
    "#     trainy = to_categorical(trainy)\n",
    "#     y_true = testy\n",
    "#     testy = to_categorical(testy)\n",
    "#     print(trainX.shape, trainy.shape)\n",
    "#     return trainX, trainy, testX, testy, subjects\n",
    "    return trainX, trainy, subjects\n",
    "\n",
    "\n",
    "# summarize scores\n",
    "def summarize_results(scores):\n",
    "    print(scores)\n",
    "    m, s = mean(scores), std(scores)\n",
    "    print('Accuracy: %.3f%% (+/-%.3f)' % (m, s))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<_sre.SRE_Match object; span=(12, 30), match='train_50_50_38.csv'>\n",
      "50_50_38\n",
      "1 out of 79 files\n",
      "Reading file total_acc_x_train_50_50_38.csv\n",
      "loaded 30067\n",
      "stacked (30067, 50, 3)\n",
      "../data/processed/train/keras/done//subjects_train_50_50_38.csv\n",
      "done\n",
      "(30067, 50, 3) (30067, 1)\n",
      "3\n",
      "50\n",
      "1\n",
      "OKKKK\n",
      "YOOOO\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/elizabeth/education/chair_sensor/ml_project/venv/lib/python3.5/site-packages/sklearn/model_selection/_search.py:813: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 24986 samples\n",
      "Epoch 1/20\n",
      "24986/24986 [==============================] - 38s 2ms/sample - loss: 4.8561 - categorical_accuracy: 0.2201\n",
      "Epoch 2/20\n",
      "24986/24986 [==============================] - 37s 1ms/sample - loss: 14.9260 - categorical_accuracy: 0.0040\n",
      "Epoch 3/20\n",
      "24986/24986 [==============================] - 37s 1ms/sample - loss: 14.8892 - categorical_accuracy: 0.0043\n",
      "Epoch 4/20\n",
      "24986/24986 [==============================] - 37s 1ms/sample - loss: 14.9157 - categorical_accuracy: 0.0052\n",
      "Epoch 5/20\n",
      "24986/24986 [==============================] - 37s 1ms/sample - loss: 14.9415 - categorical_accuracy: 0.0050\n",
      "Epoch 6/20\n",
      "24986/24986 [==============================] - 37s 1ms/sample - loss: 14.9318 - categorical_accuracy: 0.0043\n",
      "Epoch 7/20\n",
      "24986/24986 [==============================] - 37s 1ms/sample - loss: 14.9305 - categorical_accuracy: 0.0048\n",
      "Epoch 8/20\n",
      "24986/24986 [==============================] - 37s 1ms/sample - loss: 14.9189 - categorical_accuracy: 0.0038\n",
      "Epoch 9/20\n",
      "24986/24986 [==============================] - 37s 1ms/sample - loss: 14.9369 - categorical_accuracy: 0.0038\n",
      "Epoch 10/20\n",
      "24986/24986 [==============================] - 37s 1ms/sample - loss: 14.9292 - categorical_accuracy: 0.0045\n",
      "Epoch 11/20\n",
      "24986/24986 [==============================] - 37s 1ms/sample - loss: 14.9073 - categorical_accuracy: 0.0043\n",
      "Epoch 12/20\n",
      "24986/24986 [==============================] - 37s 1ms/sample - loss: 14.9408 - categorical_accuracy: 0.0039\n",
      "Epoch 13/20\n",
      "24986/24986 [==============================] - 37s 1ms/sample - loss: 14.9228 - categorical_accuracy: 0.0040\n",
      "Epoch 14/20\n",
      "24986/24986 [==============================] - 37s 1ms/sample - loss: 14.9292 - categorical_accuracy: 0.0040\n",
      "Epoch 15/20\n",
      "24986/24986 [==============================] - 37s 1ms/sample - loss: 14.9389 - categorical_accuracy: 0.0040\n",
      "Epoch 16/20\n",
      "24986/24986 [==============================] - 37s 1ms/sample - loss: 14.8944 - categorical_accuracy: 0.0038\n",
      "Epoch 17/20\n",
      "24986/24986 [==============================] - 37s 1ms/sample - loss: 14.9260 - categorical_accuracy: 0.0045\n",
      "Epoch 18/20\n",
      "24986/24986 [==============================] - 37s 1ms/sample - loss: 14.9202 - categorical_accuracy: 0.0048\n",
      "Epoch 19/20\n",
      "24986/24986 [==============================] - 37s 1ms/sample - loss: 14.9298 - categorical_accuracy: 0.0044\n",
      "Epoch 20/20\n",
      "24986/24986 [==============================] - 37s 1ms/sample - loss: 14.9066 - categorical_accuracy: 0.0047\n",
      "5081/5081 [==============================] - 3s 635us/sample\n",
      "Group 0\n",
      "{'epochs': 20, 'batch_size': 10}\n",
      "[0.         0.         0.11814815 0.        ]\n",
      "macro 0.029537037037037035\n",
      "0.225163857440014\n",
      "3\n",
      "50\n",
      "1\n",
      "OKKKK\n",
      "YOOOO\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/elizabeth/education/chair_sensor/ml_project/venv/lib/python3.5/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/elizabeth/education/chair_sensor/ml_project/venv/lib/python3.5/site-packages/sklearn/model_selection/_search.py:813: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 26799 samples\n",
      "Epoch 1/20\n",
      "26799/26799 [==============================] - 40s 1ms/sample - loss: 3.2275 - categorical_accuracy: 0.2025\n",
      "Epoch 2/20\n",
      "26799/26799 [==============================] - 39s 1ms/sample - loss: 8.9140 - categorical_accuracy: 0.0742\n",
      "Epoch 3/20\n",
      "26799/26799 [==============================] - 39s 1ms/sample - loss: 8.8929 - categorical_accuracy: 0.0749\n",
      "Epoch 4/20\n",
      "26799/26799 [==============================] - 39s 1ms/sample - loss: 8.9759 - categorical_accuracy: 0.0744\n",
      "Epoch 5/20\n",
      "26799/26799 [==============================] - 39s 1ms/sample - loss: 8.8893 - categorical_accuracy: 0.0766\n",
      "Epoch 6/20\n",
      "26799/26799 [==============================] - 39s 1ms/sample - loss: 8.9134 - categorical_accuracy: 0.0741\n",
      "Epoch 7/20\n",
      "26799/26799 [==============================] - 39s 1ms/sample - loss: 8.9525 - categorical_accuracy: 0.0777\n",
      "Epoch 8/20\n",
      "26799/26799 [==============================] - 39s 1ms/sample - loss: 8.9278 - categorical_accuracy: 0.0755\n",
      "Epoch 9/20\n",
      "26799/26799 [==============================] - 39s 1ms/sample - loss: 8.9441 - categorical_accuracy: 0.0744\n",
      "Epoch 10/20\n",
      "26799/26799 [==============================] - 39s 1ms/sample - loss: 8.9278 - categorical_accuracy: 0.0729\n",
      "Epoch 11/20\n",
      "26799/26799 [==============================] - 39s 1ms/sample - loss: 8.9034 - categorical_accuracy: 0.1173\n",
      "Epoch 12/20\n",
      "26799/26799 [==============================] - 39s 1ms/sample - loss: 9.3561 - categorical_accuracy: 0.6990\n",
      "Epoch 13/20\n",
      "26799/26799 [==============================] - 39s 1ms/sample - loss: 9.2833 - categorical_accuracy: 0.6953\n",
      "Epoch 14/20\n",
      "26799/26799 [==============================] - 40s 1ms/sample - loss: 9.3543 - categorical_accuracy: 0.6932\n",
      "Epoch 15/20\n",
      "26799/26799 [==============================] - 39s 1ms/sample - loss: 9.3747 - categorical_accuracy: 0.6954\n",
      "Epoch 16/20\n",
      "26799/26799 [==============================] - 39s 1ms/sample - loss: 9.3531 - categorical_accuracy: 0.6976\n",
      "Epoch 17/20\n",
      "26799/26799 [==============================] - 39s 1ms/sample - loss: 9.3428 - categorical_accuracy: 0.7023\n",
      "Epoch 18/20\n",
      "26799/26799 [==============================] - 40s 1ms/sample - loss: 9.3494 - categorical_accuracy: 0.6909\n",
      "Epoch 19/20\n",
      "26799/26799 [==============================] - 39s 1ms/sample - loss: 9.3861 - categorical_accuracy: 0.6973\n",
      "Epoch 20/20\n",
      "26799/26799 [==============================] - 39s 1ms/sample - loss: 9.3025 - categorical_accuracy: 0.6905\n",
      "3268/3268 [==============================] - 2s 642us/sample\n",
      "Group 1\n",
      "{'epochs': 20, 'batch_size': 10}\n",
      "[0.5539823 0.        0.        0.       ]\n",
      "macro 0.13849557522123893\n",
      "0.3563785752961103\n",
      "3\n",
      "50\n",
      "1\n",
      "OKKKK\n",
      "YOOOO\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/elizabeth/education/chair_sensor/ml_project/venv/lib/python3.5/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "E0801 22:30:09.614862 140475848558336 ultratb.py:149] Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/elizabeth/education/chair_sensor/ml_project/venv/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 3291, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-88-3234e7623080>\", line 195, in <module>\n",
      "    run_nested_logo(source, dest, 'lstm')\n",
      "  File \"<ipython-input-88-3234e7623080>\", line 143, in run_nested_logo\n",
      "    f1, f1_macro, grid_obj = evaluate_model(X_train, y_train, X_test, y_test, grid_obj)\n",
      "  File \"<ipython-input-88-3234e7623080>\", line 19, in evaluate_model\n",
      "    model.fit(trainX, trainy)\n",
      "  File \"/home/elizabeth/education/chair_sensor/ml_project/venv/lib/python3.5/site-packages/sklearn/model_selection/_search.py\", line 687, in fit\n",
      "    self._run_search(evaluate_candidates)\n",
      "  File \"/home/elizabeth/education/chair_sensor/ml_project/venv/lib/python3.5/site-packages/sklearn/model_selection/_search.py\", line 1468, in _run_search\n",
      "    random_state=self.random_state))\n",
      "  File \"/home/elizabeth/education/chair_sensor/ml_project/venv/lib/python3.5/site-packages/sklearn/model_selection/_search.py\", line 666, in evaluate_candidates\n",
      "    cv.split(X, y, groups)))\n",
      "  File \"/home/elizabeth/education/chair_sensor/ml_project/venv/lib/python3.5/site-packages/joblib/parallel.py\", line 934, in __call__\n",
      "    self.retrieve()\n",
      "  File \"/home/elizabeth/education/chair_sensor/ml_project/venv/lib/python3.5/site-packages/joblib/parallel.py\", line 833, in retrieve\n",
      "    self._output.extend(job.get(timeout=self.timeout))\n",
      "  File \"/home/elizabeth/education/chair_sensor/ml_project/venv/lib/python3.5/site-packages/joblib/_parallel_backends.py\", line 521, in wrap_future_result\n",
      "    return future.result(timeout=timeout)\n",
      "  File \"/usr/lib/python3.5/concurrent/futures/_base.py\", line 400, in result\n",
      "    self._condition.wait(timeout)\n",
      "  File \"/usr/lib/python3.5/threading.py\", line 293, in wait\n",
      "    waiter.acquire()\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/elizabeth/education/chair_sensor/ml_project/venv/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2033, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/elizabeth/education/chair_sensor/ml_project/venv/lib/python3.5/site-packages/IPython/core/ultratb.py\", line 1095, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"/home/elizabeth/education/chair_sensor/ml_project/venv/lib/python3.5/site-packages/IPython/core/ultratb.py\", line 313, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/home/elizabeth/education/chair_sensor/ml_project/venv/lib/python3.5/site-packages/IPython/core/ultratb.py\", line 347, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"/usr/lib/python3.5/inspect.py\", line 1454, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"/usr/lib/python3.5/inspect.py\", line 1411, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"/usr/lib/python3.5/inspect.py\", line 671, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"/usr/lib/python3.5/inspect.py\", line 708, in getmodule\n",
      "    if ismodule(module) and hasattr(module, '__file__'):\n",
      "  File \"/home/elizabeth/education/chair_sensor/ml_project/venv/lib/python3.5/site-packages/tensorflow/__init__.py\", line 49, in __getattr__\n",
      "    module = self._load()\n",
      "  File \"/home/elizabeth/education/chair_sensor/ml_project/venv/lib/python3.5/site-packages/tensorflow/__init__.py\", line 43, in _load\n",
      "    module = _importlib.import_module(self.__name__)\n",
      "  File \"/home/elizabeth/education/chair_sensor/ml_project/venv/lib/python3.5/importlib/__init__.py\", line 126, in import_module\n",
      "    return _bootstrap._gcd_import(name[level:], package, level)\n",
      "  File \"<frozen importlib._bootstrap>\", line 986, in _gcd_import\n",
      "  File \"<frozen importlib._bootstrap>\", line 969, in _find_and_load\n",
      "  File \"<frozen importlib._bootstrap>\", line 956, in _find_and_load_unlocked\n",
      "ImportError: No module named 'tensorflow_core.contrib'\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m"
     ]
    }
   ],
   "source": [
    "## Correct way to do nested LOOCV\n",
    "# nested LOOCV with the all combis and hyperparameter tuning\n",
    "from sklearn.model_selection import LeaveOneGroupOut\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.metrics import f1_score\n",
    "from os import listdir\n",
    "from os import path\n",
    "import re\n",
    "import csv\n",
    "\n",
    "n_features, n_timesteps = 1, 2\n",
    "\n",
    "def evaluate_model(trainX, trainy, testX, testy, model):\n",
    "#     trainy, testy = trainy[:,0], testy[:,0]\n",
    "    print('YOOOO')\n",
    "\n",
    "    # fit the model\n",
    "    model.fit(trainX, trainy)\n",
    "    # make predictions\n",
    "    yhat = model.predict(testX)\n",
    "\n",
    "#     hat, test = 0,0\n",
    "#     for i in range(len(yhat)):\n",
    "#         if yhat[i] == 0:\n",
    "#             hat += 1\n",
    "#         if testy[i][0] == 0:\n",
    "#             test += 1\n",
    "#     print('hat', hat)\n",
    "#     print('test', test)\n",
    "    # evaluate predictions\n",
    "#     accuracy = balanced_accuracy_score(testy, yhat)\n",
    "\n",
    "    f1_macro = f1_score(testy, yhat, average='macro')\n",
    "    f1 = f1_score(testy, yhat, average=None)\n",
    "#     _, accuracy = model.evaluate(testX, testy, verbose=verbose)\n",
    "\n",
    "#     print('accuracy:', accuracy)\n",
    "#     print(classification_report(testy, yhat))\n",
    "#     print(confusion_matrix(testy, yhat))\n",
    "    return f1, f1_macro, model\n",
    "\n",
    "def create_model():\n",
    "    clf = Sequential()\n",
    "    clf.add(LSTM(100, input_shape=(n_timesteps,n_features), activation='relu'))\n",
    "    clf.add(Dropout(0.5))\n",
    "    clf.add(Flatten())\n",
    "    clf.add(Dense(4, activation='softmax'))\n",
    "    clf.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['categorical_accuracy'])\n",
    "\n",
    "    return clf\n",
    "\n",
    "def run_nested_logo(source, dest, key):    \n",
    "    global n_features\n",
    "    global n_timesteps\n",
    "    \n",
    "    logo = LeaveOneGroupOut()\n",
    "\n",
    "    i = 1\n",
    "    \n",
    "    done = ['30_15_4', '10_5_1', '5_3_2', '60_30_8', '60_90_0', '5_5_4', '30_45_23',\n",
    "        '5_5_0', '30_30_8', '60_90_68', '50_100_75', '30_30_15', '60_120_90',\n",
    "        '10_10_8', '10_20_0', '30_15_0', '60_30_23', '50_25_0', '50_25_6', '30_45_0',\n",
    "        '5_10_8', '30_15_11']\n",
    "    \n",
    "    for name in listdir(source):\n",
    "        filename = source + '/' + name\n",
    "        if not name.endswith('csv') or not name.startswith('total_acc_x_train_'):\n",
    "            continue\n",
    "#         pattern = 'total_acc_x_train_' + '[0-9]*[0-9]_[0-9]*[0-9]_[0-9]*[0-9]' + '.csv'\n",
    "        pattern = 'total_acc_x_train_' + '50_50_38' + '.csv'\n",
    "        match = re.search(pattern, name)\n",
    "        if not match:\n",
    "            continue\n",
    "\n",
    "        combi = re.search('train_(.+?).csv', name)\n",
    "        print(combi)\n",
    "        if combi:\n",
    "            combi = combi.group(1)\n",
    "        print(combi)            \n",
    "            \n",
    "        print(i, 'out of 79 files')\n",
    "        print('Reading file', name)\n",
    "        \n",
    "        X_all, y_all, subjects = load_dataset(comb=combi, prefix=source)\n",
    "        # dummy dataset just for logo.split\n",
    "        X_dummy = np.arange(len(X_all))\n",
    "\n",
    "        groups = subjects.iloc[:,0]\n",
    "        \n",
    "#         results = run_logo(trainX, trainy, subjects.iloc[:,0], X_dummy)\n",
    "\n",
    "#         all_df = pd.read_csv(filename)\n",
    "\n",
    "#         X_all = all_df.drop(['state', 'name'], axis=1)\n",
    "#         y_all = pd.DataFrame(all_df['state'])\n",
    "#         groups = all_df['name']\n",
    "\n",
    "        # counting the number of samples per class\n",
    "#         freq = [0,0,0,0]\n",
    "#         for val in y_all['state']:\n",
    "#             freq[val] += 1\n",
    "\n",
    "#         print('class frequencies', freq)\n",
    "    \n",
    "        group = 0\n",
    "        \n",
    "        f1s = []\n",
    "        f1_macros = []\n",
    "        best_params = []\n",
    "        best_scores = []\n",
    "    \n",
    "        for train_index, test_index in logo.split(X_dummy, groups=groups[0:len(X_all)]):\n",
    "            X_train, X_test = X_all[train_index], X_all[test_index]\n",
    "            y_train, y_test = y_all[train_index], y_all[test_index]\n",
    "\n",
    "#             y_train = to_categorical(y_train)\n",
    "            y_true = y_test\n",
    "#             y_test = to_categorical(y_test)\n",
    "            \n",
    "            inner_groups = groups.iloc[groups.index.isin(train_index)]\n",
    "\n",
    "            n_features = X_train.shape[2]\n",
    "            n_timesteps = X_train.shape[1]\n",
    "            \n",
    "            print(n_features)\n",
    "            print(n_timesteps)\n",
    "            print(n_outputs)\n",
    "            clf = KerasClassifier(build_fn=create_model, verbose=1)\n",
    "            \n",
    "#             epochs = [10, 50, 100]\n",
    "#             batches = [10, 20, 40]\n",
    "            epochs = [20]\n",
    "            batches = [10]\n",
    "            dropout = [0.2, 0.5, 0.8]\n",
    "            neurons = [n_features, n_timesteps, 4, 10]\n",
    "            \n",
    "            params = dict(epochs=epochs, batch_size=batches)\n",
    "\n",
    "            grid_obj = RandomizedSearchCV(clf, params, scoring='f1_macro', cv=logo.split(X_train, groups=inner_groups), n_iter=1, n_jobs=-1)\n",
    "#             grid_result = grid_obj.fit(X_train, y_train)\n",
    "            print('OKKKK')\n",
    "            f1, f1_macro, grid_obj = evaluate_model(X_train, y_train, X_test, y_test, grid_obj)\n",
    "            print('Group', group)\n",
    "            print(grid_obj.best_params_)\n",
    "            print(f1)\n",
    "            print('macro', f1_macro)\n",
    "            print(grid_obj.best_score_)\n",
    "            f1s.append(f1)\n",
    "            f1_macros.append(f1_macro)\n",
    "            best_params.append(grid_obj.best_params_)\n",
    "            best_scores.append(grid_obj.best_score_)\n",
    "                        \n",
    "            group += 1\n",
    "\n",
    "        header = ['comb']\n",
    "        row = [combi]\n",
    "        \n",
    "        # create header\n",
    "        for j in range(9):\n",
    "            header.append('f1-0'+'.'+str(j))\n",
    "            header.append('f1-1'+'.'+str(j))\n",
    "            header.append('f1-2'+'.'+str(j))\n",
    "            header.append('f1-3'+'.'+str(j))\n",
    "            header.append('macro'+'.'+str(j))\n",
    "            header.append('best_score_'+'.'+str())\n",
    "            header.append('hyper'+'.'+str(j))\n",
    "            \n",
    "            row.extend(f1s[j])\n",
    "            row.append(f1_macros[j])\n",
    "            row.append(best_scores[j])\n",
    "            row.append(best_params[j])\n",
    "\n",
    "        outFilename = dest + '/' + key + '.csv'\n",
    "        if not path.isfile(outFilename):\n",
    "            print('creating new file', outFilename)\n",
    "            with open(outFilename, 'w') as outFile:\n",
    "                writer = csv.writer(outFile)\n",
    "                writer.writerow(header)\n",
    "                writer.writerow(row)\n",
    "                outFile.close()\n",
    "        else:\n",
    "            print('opening existing file', outFilename)\n",
    "            with open(outFilename, 'a+') as outFile:\n",
    "                writer = csv.writer(outFile)\n",
    "                writer.writerow(row)\n",
    "                outFile.close()\n",
    "        i += 1\n",
    "#     return np.average(f1s, axis=0).tolist(), [np.average(f1_macros).tolist()], [np.average(f1_micros).tolist()], best_params, best_scores\n",
    "    return 0\n",
    "\n",
    "source = '../data/processed/train/keras/done/'\n",
    "dest = 'results/'\n",
    "\n",
    "run_nested_logo(source, dest, 'lstm')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<_sre.SRE_Match object; span=(12, 30), match='train_50_50_38.csv'>\n",
      "50_50_38\n",
      "1 out of 79 files\n",
      "Reading file total_acc_x_train_50_50_38.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0816 18:26:15.915320 140241072178944 ag_logging.py:145] Entity <function standard_lstm at 0x7f8c0ce8f268> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: No module named 'tensorflow_core.contrib'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded 30067\n",
      "stacked (30067, 50, 3)\n",
      "../data/processed/train/keras/done//subjects_train_50_50_38.csv\n",
      "done\n",
      "(30067, 50, 3) (30067, 1)\n",
      "3\n",
      "50\n",
      "WARNING: Entity <function standard_lstm at 0x7f8c0ce8f268> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: No module named 'tensorflow_core.contrib'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0816 18:26:16.024877 140241072178944 ag_logging.py:145] Entity <function cudnn_lstm at 0x7f8c0ce8f2f0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: No module named 'tensorflow_core.contrib'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Entity <function cudnn_lstm at 0x7f8c0ce8f2f0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: No module named 'tensorflow_core.contrib'\n",
      "OKKKK\n",
      "YOOOO\n",
      "Train on 24986 samples, validate on 5081 samples\n",
      "Epoch 1/100\n",
      "24986/24986 [==============================] - 20s 804us/sample - loss: 0.7095 - f1: 0.6673 - val_loss: 0.6814 - val_f1: 0.7296\n",
      "Epoch 2/100\n",
      "24986/24986 [==============================] - 21s 841us/sample - loss: 0.6949 - f1: 0.6776 - val_loss: 0.6874 - val_f1: 0.7416\n",
      "Epoch 3/100\n",
      "24986/24986 [==============================] - 23s 923us/sample - loss: 0.6745 - f1: 0.6767 - val_loss: 0.5770 - val_f1: 0.7300\n",
      "Epoch 4/100\n",
      "24986/24986 [==============================] - 23s 931us/sample - loss: 0.5698 - f1: 0.6775 - val_loss: 0.4434 - val_f1: 0.7297\n",
      "Epoch 5/100\n",
      "24986/24986 [==============================] - 25s 1ms/sample - loss: 0.4709 - f1: 0.6780 - val_loss: 0.4496 - val_f1: 0.7303\n",
      "Epoch 6/100\n",
      "24986/24986 [==============================] - 23s 936us/sample - loss: 0.4087 - f1: 0.6777 - val_loss: 0.3354 - val_f1: 0.7290\n",
      "Epoch 7/100\n",
      "24986/24986 [==============================] - 24s 953us/sample - loss: 0.3506 - f1: 0.6775 - val_loss: 0.2954 - val_f1: 0.7303\n",
      "Epoch 8/100\n",
      "24986/24986 [==============================] - 23s 935us/sample - loss: 0.3287 - f1: 0.6778 - val_loss: 0.2597 - val_f1: 0.7297\n",
      "Epoch 9/100\n",
      "24986/24986 [==============================] - 23s 910us/sample - loss: 0.3203 - f1: 0.6775 - val_loss: 0.2593 - val_f1: 0.7294\n",
      "Epoch 10/100\n",
      "24986/24986 [==============================] - 24s 944us/sample - loss: 0.3007 - f1: 0.6781 - val_loss: 0.2632 - val_f1: 0.7305\n",
      "Epoch 11/100\n",
      "24986/24986 [==============================] - 23s 927us/sample - loss: 0.2895 - f1: 0.6782 - val_loss: 0.3530 - val_f1: 0.7308\n",
      "Epoch 12/100\n",
      "24986/24986 [==============================] - 23s 910us/sample - loss: 0.2770 - f1: 0.6780 - val_loss: 0.2646 - val_f1: 0.7301\n",
      "Epoch 13/100\n",
      "24986/24986 [==============================] - 24s 965us/sample - loss: 0.2675 - f1: 0.6781 - val_loss: 0.2317 - val_f1: 0.7301\n",
      "Epoch 14/100\n",
      "24986/24986 [==============================] - 23s 927us/sample - loss: 0.2858 - f1: 0.6781 - val_loss: 0.2900 - val_f1: 0.7306\n",
      "Epoch 15/100\n",
      "24986/24986 [==============================] - 23s 929us/sample - loss: 0.2608 - f1: 0.6778 - val_loss: 0.1998 - val_f1: 0.7303\n",
      "Epoch 16/100\n",
      "24986/24986 [==============================] - 25s 987us/sample - loss: 0.2535 - f1: 0.6777 - val_loss: 0.2973 - val_f1: 0.7298\n",
      "Epoch 17/100\n",
      "24986/24986 [==============================] - 24s 941us/sample - loss: 0.2440 - f1: 0.6781 - val_loss: 0.1887 - val_f1: 0.7297\n",
      "Epoch 18/100\n",
      "24986/24986 [==============================] - 22s 900us/sample - loss: 0.2367 - f1: 0.6779 - val_loss: 0.2018 - val_f1: 0.7301\n",
      "Epoch 19/100\n",
      "24986/24986 [==============================] - 23s 924us/sample - loss: 0.2299 - f1: 0.6775 - val_loss: 0.1862 - val_f1: 0.7294\n",
      "Epoch 20/100\n",
      "24986/24986 [==============================] - 23s 914us/sample - loss: 0.2204 - f1: 0.6778 - val_loss: 0.1987 - val_f1: 0.7295\n",
      "Epoch 21/100\n",
      "24986/24986 [==============================] - 22s 883us/sample - loss: 0.2145 - f1: 0.6776 - val_loss: 0.2708 - val_f1: 0.7296\n",
      "Epoch 22/100\n",
      "24986/24986 [==============================] - 24s 949us/sample - loss: 0.2122 - f1: 0.6779 - val_loss: 0.3738 - val_f1: 0.7295\n",
      "Epoch 23/100\n",
      "24986/24986 [==============================] - 21s 858us/sample - loss: 0.2083 - f1: 0.6779 - val_loss: 0.2047 - val_f1: 0.7292\n",
      "Epoch 24/100\n",
      "24986/24986 [==============================] - 25s 981us/sample - loss: 0.1976 - f1: 0.6778 - val_loss: 0.3863 - val_f1: 0.7298\n",
      "Epoch 25/100\n",
      "24986/24986 [==============================] - 25s 988us/sample - loss: 0.1974 - f1: 0.6777 - val_loss: 0.3114 - val_f1: 0.7296\n",
      "Epoch 26/100\n",
      "24986/24986 [==============================] - 25s 992us/sample - loss: 0.1929 - f1: 0.6778 - val_loss: 0.2625 - val_f1: 0.7302\n",
      "Epoch 27/100\n",
      "24986/24986 [==============================] - 25s 988us/sample - loss: 0.1856 - f1: 0.6779 - val_loss: 0.1720 - val_f1: 0.7298\n",
      "Epoch 28/100\n",
      "24986/24986 [==============================] - 25s 989us/sample - loss: 0.1835 - f1: 0.6776 - val_loss: 0.2662 - val_f1: 0.7284\n",
      "Epoch 29/100\n",
      "24986/24986 [==============================] - 29s 1ms/sample - loss: 0.1830 - f1: 0.6779 - val_loss: 0.1221 - val_f1: 0.7304\n",
      "Epoch 30/100\n",
      "24986/24986 [==============================] - 30s 1ms/sample - loss: 0.1777 - f1: 0.6775 - val_loss: 0.2180 - val_f1: 0.7300\n",
      "Epoch 31/100\n",
      "24986/24986 [==============================] - 26s 1ms/sample - loss: 0.1776 - f1: 0.6777 - val_loss: 0.3000 - val_f1: 0.7300\n",
      "Epoch 32/100\n",
      "24986/24986 [==============================] - 26s 1ms/sample - loss: 0.1719 - f1: 0.6776 - val_loss: 0.1479 - val_f1: 0.7304\n",
      "Epoch 33/100\n",
      "24986/24986 [==============================] - 26s 1ms/sample - loss: 0.1715 - f1: 0.6777 - val_loss: 0.1548 - val_f1: 0.7299\n",
      "Epoch 34/100\n",
      "24986/24986 [==============================] - 26s 1ms/sample - loss: 0.1708 - f1: 0.6776 - val_loss: 0.1264 - val_f1: 0.7299\n",
      "Epoch 35/100\n",
      "24986/24986 [==============================] - 26s 1ms/sample - loss: 0.1706 - f1: 0.6776 - val_loss: 0.1298 - val_f1: 0.7300\n",
      "Epoch 36/100\n",
      "24986/24986 [==============================] - 25s 994us/sample - loss: 0.1634 - f1: 0.6779 - val_loss: 0.2364 - val_f1: 0.7295\n",
      "Epoch 37/100\n",
      "24986/24986 [==============================] - 25s 993us/sample - loss: 0.1631 - f1: 0.6772 - val_loss: 0.1402 - val_f1: 0.7296\n",
      "Epoch 38/100\n",
      "24986/24986 [==============================] - 25s 997us/sample - loss: 0.1626 - f1: 0.6774 - val_loss: 0.2123 - val_f1: 0.7292\n",
      "Epoch 39/100\n",
      "24986/24986 [==============================] - 26s 1ms/sample - loss: 0.1590 - f1: 0.6778 - val_loss: 0.1334 - val_f1: 0.7301\n",
      "Epoch 40/100\n",
      "24986/24986 [==============================] - 25s 1ms/sample - loss: 0.1558 - f1: 0.6781 - val_loss: 0.1587 - val_f1: 0.7301\n",
      "Epoch 41/100\n",
      "24986/24986 [==============================] - 25s 1ms/sample - loss: 0.1563 - f1: 0.6776 - val_loss: 0.1699 - val_f1: 0.7292\n",
      "Epoch 42/100\n",
      "24986/24986 [==============================] - 25s 1ms/sample - loss: 0.1554 - f1: 0.6776 - val_loss: 0.1313 - val_f1: 0.7290\n",
      "Epoch 43/100\n",
      "24986/24986 [==============================] - 25s 1ms/sample - loss: 0.1526 - f1: 0.6783 - val_loss: 0.1255 - val_f1: 0.7287\n",
      "Epoch 44/100\n",
      "24986/24986 [==============================] - 25s 999us/sample - loss: 0.1555 - f1: 0.6776 - val_loss: 0.2576 - val_f1: 0.7301\n",
      "Epoch 45/100\n",
      "24986/24986 [==============================] - 25s 1ms/sample - loss: 0.1431 - f1: 0.6779 - val_loss: 0.1574 - val_f1: 0.7296\n",
      "Epoch 46/100\n",
      "24986/24986 [==============================] - 25s 1ms/sample - loss: 0.1450 - f1: 0.6780 - val_loss: 0.2395 - val_f1: 0.7305\n",
      "Epoch 47/100\n",
      "24986/24986 [==============================] - 25s 1ms/sample - loss: 0.1484 - f1: 0.6782 - val_loss: 0.2344 - val_f1: 0.7300\n",
      "Epoch 48/100\n",
      "24986/24986 [==============================] - 26s 1ms/sample - loss: 0.1483 - f1: 0.6778 - val_loss: 0.1428 - val_f1: 0.7290\n",
      "Epoch 49/100\n",
      "24986/24986 [==============================] - 26s 1ms/sample - loss: 0.1499 - f1: 0.6779 - val_loss: 0.3181 - val_f1: 0.7294\n",
      "Epoch 50/100\n",
      "24986/24986 [==============================] - 27s 1ms/sample - loss: 0.1400 - f1: 0.6776 - val_loss: 0.1148 - val_f1: 0.7294\n",
      "Epoch 51/100\n",
      "24986/24986 [==============================] - 25s 1ms/sample - loss: 0.1344 - f1: 0.6776 - val_loss: 0.1411 - val_f1: 0.7297\n",
      "Epoch 52/100\n",
      "24986/24986 [==============================] - 28s 1ms/sample - loss: 0.1424 - f1: 0.6772 - val_loss: 0.3263 - val_f1: 0.7300\n",
      "Epoch 53/100\n",
      "24986/24986 [==============================] - 26s 1ms/sample - loss: 0.1340 - f1: 0.6779 - val_loss: 0.1467 - val_f1: 0.7295\n",
      "Epoch 54/100\n",
      "24986/24986 [==============================] - 26s 1ms/sample - loss: 0.1332 - f1: 0.6777 - val_loss: 0.1687 - val_f1: 0.7295\n",
      "Epoch 55/100\n",
      "24986/24986 [==============================] - 27s 1ms/sample - loss: 0.1383 - f1: 0.6781 - val_loss: 0.1391 - val_f1: 0.7300\n",
      "Epoch 56/100\n",
      "24986/24986 [==============================] - 26s 1ms/sample - loss: 0.1348 - f1: 0.6779 - val_loss: 0.2147 - val_f1: 0.7301\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/100\n",
      "24986/24986 [==============================] - 21s 857us/sample - loss: 0.1343 - f1: 0.6782 - val_loss: 0.2739 - val_f1: 0.7306\n",
      "Epoch 58/100\n",
      "24986/24986 [==============================] - 22s 866us/sample - loss: 0.1285 - f1: 0.6778 - val_loss: 0.1402 - val_f1: 0.7296\n",
      "Epoch 59/100\n",
      "24986/24986 [==============================] - 22s 883us/sample - loss: 0.1240 - f1: 0.6775 - val_loss: 0.1860 - val_f1: 0.7294\n",
      "Epoch 60/100\n",
      "24986/24986 [==============================] - 22s 880us/sample - loss: 0.1273 - f1: 0.6775 - val_loss: 0.3373 - val_f1: 0.7299\n",
      "Epoch 61/100\n",
      "24986/24986 [==============================] - 22s 869us/sample - loss: 0.1279 - f1: 0.6775 - val_loss: 0.1547 - val_f1: 0.7290\n",
      "Epoch 62/100\n",
      "24986/24986 [==============================] - 23s 907us/sample - loss: 0.1370 - f1: 0.6781 - val_loss: 0.2382 - val_f1: 0.7290\n",
      "Epoch 63/100\n",
      "24986/24986 [==============================] - 22s 885us/sample - loss: 0.1222 - f1: 0.6781 - val_loss: 0.1423 - val_f1: 0.7296\n",
      "Epoch 64/100\n",
      "24986/24986 [==============================] - 23s 907us/sample - loss: 0.1225 - f1: 0.6779 - val_loss: 0.1220 - val_f1: 0.7300\n",
      "Epoch 65/100\n",
      "24986/24986 [==============================] - 22s 874us/sample - loss: 0.1266 - f1: 0.6776 - val_loss: 0.1326 - val_f1: 0.7303\n",
      "Epoch 66/100\n",
      "24986/24986 [==============================] - 23s 904us/sample - loss: 0.1196 - f1: 0.6780 - val_loss: 0.1565 - val_f1: 0.7301\n",
      "Epoch 67/100\n",
      "24986/24986 [==============================] - 23s 917us/sample - loss: 0.1222 - f1: 0.6777 - val_loss: 0.1406 - val_f1: 0.7304\n",
      "Epoch 68/100\n",
      "24986/24986 [==============================] - 23s 920us/sample - loss: 0.1183 - f1: 0.6779 - val_loss: 0.1536 - val_f1: 0.7299\n",
      "Epoch 69/100\n",
      "24986/24986 [==============================] - 22s 894us/sample - loss: 0.1203 - f1: 0.6776 - val_loss: 0.1330 - val_f1: 0.7294\n",
      "Epoch 70/100\n",
      "24986/24986 [==============================] - 22s 880us/sample - loss: 0.1143 - f1: 0.6780 - val_loss: 0.1280 - val_f1: 0.7293\n",
      "Epoch 71/100\n",
      "24986/24986 [==============================] - 22s 878us/sample - loss: 0.1132 - f1: 0.6779 - val_loss: 0.2435 - val_f1: 0.7298\n",
      "Epoch 72/100\n",
      "24986/24986 [==============================] - 23s 905us/sample - loss: 0.1120 - f1: 0.6780 - val_loss: 0.3342 - val_f1: 0.7306\n",
      "Epoch 73/100\n",
      "24986/24986 [==============================] - 22s 891us/sample - loss: 0.1158 - f1: 0.6777 - val_loss: 0.1821 - val_f1: 0.7296\n",
      "Epoch 74/100\n",
      "24986/24986 [==============================] - 25s 1ms/sample - loss: 0.1117 - f1: 0.6779 - val_loss: 0.3642 - val_f1: 0.7296\n",
      "Epoch 75/100\n",
      "24986/24986 [==============================] - 31s 1ms/sample - loss: 0.1143 - f1: 0.6780 - val_loss: 0.3806 - val_f1: 0.7303\n",
      "Epoch 76/100\n",
      "24986/24986 [==============================] - 23s 910us/sample - loss: 0.1127 - f1: 0.6776 - val_loss: 0.1553 - val_f1: 0.7298\n",
      "Epoch 77/100\n",
      "24986/24986 [==============================] - 23s 916us/sample - loss: 0.1117 - f1: 0.6775 - val_loss: 0.1474 - val_f1: 0.7299\n",
      "Epoch 78/100\n",
      "24986/24986 [==============================] - 22s 880us/sample - loss: 0.1052 - f1: 0.6778 - val_loss: 0.1956 - val_f1: 0.7300\n",
      "Epoch 79/100\n",
      "24986/24986 [==============================] - 26s 1ms/sample - loss: 0.1075 - f1: 0.6776 - val_loss: 0.1399 - val_f1: 0.7292\n",
      "Epoch 80/100\n",
      "24986/24986 [==============================] - 24s 943us/sample - loss: 0.1040 - f1: 0.6778 - val_loss: 0.2347 - val_f1: 0.7298\n",
      "Epoch 81/100\n",
      "24986/24986 [==============================] - 24s 957us/sample - loss: 0.1049 - f1: 0.6777 - val_loss: 0.1668 - val_f1: 0.7303\n",
      "Epoch 82/100\n",
      "24986/24986 [==============================] - 23s 908us/sample - loss: 0.1035 - f1: 0.6779 - val_loss: 0.3537 - val_f1: 0.7303\n",
      "Epoch 83/100\n",
      "24986/24986 [==============================] - 22s 891us/sample - loss: 0.1044 - f1: 0.6778 - val_loss: 0.1230 - val_f1: 0.7299\n",
      "Epoch 84/100\n",
      "24986/24986 [==============================] - 24s 973us/sample - loss: 0.1059 - f1: 0.6781 - val_loss: 0.2017 - val_f1: 0.7291\n",
      "Epoch 85/100\n",
      "24986/24986 [==============================] - 25s 1ms/sample - loss: 0.1022 - f1: 0.6778 - val_loss: 0.2444 - val_f1: 0.7292\n",
      "Epoch 86/100\n",
      "24986/24986 [==============================] - 24s 964us/sample - loss: 0.1033 - f1: 0.6780 - val_loss: 0.3599 - val_f1: 0.7294\n",
      "Epoch 87/100\n",
      "24986/24986 [==============================] - 24s 950us/sample - loss: 0.0973 - f1: 0.6780 - val_loss: 0.2046 - val_f1: 0.7294\n",
      "Epoch 88/100\n",
      "24986/24986 [==============================] - 23s 926us/sample - loss: 0.0965 - f1: 0.6777 - val_loss: 0.2328 - val_f1: 0.7305\n",
      "Epoch 89/100\n",
      "24986/24986 [==============================] - 23s 918us/sample - loss: 0.0987 - f1: 0.6782 - val_loss: 0.1524 - val_f1: 0.7294\n",
      "Epoch 90/100\n",
      "24986/24986 [==============================] - 26s 1ms/sample - loss: 0.1031 - f1: 0.6780 - val_loss: 0.1248 - val_f1: 0.7295\n",
      "Epoch 91/100\n",
      "24986/24986 [==============================] - 25s 983us/sample - loss: 0.0954 - f1: 0.6778 - val_loss: 0.2621 - val_f1: 0.7292\n",
      "Epoch 92/100\n",
      "24986/24986 [==============================] - 25s 997us/sample - loss: 0.0959 - f1: 0.6776 - val_loss: 0.2745 - val_f1: 0.7301\n",
      "Epoch 93/100\n",
      "24986/24986 [==============================] - 31s 1ms/sample - loss: 0.0973 - f1: 0.6776 - val_loss: 0.2286 - val_f1: 0.7298\n",
      "Epoch 94/100\n",
      "24986/24986 [==============================] - 32s 1ms/sample - loss: 0.0919 - f1: 0.6782 - val_loss: 0.2448 - val_f1: 0.7298\n",
      "Epoch 95/100\n",
      "24986/24986 [==============================] - 26s 1ms/sample - loss: 0.0993 - f1: 0.6779 - val_loss: 0.1971 - val_f1: 0.7296\n",
      "Epoch 96/100\n",
      "24986/24986 [==============================] - 35s 1ms/sample - loss: 0.0914 - f1: 0.6780 - val_loss: 0.1744 - val_f1: 0.7292\n",
      "Epoch 97/100\n",
      "24986/24986 [==============================] - 33s 1ms/sample - loss: 0.0960 - f1: 0.6776 - val_loss: 0.1454 - val_f1: 0.7302\n",
      "Epoch 98/100\n",
      "24986/24986 [==============================] - 33s 1ms/sample - loss: 0.0995 - f1: 0.6777 - val_loss: 0.5364 - val_f1: 0.7298\n",
      "Epoch 99/100\n",
      "24986/24986 [==============================] - 28s 1ms/sample - loss: 0.0915 - f1: 0.6776 - val_loss: 0.2685 - val_f1: 0.7295\n",
      "Epoch 100/100\n",
      "24986/24986 [==============================] - 26s 1ms/sample - loss: 0.0894 - f1: 0.6778 - val_loss: 0.3136 - val_f1: 0.7300\n",
      "FIT\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0816 19:07:26.263773 140241072178944 ag_logging.py:145] Entity <function standard_lstm at 0x7f8c0ce8f268> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: No module named 'tensorflow_core.contrib'\n",
      "W0816 19:07:26.362457 140241072178944 ag_logging.py:145] Entity <function cudnn_lstm at 0x7f8c0ce8f2f0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: No module named 'tensorflow_core.contrib'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PREDICT\n",
      "Group 0\n",
      "[0.88668976 0.9251634 ]\n",
      "macro 0.90592657811929\n",
      "3\n",
      "50\n",
      "WARNING: Entity <function standard_lstm at 0x7f8c0ce8f268> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: No module named 'tensorflow_core.contrib'\n",
      "WARNING: Entity <function cudnn_lstm at 0x7f8c0ce8f2f0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: No module named 'tensorflow_core.contrib'\n",
      "OKKKK\n",
      "YOOOO\n",
      "Train on 26799 samples, validate on 3268 samples\n",
      "Epoch 1/100\n",
      "26799/26799 [==============================] - 25s 928us/sample - loss: 0.7124 - f1: 0.6731 - val_loss: 0.6909 - val_f1: 0.7009\n",
      "Epoch 2/100\n",
      "26799/26799 [==============================] - 23s 876us/sample - loss: 0.6938 - f1: 0.6843 - val_loss: 0.6931 - val_f1: 0.6948\n",
      "Epoch 3/100\n",
      "26799/26799 [==============================] - 23s 853us/sample - loss: 0.6483 - f1: 0.6835 - val_loss: 0.6790 - val_f1: 0.6982\n",
      "Epoch 4/100\n",
      "26799/26799 [==============================] - 23s 874us/sample - loss: 0.5318 - f1: 0.6851 - val_loss: 0.5683 - val_f1: 0.6998\n",
      "Epoch 5/100\n",
      "26799/26799 [==============================] - 23s 851us/sample - loss: 0.5091 - f1: 0.6853 - val_loss: 0.9149 - val_f1: 0.7003\n",
      "Epoch 6/100\n",
      "26799/26799 [==============================] - 23s 849us/sample - loss: 0.4704 - f1: 0.6852 - val_loss: 0.4156 - val_f1: 0.7028\n",
      "Epoch 7/100\n",
      "26799/26799 [==============================] - 23s 850us/sample - loss: 0.4072 - f1: 0.6851 - val_loss: 0.3996 - val_f1: 0.7020\n",
      "Epoch 8/100\n",
      "26799/26799 [==============================] - 23s 848us/sample - loss: 0.4122 - f1: 0.6850 - val_loss: 0.3880 - val_f1: 0.6982\n",
      "Epoch 9/100\n",
      "26799/26799 [==============================] - 23s 846us/sample - loss: 0.3333 - f1: 0.6855 - val_loss: 0.3565 - val_f1: 0.6988\n",
      "Epoch 10/100\n",
      "26799/26799 [==============================] - 23s 854us/sample - loss: 0.3116 - f1: 0.6854 - val_loss: 0.3394 - val_f1: 0.7030\n",
      "Epoch 11/100\n",
      "26799/26799 [==============================] - 23s 852us/sample - loss: 0.3004 - f1: 0.6853 - val_loss: 0.2663 - val_f1: 0.7011\n",
      "Epoch 12/100\n",
      "26799/26799 [==============================] - 23s 852us/sample - loss: 0.2851 - f1: 0.6854 - val_loss: 0.2933 - val_f1: 0.7017\n",
      "Epoch 13/100\n",
      "26799/26799 [==============================] - 23s 854us/sample - loss: 0.2763 - f1: 0.6855 - val_loss: 0.4441 - val_f1: 0.7011\n",
      "Epoch 14/100\n",
      "26799/26799 [==============================] - 23s 854us/sample - loss: 0.2689 - f1: 0.6853 - val_loss: 0.2788 - val_f1: 0.7023\n",
      "Epoch 15/100\n",
      "26799/26799 [==============================] - 23s 859us/sample - loss: 0.2578 - f1: 0.6852 - val_loss: 0.4593 - val_f1: 0.6988\n",
      "Epoch 16/100\n",
      "26799/26799 [==============================] - 23s 856us/sample - loss: 0.2528 - f1: 0.6855 - val_loss: 0.2921 - val_f1: 0.7032\n",
      "Epoch 17/100\n",
      "26799/26799 [==============================] - 23s 856us/sample - loss: 0.2458 - f1: 0.6853 - val_loss: 0.2495 - val_f1: 0.6985\n",
      "Epoch 18/100\n",
      "26799/26799 [==============================] - 23s 856us/sample - loss: 0.2357 - f1: 0.6851 - val_loss: 0.2378 - val_f1: 0.7025\n",
      "Epoch 19/100\n",
      "26799/26799 [==============================] - 23s 862us/sample - loss: 0.2325 - f1: 0.6857 - val_loss: 0.2683 - val_f1: 0.7001\n",
      "Epoch 20/100\n",
      "26799/26799 [==============================] - 23s 873us/sample - loss: 0.2309 - f1: 0.6855 - val_loss: 0.2851 - val_f1: 0.7024\n",
      "Epoch 21/100\n",
      "26799/26799 [==============================] - 24s 901us/sample - loss: 0.2288 - f1: 0.6852 - val_loss: 0.2396 - val_f1: 0.7016\n",
      "Epoch 22/100\n",
      "26799/26799 [==============================] - 23s 862us/sample - loss: 0.2228 - f1: 0.6851 - val_loss: 0.3397 - val_f1: 0.7028\n",
      "Epoch 23/100\n",
      "26799/26799 [==============================] - 23s 864us/sample - loss: 0.2149 - f1: 0.6854 - val_loss: 0.3151 - val_f1: 0.7031\n",
      "Epoch 24/100\n",
      "26799/26799 [==============================] - 23s 864us/sample - loss: 0.2114 - f1: 0.6854 - val_loss: 0.5594 - val_f1: 0.6970\n",
      "Epoch 25/100\n",
      "26799/26799 [==============================] - 23s 861us/sample - loss: 0.2129 - f1: 0.6852 - val_loss: 0.2731 - val_f1: 0.7022\n",
      "Epoch 26/100\n",
      "26799/26799 [==============================] - 23s 865us/sample - loss: 0.2098 - f1: 0.6853 - val_loss: 0.2362 - val_f1: 0.6994\n",
      "Epoch 27/100\n",
      "26799/26799 [==============================] - 23s 862us/sample - loss: 0.2043 - f1: 0.6852 - val_loss: 0.2659 - val_f1: 0.6991\n",
      "Epoch 28/100\n",
      "26799/26799 [==============================] - 23s 862us/sample - loss: 0.1971 - f1: 0.6850 - val_loss: 0.2562 - val_f1: 0.7009\n",
      "Epoch 29/100\n",
      "26799/26799 [==============================] - 23s 877us/sample - loss: 0.1919 - f1: 0.6851 - val_loss: 0.2337 - val_f1: 0.6983\n",
      "Epoch 30/100\n",
      "26799/26799 [==============================] - 24s 899us/sample - loss: 0.1839 - f1: 0.6850 - val_loss: 0.3286 - val_f1: 0.7029\n",
      "Epoch 31/100\n",
      "26799/26799 [==============================] - 23s 874us/sample - loss: 0.1802 - f1: 0.6852 - val_loss: 0.3033 - val_f1: 0.6996\n",
      "Epoch 32/100\n",
      "26799/26799 [==============================] - 23s 870us/sample - loss: 0.1770 - f1: 0.6854 - val_loss: 0.2112 - val_f1: 0.7015\n",
      "Epoch 33/100\n",
      "26799/26799 [==============================] - 23s 871us/sample - loss: 0.1889 - f1: 0.6851 - val_loss: 0.1998 - val_f1: 0.7029\n",
      "Epoch 34/100\n",
      "26799/26799 [==============================] - 23s 870us/sample - loss: 0.1705 - f1: 0.6850 - val_loss: 0.2611 - val_f1: 0.6989\n",
      "Epoch 35/100\n",
      "26799/26799 [==============================] - 23s 867us/sample - loss: 0.1648 - f1: 0.6855 - val_loss: 0.2405 - val_f1: 0.7017\n",
      "Epoch 36/100\n",
      "26799/26799 [==============================] - 23s 872us/sample - loss: 0.1638 - f1: 0.6849 - val_loss: 0.2514 - val_f1: 0.7026\n",
      "Epoch 37/100\n",
      "26799/26799 [==============================] - 23s 875us/sample - loss: 0.1613 - f1: 0.6849 - val_loss: 0.4579 - val_f1: 0.7014\n",
      "Epoch 38/100\n",
      "26799/26799 [==============================] - 23s 868us/sample - loss: 0.1578 - f1: 0.6853 - val_loss: 0.2102 - val_f1: 0.7026\n",
      "Epoch 39/100\n",
      "26799/26799 [==============================] - 23s 869us/sample - loss: 0.1570 - f1: 0.6856 - val_loss: 0.2019 - val_f1: 0.6993\n",
      "Epoch 40/100\n",
      "26799/26799 [==============================] - 23s 870us/sample - loss: 0.1518 - f1: 0.6853 - val_loss: 0.2304 - val_f1: 0.6983\n",
      "Epoch 41/100\n",
      "26799/26799 [==============================] - 23s 875us/sample - loss: 0.1566 - f1: 0.6853 - val_loss: 0.2216 - val_f1: 0.7001\n",
      "Epoch 42/100\n",
      "26799/26799 [==============================] - 25s 921us/sample - loss: 0.1736 - f1: 0.6853 - val_loss: 0.1806 - val_f1: 0.7006\n",
      "Epoch 43/100\n",
      "26799/26799 [==============================] - 24s 896us/sample - loss: 0.1595 - f1: 0.6855 - val_loss: 0.2288 - val_f1: 0.7016\n",
      "Epoch 44/100\n",
      "26799/26799 [==============================] - 26s 987us/sample - loss: 0.1610 - f1: 0.6856 - val_loss: 0.1828 - val_f1: 0.7021\n",
      "Epoch 45/100\n",
      "26799/26799 [==============================] - 33s 1ms/sample - loss: 0.1565 - f1: 0.6855 - val_loss: 0.2069 - val_f1: 0.7024\n",
      "Epoch 46/100\n",
      "26799/26799 [==============================] - 26s 957us/sample - loss: 0.1509 - f1: 0.6849 - val_loss: 0.2106 - val_f1: 0.7019\n",
      "Epoch 47/100\n",
      "26799/26799 [==============================] - 25s 944us/sample - loss: 0.1378 - f1: 0.6852 - val_loss: 0.2471 - val_f1: 0.7005\n",
      "Epoch 48/100\n",
      "26799/26799 [==============================] - 33s 1ms/sample - loss: 0.1412 - f1: 0.6852 - val_loss: 0.2166 - val_f1: 0.6999\n",
      "Epoch 49/100\n",
      "26799/26799 [==============================] - 26s 953us/sample - loss: 0.1338 - f1: 0.6852 - val_loss: 0.2128 - val_f1: 0.6983\n",
      "Epoch 50/100\n",
      "26799/26799 [==============================] - 27s 1ms/sample - loss: 0.1465 - f1: 0.6849 - val_loss: 0.5239 - val_f1: 0.7017\n",
      "Epoch 51/100\n",
      "26799/26799 [==============================] - 26s 959us/sample - loss: 0.1419 - f1: 0.6860 - val_loss: 0.2423 - val_f1: 0.7003\n",
      "Epoch 52/100\n",
      "26799/26799 [==============================] - 26s 953us/sample - loss: 0.1337 - f1: 0.6853 - val_loss: 0.1902 - val_f1: 0.6986\n",
      "Epoch 53/100\n",
      "26799/26799 [==============================] - 26s 958us/sample - loss: 0.1378 - f1: 0.6853 - val_loss: 0.2316 - val_f1: 0.7020\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 54/100\n",
      "26799/26799 [==============================] - 23s 848us/sample - loss: 0.1263 - f1: 0.6855 - val_loss: 0.5061 - val_f1: 0.7016\n",
      "Epoch 55/100\n",
      "26799/26799 [==============================] - 23s 875us/sample - loss: 0.1281 - f1: 0.6853 - val_loss: 0.2403 - val_f1: 0.7008\n",
      "Epoch 56/100\n",
      "26799/26799 [==============================] - 25s 917us/sample - loss: 0.1258 - f1: 0.6854 - val_loss: 0.2590 - val_f1: 0.6987\n",
      "Epoch 57/100\n",
      "26799/26799 [==============================] - 23s 852us/sample - loss: 0.1253 - f1: 0.6848 - val_loss: 0.2362 - val_f1: 0.7003\n",
      "Epoch 58/100\n",
      "26799/26799 [==============================] - 22s 836us/sample - loss: 0.1241 - f1: 0.6851 - val_loss: 0.2330 - val_f1: 0.6934\n",
      "Epoch 59/100\n",
      "26799/26799 [==============================] - 22s 835us/sample - loss: 0.1237 - f1: 0.6854 - val_loss: 0.2626 - val_f1: 0.6984\n",
      "Epoch 60/100\n",
      "26799/26799 [==============================] - 23s 840us/sample - loss: 0.1209 - f1: 0.6848 - val_loss: 0.2227 - val_f1: 0.7012\n",
      "Epoch 61/100\n",
      "26799/26799 [==============================] - 22s 838us/sample - loss: 0.1241 - f1: 0.6856 - val_loss: 0.2855 - val_f1: 0.7014\n",
      "Epoch 62/100\n",
      "26799/26799 [==============================] - 22s 837us/sample - loss: 0.1165 - f1: 0.6852 - val_loss: 0.2196 - val_f1: 0.7030\n",
      "Epoch 63/100\n",
      "26799/26799 [==============================] - 23s 851us/sample - loss: 0.1166 - f1: 0.6851 - val_loss: 0.2976 - val_f1: 0.7009\n",
      "Epoch 64/100\n",
      "26799/26799 [==============================] - 23s 846us/sample - loss: 0.1140 - f1: 0.6855 - val_loss: 0.2822 - val_f1: 0.7019\n",
      "Epoch 65/100\n",
      "26799/26799 [==============================] - 23s 841us/sample - loss: 0.1117 - f1: 0.6851 - val_loss: 0.2911 - val_f1: 0.7020\n",
      "Epoch 66/100\n",
      "26799/26799 [==============================] - 22s 835us/sample - loss: 0.1182 - f1: 0.6852 - val_loss: 0.2516 - val_f1: 0.7013\n",
      "Epoch 67/100\n",
      "26799/26799 [==============================] - 23s 841us/sample - loss: 0.1118 - f1: 0.6851 - val_loss: 0.3167 - val_f1: 0.7016\n",
      "Epoch 68/100\n",
      "26799/26799 [==============================] - 22s 838us/sample - loss: 0.1129 - f1: 0.6851 - val_loss: 0.3535 - val_f1: 0.7026\n",
      "Epoch 69/100\n",
      "26799/26799 [==============================] - 23s 845us/sample - loss: 0.1113 - f1: 0.6851 - val_loss: 0.2738 - val_f1: 0.7006\n",
      "Epoch 70/100\n",
      "26799/26799 [==============================] - 24s 891us/sample - loss: 0.1084 - f1: 0.6853 - val_loss: 0.3089 - val_f1: 0.7016\n",
      "Epoch 71/100\n",
      "26799/26799 [==============================] - 24s 880us/sample - loss: 0.1074 - f1: 0.6851 - val_loss: 0.3111 - val_f1: 0.7006\n",
      "Epoch 72/100\n",
      "26799/26799 [==============================] - 24s 880us/sample - loss: 0.1047 - f1: 0.6852 - val_loss: 0.2439 - val_f1: 0.7014\n",
      "Epoch 73/100\n",
      "26799/26799 [==============================] - 24s 879us/sample - loss: 0.1094 - f1: 0.6852 - val_loss: 0.2649 - val_f1: 0.7012\n",
      "Epoch 74/100\n",
      "26799/26799 [==============================] - 24s 884us/sample - loss: 0.1038 - f1: 0.6852 - val_loss: 0.2409 - val_f1: 0.7010\n",
      "Epoch 75/100\n",
      "26799/26799 [==============================] - 24s 878us/sample - loss: 0.1043 - f1: 0.6853 - val_loss: 0.2582 - val_f1: 0.7005\n",
      "Epoch 76/100\n",
      "26799/26799 [==============================] - 24s 882us/sample - loss: 0.1026 - f1: 0.6855 - val_loss: 0.2884 - val_f1: 0.7026\n",
      "Epoch 77/100\n",
      "26799/26799 [==============================] - 24s 886us/sample - loss: 0.1047 - f1: 0.6852 - val_loss: 0.3079 - val_f1: 0.7010\n",
      "Epoch 78/100\n",
      "26799/26799 [==============================] - 24s 890us/sample - loss: 0.1018 - f1: 0.6853 - val_loss: 0.2094 - val_f1: 0.7025\n",
      "Epoch 79/100\n",
      "26799/26799 [==============================] - 24s 893us/sample - loss: 0.1000 - f1: 0.6850 - val_loss: 0.2963 - val_f1: 0.6982\n",
      "Epoch 80/100\n",
      "26799/26799 [==============================] - 24s 885us/sample - loss: 0.1014 - f1: 0.6852 - val_loss: 0.2289 - val_f1: 0.7026\n",
      "Epoch 81/100\n",
      "26799/26799 [==============================] - 24s 887us/sample - loss: 0.0923 - f1: 0.6851 - val_loss: 0.2418 - val_f1: 0.6982\n",
      "Epoch 82/100\n",
      "26799/26799 [==============================] - 24s 878us/sample - loss: 0.0991 - f1: 0.6853 - val_loss: 0.3066 - val_f1: 0.7014\n",
      "Epoch 83/100\n",
      "26799/26799 [==============================] - 23s 875us/sample - loss: 0.0976 - f1: 0.6854 - val_loss: 0.2925 - val_f1: 0.7001\n",
      "Epoch 84/100\n",
      "26799/26799 [==============================] - 21s 786us/sample - loss: 0.1030 - f1: 0.6853 - val_loss: 0.2882 - val_f1: 0.7022\n",
      "Epoch 85/100\n",
      "26799/26799 [==============================] - 21s 778us/sample - loss: 0.0939 - f1: 0.6850 - val_loss: 0.2515 - val_f1: 0.7008\n",
      "Epoch 86/100\n",
      "26799/26799 [==============================] - 21s 782us/sample - loss: 0.0919 - f1: 0.6853 - val_loss: 0.3634 - val_f1: 0.7016\n",
      "Epoch 87/100\n",
      "26799/26799 [==============================] - 21s 777us/sample - loss: 0.0920 - f1: 0.6856 - val_loss: 0.4173 - val_f1: 0.7002\n",
      "Epoch 88/100\n",
      "26799/26799 [==============================] - 21s 779us/sample - loss: 0.0910 - f1: 0.6852 - val_loss: 0.2769 - val_f1: 0.7004\n",
      "Epoch 89/100\n",
      "26799/26799 [==============================] - 21s 779us/sample - loss: 0.0953 - f1: 0.6856 - val_loss: 0.2590 - val_f1: 0.7006\n",
      "Epoch 90/100\n",
      "26799/26799 [==============================] - 21s 778us/sample - loss: 0.0902 - f1: 0.6854 - val_loss: 0.2542 - val_f1: 0.7034\n",
      "Epoch 91/100\n",
      "26799/26799 [==============================] - 21s 777us/sample - loss: 0.0910 - f1: 0.6852 - val_loss: 0.2727 - val_f1: 0.7005\n",
      "Epoch 92/100\n",
      "26799/26799 [==============================] - 21s 783us/sample - loss: 0.0920 - f1: 0.6849 - val_loss: 0.2952 - val_f1: 0.7030\n",
      "Epoch 93/100\n",
      "26799/26799 [==============================] - 21s 780us/sample - loss: 0.0940 - f1: 0.6852 - val_loss: 0.3456 - val_f1: 0.7001\n",
      "Epoch 94/100\n",
      "26799/26799 [==============================] - 21s 788us/sample - loss: 0.0846 - f1: 0.6855 - val_loss: 0.2597 - val_f1: 0.7021\n",
      "Epoch 95/100\n",
      "26799/26799 [==============================] - 21s 781us/sample - loss: 0.0898 - f1: 0.6851 - val_loss: 0.2694 - val_f1: 0.7025\n",
      "Epoch 96/100\n",
      "26799/26799 [==============================] - 21s 782us/sample - loss: 0.0842 - f1: 0.6852 - val_loss: 0.2079 - val_f1: 0.7010\n",
      "Epoch 97/100\n",
      "26799/26799 [==============================] - 21s 783us/sample - loss: 0.0837 - f1: 0.6851 - val_loss: 0.3601 - val_f1: 0.7002\n",
      "Epoch 98/100\n",
      "26799/26799 [==============================] - 21s 788us/sample - loss: 0.0860 - f1: 0.6854 - val_loss: 0.2868 - val_f1: 0.7029\n",
      "Epoch 99/100\n",
      "26799/26799 [==============================] - 21s 787us/sample - loss: 0.0835 - f1: 0.6853 - val_loss: 0.3254 - val_f1: 0.7008\n",
      "Epoch 100/100\n",
      "26799/26799 [==============================] - 21s 787us/sample - loss: 0.0837 - f1: 0.6848 - val_loss: 0.2469 - val_f1: 0.6972\n",
      "FIT\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0816 19:46:14.684479 140241072178944 ag_logging.py:145] Entity <function standard_lstm at 0x7f8c0ce8f268> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: No module named 'tensorflow_core.contrib'\n",
      "W0816 19:46:14.781135 140241072178944 ag_logging.py:145] Entity <function cudnn_lstm at 0x7f8c0ce8f2f0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: No module named 'tensorflow_core.contrib'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PREDICT\n",
      "Group 1\n",
      "[0.90817356 0.92337917]\n",
      "macro 0.9157763684555895\n",
      "3\n",
      "50\n",
      "WARNING: Entity <function standard_lstm at 0x7f8c0ce8f268> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: No module named 'tensorflow_core.contrib'\n",
      "WARNING: Entity <function cudnn_lstm at 0x7f8c0ce8f2f0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: No module named 'tensorflow_core.contrib'\n",
      "OKKKK\n",
      "YOOOO\n",
      "Train on 27747 samples, validate on 2320 samples\n",
      "Epoch 1/100\n",
      "27747/27747 [==============================] - 22s 781us/sample - loss: 0.7061 - f1: 0.6814 - val_loss: 0.6922 - val_f1: 0.6371\n",
      "Epoch 2/100\n",
      "27747/27747 [==============================] - 21s 744us/sample - loss: 0.6934 - f1: 0.6904 - val_loss: 0.6978 - val_f1: 0.6380\n",
      "Epoch 3/100\n",
      "27747/27747 [==============================] - 21s 749us/sample - loss: 0.6793 - f1: 0.6897 - val_loss: 0.6195 - val_f1: 0.6352\n",
      "Epoch 4/100\n",
      "27747/27747 [==============================] - 21s 744us/sample - loss: 0.5504 - f1: 0.6909 - val_loss: 0.6063 - val_f1: 0.6362\n",
      "Epoch 5/100\n",
      "27747/27747 [==============================] - 21s 746us/sample - loss: 0.4455 - f1: 0.6917 - val_loss: 0.6538 - val_f1: 0.6360\n",
      "Epoch 6/100\n",
      "27747/27747 [==============================] - 21s 744us/sample - loss: 0.5124 - f1: 0.6910 - val_loss: 0.6651 - val_f1: 0.6376\n",
      "Epoch 7/100\n",
      "27747/27747 [==============================] - 21s 746us/sample - loss: 0.5166 - f1: 0.6904 - val_loss: 0.7050 - val_f1: 0.6361\n",
      "Epoch 8/100\n",
      "27747/27747 [==============================] - 21s 747us/sample - loss: 0.4944 - f1: 0.6909 - val_loss: 1.0690 - val_f1: 0.6371\n",
      "Epoch 9/100\n",
      "27747/27747 [==============================] - 21s 757us/sample - loss: 0.4078 - f1: 0.6905 - val_loss: 0.8300 - val_f1: 0.6364\n",
      "Epoch 10/100\n",
      "27747/27747 [==============================] - 21s 749us/sample - loss: 0.3341 - f1: 0.6910 - val_loss: 0.8923 - val_f1: 0.6376\n",
      "Epoch 11/100\n",
      "27747/27747 [==============================] - 21s 754us/sample - loss: 0.4721 - f1: 0.6908 - val_loss: 0.6015 - val_f1: 0.6361\n",
      "Epoch 12/100\n",
      "27747/27747 [==============================] - 21s 751us/sample - loss: 0.5982 - f1: 0.6911 - val_loss: 0.6929 - val_f1: 0.6385\n",
      "Epoch 13/100\n",
      "27747/27747 [==============================] - 21s 749us/sample - loss: 0.6920 - f1: 0.6906 - val_loss: 0.6946 - val_f1: 0.6364\n",
      "Epoch 14/100\n",
      "27747/27747 [==============================] - 21s 750us/sample - loss: 0.6847 - f1: 0.6912 - val_loss: 0.6826 - val_f1: 0.6387\n",
      "Epoch 15/100\n",
      "27747/27747 [==============================] - 21s 756us/sample - loss: 0.6851 - f1: 0.6904 - val_loss: 0.6930 - val_f1: 0.6381\n",
      "Epoch 16/100\n",
      "27747/27747 [==============================] - 21s 752us/sample - loss: 0.6851 - f1: 0.6908 - val_loss: 0.6811 - val_f1: 0.6361\n",
      "Epoch 17/100\n",
      "27747/27747 [==============================] - 21s 752us/sample - loss: 0.6729 - f1: 0.6911 - val_loss: 0.6727 - val_f1: 0.6388\n",
      "Epoch 18/100\n",
      "27747/27747 [==============================] - 21s 755us/sample - loss: 0.6650 - f1: 0.6908 - val_loss: 0.6452 - val_f1: 0.6384\n",
      "Epoch 19/100\n",
      "27747/27747 [==============================] - 21s 756us/sample - loss: 0.5670 - f1: 0.6913 - val_loss: 0.6718 - val_f1: 0.6351\n",
      "Epoch 20/100\n",
      "27747/27747 [==============================] - 21s 758us/sample - loss: 0.5098 - f1: 0.6909 - val_loss: 0.6264 - val_f1: 0.6349\n",
      "Epoch 21/100\n",
      "27747/27747 [==============================] - 21s 755us/sample - loss: 0.5550 - f1: 0.6906 - val_loss: 0.6496 - val_f1: 0.6376\n",
      "Epoch 22/100\n",
      "27747/27747 [==============================] - 21s 758us/sample - loss: 0.5592 - f1: 0.6911 - val_loss: 0.6500 - val_f1: 0.6349\n",
      "Epoch 23/100\n",
      "27747/27747 [==============================] - 20s 704us/sample - loss: 0.4402 - f1: 0.6912 - val_loss: 0.7721 - val_f1: 0.6359\n",
      "Epoch 24/100\n",
      "27747/27747 [==============================] - 20s 707us/sample - loss: 0.4056 - f1: 0.6909 - val_loss: 0.7536 - val_f1: 0.6385\n",
      "Epoch 25/100\n",
      "27747/27747 [==============================] - 20s 708us/sample - loss: 0.4229 - f1: 0.6909 - val_loss: 0.7146 - val_f1: 0.6382\n",
      "Epoch 26/100\n",
      "27747/27747 [==============================] - 20s 710us/sample - loss: 0.3640 - f1: 0.6906 - val_loss: 0.7896 - val_f1: 0.6378\n",
      "Epoch 27/100\n",
      "27747/27747 [==============================] - 20s 708us/sample - loss: 0.3125 - f1: 0.6903 - val_loss: 0.6711 - val_f1: 0.6384\n",
      "Epoch 28/100\n",
      "27747/27747 [==============================] - 20s 709us/sample - loss: 0.2980 - f1: 0.6908 - val_loss: 0.7074 - val_f1: 0.6367\n",
      "Epoch 29/100\n",
      "27747/27747 [==============================] - 20s 710us/sample - loss: 0.2693 - f1: 0.6908 - val_loss: 0.8900 - val_f1: 0.6378\n",
      "Epoch 30/100\n",
      "27747/27747 [==============================] - 20s 708us/sample - loss: 0.2516 - f1: 0.6908 - val_loss: 0.6288 - val_f1: 0.6354\n",
      "Epoch 31/100\n",
      "27747/27747 [==============================] - 20s 707us/sample - loss: 0.2913 - f1: 0.6909 - val_loss: 0.6356 - val_f1: 0.6389\n",
      "Epoch 32/100\n",
      "27747/27747 [==============================] - 20s 711us/sample - loss: 0.2556 - f1: 0.6910 - val_loss: 0.7444 - val_f1: 0.6381\n",
      "Epoch 33/100\n",
      "27747/27747 [==============================] - 20s 708us/sample - loss: 0.2451 - f1: 0.6911 - val_loss: 0.7310 - val_f1: 0.6386\n",
      "Epoch 34/100\n",
      "27747/27747 [==============================] - 20s 709us/sample - loss: 0.2349 - f1: 0.6909 - val_loss: 0.6217 - val_f1: 0.6388\n",
      "Epoch 35/100\n",
      "27747/27747 [==============================] - 20s 708us/sample - loss: 0.2274 - f1: 0.6911 - val_loss: 0.6304 - val_f1: 0.6375\n",
      "Epoch 36/100\n",
      "27747/27747 [==============================] - 20s 708us/sample - loss: 0.2133 - f1: 0.6905 - val_loss: 0.7089 - val_f1: 0.6381\n",
      "Epoch 37/100\n",
      "27747/27747 [==============================] - 20s 709us/sample - loss: 0.2084 - f1: 0.6911 - val_loss: 0.4805 - val_f1: 0.6378\n",
      "Epoch 38/100\n",
      "27747/27747 [==============================] - 20s 709us/sample - loss: 0.2050 - f1: 0.6908 - val_loss: 0.7100 - val_f1: 0.6351\n",
      "Epoch 39/100\n",
      "27747/27747 [==============================] - 20s 705us/sample - loss: 0.2055 - f1: 0.6914 - val_loss: 0.6090 - val_f1: 0.6364\n",
      "Epoch 40/100\n",
      "27747/27747 [==============================] - 20s 703us/sample - loss: 0.1917 - f1: 0.6901 - val_loss: 0.6544 - val_f1: 0.6368\n",
      "Epoch 41/100\n",
      "27747/27747 [==============================] - 20s 707us/sample - loss: 0.1841 - f1: 0.6905 - val_loss: 0.5290 - val_f1: 0.6352\n",
      "Epoch 42/100\n",
      "27747/27747 [==============================] - 20s 710us/sample - loss: 0.1787 - f1: 0.6908 - val_loss: 0.5558 - val_f1: 0.6368\n",
      "Epoch 43/100\n",
      "27747/27747 [==============================] - 20s 717us/sample - loss: 0.1710 - f1: 0.6908 - val_loss: 0.7072 - val_f1: 0.6394\n",
      "Epoch 44/100\n",
      "27747/27747 [==============================] - 20s 717us/sample - loss: 0.1749 - f1: 0.6905 - val_loss: 0.9908 - val_f1: 0.6386\n",
      "Epoch 45/100\n",
      "27747/27747 [==============================] - 20s 714us/sample - loss: 0.1762 - f1: 0.6910 - val_loss: 0.5907 - val_f1: 0.6389\n",
      "Epoch 46/100\n",
      "27747/27747 [==============================] - 20s 704us/sample - loss: 0.1610 - f1: 0.6907 - val_loss: 0.5453 - val_f1: 0.6389\n",
      "Epoch 47/100\n",
      "27747/27747 [==============================] - 20s 711us/sample - loss: 0.1598 - f1: 0.6908 - val_loss: 0.8136 - val_f1: 0.6381\n",
      "Epoch 48/100\n",
      "27747/27747 [==============================] - 20s 710us/sample - loss: 0.1525 - f1: 0.6907 - val_loss: 0.6632 - val_f1: 0.6376\n",
      "Epoch 49/100\n",
      "27747/27747 [==============================] - 20s 721us/sample - loss: 0.1571 - f1: 0.6908 - val_loss: 0.9057 - val_f1: 0.6395\n",
      "Epoch 50/100\n",
      "27747/27747 [==============================] - 20s 713us/sample - loss: 0.1528 - f1: 0.6912 - val_loss: 0.5426 - val_f1: 0.6346\n",
      "Epoch 51/100\n",
      "27747/27747 [==============================] - 20s 708us/sample - loss: 0.1503 - f1: 0.6914 - val_loss: 0.4074 - val_f1: 0.6349\n",
      "Epoch 52/100\n",
      "27747/27747 [==============================] - 20s 713us/sample - loss: 0.1488 - f1: 0.6913 - val_loss: 0.7223 - val_f1: 0.6378\n",
      "Epoch 53/100\n",
      "27747/27747 [==============================] - 20s 737us/sample - loss: 0.1410 - f1: 0.6910 - val_loss: 0.7719 - val_f1: 0.6382\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 54/100\n",
      "27747/27747 [==============================] - 20s 710us/sample - loss: 0.1458 - f1: 0.6911 - val_loss: 0.7870 - val_f1: 0.6383\n",
      "Epoch 55/100\n",
      "27747/27747 [==============================] - 20s 705us/sample - loss: 0.1429 - f1: 0.6911 - val_loss: 0.5933 - val_f1: 0.6362\n",
      "Epoch 56/100\n",
      "27747/27747 [==============================] - 19s 699us/sample - loss: 0.1372 - f1: 0.6906 - val_loss: 0.5144 - val_f1: 0.6367\n",
      "Epoch 57/100\n",
      "27747/27747 [==============================] - 19s 701us/sample - loss: 0.1358 - f1: 0.6911 - val_loss: 0.7907 - val_f1: 0.6390\n",
      "Epoch 58/100\n",
      "27747/27747 [==============================] - 19s 703us/sample - loss: 0.1351 - f1: 0.6907 - val_loss: 1.0137 - val_f1: 0.6378\n",
      "Epoch 59/100\n",
      "27747/27747 [==============================] - 19s 702us/sample - loss: 0.1332 - f1: 0.6915 - val_loss: 0.4650 - val_f1: 0.6359\n",
      "Epoch 60/100\n",
      "27747/27747 [==============================] - 19s 702us/sample - loss: 0.1327 - f1: 0.6907 - val_loss: 0.5959 - val_f1: 0.6375\n",
      "Epoch 61/100\n",
      "27747/27747 [==============================] - 20s 703us/sample - loss: 0.1293 - f1: 0.6909 - val_loss: 0.5275 - val_f1: 0.6386\n",
      "Epoch 62/100\n",
      "27747/27747 [==============================] - 20s 704us/sample - loss: 0.1297 - f1: 0.6908 - val_loss: 0.8451 - val_f1: 0.6354\n",
      "Epoch 63/100\n",
      "27747/27747 [==============================] - 20s 705us/sample - loss: 0.1321 - f1: 0.6911 - val_loss: 0.6751 - val_f1: 0.6376\n",
      "Epoch 64/100\n",
      "27747/27747 [==============================] - 20s 704us/sample - loss: 0.1287 - f1: 0.6911 - val_loss: 0.5938 - val_f1: 0.6372\n",
      "Epoch 65/100\n",
      "27747/27747 [==============================] - 20s 704us/sample - loss: 0.1241 - f1: 0.6914 - val_loss: 0.9759 - val_f1: 0.6379\n",
      "Epoch 66/100\n",
      "27747/27747 [==============================] - 20s 703us/sample - loss: 0.1241 - f1: 0.6909 - val_loss: 0.6737 - val_f1: 0.6376\n",
      "Epoch 67/100\n",
      "27747/27747 [==============================] - 20s 703us/sample - loss: 0.1203 - f1: 0.6912 - val_loss: 0.6873 - val_f1: 0.6370\n",
      "Epoch 68/100\n",
      "27747/27747 [==============================] - 19s 699us/sample - loss: 0.1246 - f1: 0.6911 - val_loss: 0.7888 - val_f1: 0.6384\n",
      "Epoch 69/100\n",
      "27747/27747 [==============================] - 19s 703us/sample - loss: 0.1249 - f1: 0.6913 - val_loss: 0.9749 - val_f1: 0.6384\n",
      "Epoch 70/100\n",
      "27747/27747 [==============================] - 20s 705us/sample - loss: 0.1191 - f1: 0.6910 - val_loss: 0.6086 - val_f1: 0.6376\n",
      "Epoch 71/100\n",
      "27747/27747 [==============================] - 20s 704us/sample - loss: 0.1178 - f1: 0.6902 - val_loss: 0.8777 - val_f1: 0.6358\n",
      "Epoch 72/100\n",
      "27747/27747 [==============================] - 20s 704us/sample - loss: 0.1168 - f1: 0.6902 - val_loss: 0.7140 - val_f1: 0.6373\n",
      "Epoch 73/100\n",
      "27747/27747 [==============================] - 20s 703us/sample - loss: 0.1163 - f1: 0.6913 - val_loss: 0.6421 - val_f1: 0.6384\n",
      "Epoch 74/100\n",
      "27747/27747 [==============================] - 20s 704us/sample - loss: 0.1146 - f1: 0.6915 - val_loss: 0.9421 - val_f1: 0.6394\n",
      "Epoch 75/100\n",
      "27747/27747 [==============================] - 20s 707us/sample - loss: 0.1148 - f1: 0.6912 - val_loss: 0.6362 - val_f1: 0.6383\n",
      "Epoch 76/100\n",
      "27747/27747 [==============================] - 20s 707us/sample - loss: 0.1279 - f1: 0.6908 - val_loss: 0.7409 - val_f1: 0.6372\n",
      "Epoch 77/100\n",
      "27747/27747 [==============================] - 20s 705us/sample - loss: 0.1131 - f1: 0.6911 - val_loss: 0.5592 - val_f1: 0.6382\n",
      "Epoch 78/100\n",
      "27747/27747 [==============================] - 20s 706us/sample - loss: 0.1144 - f1: 0.6906 - val_loss: 0.6686 - val_f1: 0.6365\n",
      "Epoch 79/100\n",
      "27747/27747 [==============================] - 20s 705us/sample - loss: 0.1146 - f1: 0.6911 - val_loss: 0.7979 - val_f1: 0.6370\n",
      "Epoch 80/100\n",
      "27747/27747 [==============================] - 19s 698us/sample - loss: 0.1094 - f1: 0.6899 - val_loss: 0.6461 - val_f1: 0.6365\n",
      "Epoch 81/100\n",
      "27747/27747 [==============================] - 20s 706us/sample - loss: 0.1818 - f1: 0.6913 - val_loss: 0.5235 - val_f1: 0.6361\n",
      "Epoch 82/100\n",
      "27747/27747 [==============================] - 20s 706us/sample - loss: 0.1335 - f1: 0.6910 - val_loss: 0.5432 - val_f1: 0.6369\n",
      "Epoch 83/100\n",
      "27747/27747 [==============================] - 20s 707us/sample - loss: 0.1142 - f1: 0.6911 - val_loss: 0.5631 - val_f1: 0.6365\n",
      "Epoch 84/100\n",
      "27747/27747 [==============================] - 20s 708us/sample - loss: 0.1077 - f1: 0.6909 - val_loss: 0.8992 - val_f1: 0.6369\n",
      "Epoch 85/100\n",
      "27747/27747 [==============================] - 20s 706us/sample - loss: 0.1122 - f1: 0.6913 - val_loss: 0.5459 - val_f1: 0.6370\n",
      "Epoch 86/100\n",
      "27747/27747 [==============================] - 20s 712us/sample - loss: 0.1035 - f1: 0.6912 - val_loss: 0.7681 - val_f1: 0.6384\n",
      "Epoch 87/100\n",
      "27747/27747 [==============================] - 20s 715us/sample - loss: 0.1042 - f1: 0.6908 - val_loss: 0.6360 - val_f1: 0.6385\n",
      "Epoch 88/100\n",
      "27747/27747 [==============================] - 19s 701us/sample - loss: 0.1090 - f1: 0.6907 - val_loss: 0.7321 - val_f1: 0.6380\n",
      "Epoch 89/100\n",
      "27747/27747 [==============================] - 20s 717us/sample - loss: 0.1022 - f1: 0.6907 - val_loss: 0.8299 - val_f1: 0.6386\n",
      "Epoch 90/100\n",
      "27747/27747 [==============================] - 20s 708us/sample - loss: 0.1048 - f1: 0.6911 - val_loss: 0.8862 - val_f1: 0.6383\n",
      "Epoch 91/100\n",
      "27747/27747 [==============================] - 20s 704us/sample - loss: 0.1007 - f1: 0.6903 - val_loss: 0.6751 - val_f1: 0.6389\n",
      "Epoch 92/100\n",
      "27747/27747 [==============================] - 19s 701us/sample - loss: 0.0986 - f1: 0.6908 - val_loss: 0.8341 - val_f1: 0.6375\n",
      "Epoch 93/100\n",
      "27747/27747 [==============================] - 20s 708us/sample - loss: 0.0974 - f1: 0.6912 - val_loss: 0.5802 - val_f1: 0.6374\n",
      "Epoch 94/100\n",
      "27747/27747 [==============================] - 20s 709us/sample - loss: 0.1018 - f1: 0.6907 - val_loss: 0.6966 - val_f1: 0.6400\n",
      "Epoch 95/100\n",
      "27747/27747 [==============================] - 20s 708us/sample - loss: 0.0998 - f1: 0.6910 - val_loss: 0.8642 - val_f1: 0.6382\n",
      "Epoch 96/100\n",
      "27747/27747 [==============================] - 20s 708us/sample - loss: 0.0956 - f1: 0.6909 - val_loss: 0.9640 - val_f1: 0.6370\n",
      "Epoch 97/100\n",
      "27747/27747 [==============================] - 20s 708us/sample - loss: 0.0952 - f1: 0.6915 - val_loss: 0.7984 - val_f1: 0.6369\n",
      "Epoch 98/100\n",
      "27747/27747 [==============================] - 20s 709us/sample - loss: 0.0947 - f1: 0.6908 - val_loss: 0.6304 - val_f1: 0.6376\n",
      "Epoch 99/100\n",
      "27747/27747 [==============================] - 20s 707us/sample - loss: 0.0943 - f1: 0.6910 - val_loss: 0.7134 - val_f1: 0.6388\n",
      "Epoch 100/100\n",
      "27747/27747 [==============================] - 20s 704us/sample - loss: 0.0947 - f1: 0.6909 - val_loss: 0.6779 - val_f1: 0.6376\n",
      "FIT\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0816 20:19:28.716746 140241072178944 ag_logging.py:145] Entity <function standard_lstm at 0x7f8c0ce8f268> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: No module named 'tensorflow_core.contrib'\n",
      "W0816 20:19:28.808675 140241072178944 ag_logging.py:145] Entity <function cudnn_lstm at 0x7f8c0ce8f2f0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: No module named 'tensorflow_core.contrib'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PREDICT\n",
      "Group 2\n",
      "[0.79984271 0.75727229]\n",
      "macro 0.7785574996094827\n",
      "3\n",
      "50\n",
      "WARNING: Entity <function standard_lstm at 0x7f8c0ce8f268> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: No module named 'tensorflow_core.contrib'\n",
      "WARNING: Entity <function cudnn_lstm at 0x7f8c0ce8f2f0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: No module named 'tensorflow_core.contrib'\n",
      "OKKKK\n",
      "YOOOO\n",
      "Train on 26301 samples, validate on 3766 samples\n",
      "Epoch 1/100\n",
      "26301/26301 [==============================] - 20s 750us/sample - loss: 0.7072 - f1: 0.6759 - val_loss: 0.6903 - val_f1: 0.6950\n",
      "Epoch 2/100\n",
      "26301/26301 [==============================] - 19s 715us/sample - loss: 0.6925 - f1: 0.6845 - val_loss: 0.6973 - val_f1: 0.6943\n",
      "Epoch 3/100\n",
      "26301/26301 [==============================] - 19s 707us/sample - loss: 0.6306 - f1: 0.6850 - val_loss: 0.4771 - val_f1: 0.6946\n",
      "Epoch 4/100\n",
      "26301/26301 [==============================] - 19s 715us/sample - loss: 0.4851 - f1: 0.6857 - val_loss: 0.8383 - val_f1: 0.6954\n",
      "Epoch 5/100\n",
      "26301/26301 [==============================] - 19s 716us/sample - loss: 0.3999 - f1: 0.6857 - val_loss: 1.0019 - val_f1: 0.6964\n",
      "Epoch 6/100\n",
      "26301/26301 [==============================] - 19s 718us/sample - loss: 0.3346 - f1: 0.6856 - val_loss: 0.9712 - val_f1: 0.6958\n",
      "Epoch 7/100\n",
      "26301/26301 [==============================] - 19s 715us/sample - loss: 0.3248 - f1: 0.6854 - val_loss: 0.8582 - val_f1: 0.6950\n",
      "Epoch 8/100\n",
      "26301/26301 [==============================] - 19s 716us/sample - loss: 0.3059 - f1: 0.6857 - val_loss: 0.7422 - val_f1: 0.6954\n",
      "Epoch 9/100\n",
      "26301/26301 [==============================] - 19s 714us/sample - loss: 0.2975 - f1: 0.6857 - val_loss: 0.8131 - val_f1: 0.6949\n",
      "Epoch 10/100\n",
      "26301/26301 [==============================] - 19s 715us/sample - loss: 0.2890 - f1: 0.6852 - val_loss: 0.8311 - val_f1: 0.6953\n",
      "Epoch 11/100\n",
      "26301/26301 [==============================] - 19s 716us/sample - loss: 0.2788 - f1: 0.6857 - val_loss: 0.8857 - val_f1: 0.6962\n",
      "Epoch 12/100\n",
      "26301/26301 [==============================] - 19s 719us/sample - loss: 0.2671 - f1: 0.6856 - val_loss: 0.7315 - val_f1: 0.6947\n",
      "Epoch 13/100\n",
      "26301/26301 [==============================] - 19s 717us/sample - loss: 0.2607 - f1: 0.6857 - val_loss: 0.7662 - val_f1: 0.6961\n",
      "Epoch 14/100\n",
      "26301/26301 [==============================] - 19s 716us/sample - loss: 0.2618 - f1: 0.6856 - val_loss: 0.7091 - val_f1: 0.6955\n",
      "Epoch 15/100\n",
      "26301/26301 [==============================] - 19s 719us/sample - loss: 0.2459 - f1: 0.6858 - val_loss: 0.8328 - val_f1: 0.6967\n",
      "Epoch 16/100\n",
      "26301/26301 [==============================] - 19s 715us/sample - loss: 0.2385 - f1: 0.6855 - val_loss: 0.7810 - val_f1: 0.6968\n",
      "Epoch 17/100\n",
      "26301/26301 [==============================] - 19s 710us/sample - loss: 0.2290 - f1: 0.6856 - val_loss: 0.5963 - val_f1: 0.6952\n",
      "Epoch 18/100\n",
      "26301/26301 [==============================] - 19s 719us/sample - loss: 0.2257 - f1: 0.6857 - val_loss: 0.8033 - val_f1: 0.6959\n",
      "Epoch 19/100\n",
      "26301/26301 [==============================] - 19s 719us/sample - loss: 0.2216 - f1: 0.6855 - val_loss: 0.6544 - val_f1: 0.6948\n",
      "Epoch 20/100\n",
      "26301/26301 [==============================] - 19s 721us/sample - loss: 0.2135 - f1: 0.6857 - val_loss: 0.8991 - val_f1: 0.6958\n",
      "Epoch 21/100\n",
      "26301/26301 [==============================] - 19s 715us/sample - loss: 0.2129 - f1: 0.6858 - val_loss: 0.5405 - val_f1: 0.6957\n",
      "Epoch 22/100\n",
      "26301/26301 [==============================] - 19s 719us/sample - loss: 0.2046 - f1: 0.6853 - val_loss: 0.8786 - val_f1: 0.6963\n",
      "Epoch 23/100\n",
      "26301/26301 [==============================] - 19s 710us/sample - loss: 0.2047 - f1: 0.6855 - val_loss: 0.4204 - val_f1: 0.6963\n",
      "Epoch 24/100\n",
      "26301/26301 [==============================] - 19s 716us/sample - loss: 0.2001 - f1: 0.6857 - val_loss: 0.7460 - val_f1: 0.6951\n",
      "Epoch 25/100\n",
      "26301/26301 [==============================] - 19s 720us/sample - loss: 0.1969 - f1: 0.6857 - val_loss: 0.5362 - val_f1: 0.6959\n",
      "Epoch 26/100\n",
      "26301/26301 [==============================] - 19s 719us/sample - loss: 0.1942 - f1: 0.6854 - val_loss: 0.6320 - val_f1: 0.6954\n",
      "Epoch 27/100\n",
      "26301/26301 [==============================] - 19s 718us/sample - loss: 0.1903 - f1: 0.6860 - val_loss: 0.5715 - val_f1: 0.6949\n",
      "Epoch 28/100\n",
      "26301/26301 [==============================] - 19s 719us/sample - loss: 0.1842 - f1: 0.6858 - val_loss: 0.5813 - val_f1: 0.6960\n",
      "Epoch 29/100\n",
      "26301/26301 [==============================] - 19s 718us/sample - loss: 0.1848 - f1: 0.6859 - val_loss: 0.8011 - val_f1: 0.6952\n",
      "Epoch 30/100\n",
      "26301/26301 [==============================] - 19s 719us/sample - loss: 0.1825 - f1: 0.6856 - val_loss: 0.4374 - val_f1: 0.6964\n",
      "Epoch 31/100\n",
      "26301/26301 [==============================] - 19s 720us/sample - loss: 0.1807 - f1: 0.6859 - val_loss: 0.4744 - val_f1: 0.6952\n",
      "Epoch 32/100\n",
      "26301/26301 [==============================] - 19s 720us/sample - loss: 0.1759 - f1: 0.6860 - val_loss: 0.3835 - val_f1: 0.6957\n",
      "Epoch 33/100\n",
      "26301/26301 [==============================] - 19s 708us/sample - loss: 0.1702 - f1: 0.6858 - val_loss: 0.4640 - val_f1: 0.6954\n",
      "Epoch 34/100\n",
      "26301/26301 [==============================] - 19s 720us/sample - loss: 0.1697 - f1: 0.6863 - val_loss: 0.4223 - val_f1: 0.6955\n",
      "Epoch 35/100\n",
      "26301/26301 [==============================] - 19s 718us/sample - loss: 0.1677 - f1: 0.6858 - val_loss: 0.3641 - val_f1: 0.6947\n",
      "Epoch 36/100\n",
      "26301/26301 [==============================] - 19s 719us/sample - loss: 0.1648 - f1: 0.6859 - val_loss: 0.3677 - val_f1: 0.6951\n",
      "Epoch 37/100\n",
      "26301/26301 [==============================] - 19s 720us/sample - loss: 0.1614 - f1: 0.6857 - val_loss: 0.5478 - val_f1: 0.6955\n",
      "Epoch 38/100\n",
      "26301/26301 [==============================] - 19s 721us/sample - loss: 0.1632 - f1: 0.6853 - val_loss: 0.3254 - val_f1: 0.6959\n",
      "Epoch 39/100\n",
      "26301/26301 [==============================] - 19s 716us/sample - loss: 0.1549 - f1: 0.6858 - val_loss: 0.4065 - val_f1: 0.6955\n",
      "Epoch 40/100\n",
      "26301/26301 [==============================] - 19s 720us/sample - loss: 0.1564 - f1: 0.6857 - val_loss: 0.4047 - val_f1: 0.6952\n",
      "Epoch 41/100\n",
      "26301/26301 [==============================] - 19s 712us/sample - loss: 0.1563 - f1: 0.6855 - val_loss: 0.2367 - val_f1: 0.6963\n",
      "Epoch 42/100\n",
      "26301/26301 [==============================] - 19s 722us/sample - loss: 0.1525 - f1: 0.6856 - val_loss: 0.5399 - val_f1: 0.6964\n",
      "Epoch 43/100\n",
      "26301/26301 [==============================] - 19s 721us/sample - loss: 0.1480 - f1: 0.6857 - val_loss: 0.3985 - val_f1: 0.6955\n",
      "Epoch 44/100\n",
      "26301/26301 [==============================] - 19s 723us/sample - loss: 0.1466 - f1: 0.6853 - val_loss: 0.4002 - val_f1: 0.6940\n",
      "Epoch 45/100\n",
      "26301/26301 [==============================] - 19s 721us/sample - loss: 0.1481 - f1: 0.6858 - val_loss: 0.4225 - val_f1: 0.6958\n",
      "Epoch 46/100\n",
      "26301/26301 [==============================] - 19s 722us/sample - loss: 0.1472 - f1: 0.6856 - val_loss: 0.3866 - val_f1: 0.6954\n",
      "Epoch 47/100\n",
      "26301/26301 [==============================] - 19s 720us/sample - loss: 0.1459 - f1: 0.6857 - val_loss: 0.3564 - val_f1: 0.6954\n",
      "Epoch 48/100\n",
      "26301/26301 [==============================] - 19s 723us/sample - loss: 0.1405 - f1: 0.6857 - val_loss: 0.7739 - val_f1: 0.6959\n",
      "Epoch 49/100\n",
      "26301/26301 [==============================] - 19s 722us/sample - loss: 0.1425 - f1: 0.6859 - val_loss: 0.6747 - val_f1: 0.6957\n",
      "Epoch 50/100\n",
      "26301/26301 [==============================] - 19s 725us/sample - loss: 0.1395 - f1: 0.6858 - val_loss: 0.5606 - val_f1: 0.6952\n",
      "Epoch 51/100\n",
      "26301/26301 [==============================] - 19s 723us/sample - loss: 0.1421 - f1: 0.6854 - val_loss: 0.3011 - val_f1: 0.6954\n",
      "Epoch 52/100\n",
      "26301/26301 [==============================] - 19s 710us/sample - loss: 0.1335 - f1: 0.6855 - val_loss: 0.6640 - val_f1: 0.6971\n",
      "Epoch 53/100\n",
      "26301/26301 [==============================] - 19s 721us/sample - loss: 0.1456 - f1: 0.6858 - val_loss: 0.3725 - val_f1: 0.6956\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 54/100\n",
      "26301/26301 [==============================] - 19s 713us/sample - loss: 0.1320 - f1: 0.6859 - val_loss: 0.2995 - val_f1: 0.6957\n",
      "Epoch 55/100\n",
      "26301/26301 [==============================] - 19s 720us/sample - loss: 0.1333 - f1: 0.6858 - val_loss: 0.3787 - val_f1: 0.6958\n",
      "Epoch 56/100\n",
      "26301/26301 [==============================] - 19s 734us/sample - loss: 0.1285 - f1: 0.6857 - val_loss: 0.4557 - val_f1: 0.6954\n",
      "Epoch 57/100\n",
      "26301/26301 [==============================] - 19s 735us/sample - loss: 0.1281 - f1: 0.6854 - val_loss: 0.8110 - val_f1: 0.6955\n",
      "Epoch 58/100\n",
      "26301/26301 [==============================] - 19s 734us/sample - loss: 0.1279 - f1: 0.6858 - val_loss: 0.5277 - val_f1: 0.6963\n",
      "Epoch 59/100\n",
      "26301/26301 [==============================] - 19s 734us/sample - loss: 0.1309 - f1: 0.6856 - val_loss: 0.3683 - val_f1: 0.6961\n",
      "Epoch 60/100\n",
      "26301/26301 [==============================] - 19s 734us/sample - loss: 0.1252 - f1: 0.6858 - val_loss: 0.7659 - val_f1: 0.6953\n",
      "Epoch 61/100\n",
      "26301/26301 [==============================] - 19s 733us/sample - loss: 0.1213 - f1: 0.6852 - val_loss: 0.9251 - val_f1: 0.6967\n",
      "Epoch 62/100\n",
      "26301/26301 [==============================] - 19s 727us/sample - loss: 0.1222 - f1: 0.6858 - val_loss: 0.4393 - val_f1: 0.6950\n",
      "Epoch 63/100\n",
      "26301/26301 [==============================] - 20s 745us/sample - loss: 0.1235 - f1: 0.6858 - val_loss: 1.0128 - val_f1: 0.6958\n",
      "Epoch 64/100\n",
      "26301/26301 [==============================] - 19s 726us/sample - loss: 0.1205 - f1: 0.6858 - val_loss: 0.5598 - val_f1: 0.6957\n",
      "Epoch 65/100\n",
      "26301/26301 [==============================] - 19s 732us/sample - loss: 0.1168 - f1: 0.6857 - val_loss: 0.6482 - val_f1: 0.6956\n",
      "Epoch 66/100\n",
      "26301/26301 [==============================] - 19s 719us/sample - loss: 0.1205 - f1: 0.6858 - val_loss: 0.5389 - val_f1: 0.6959\n",
      "Epoch 67/100\n",
      "26301/26301 [==============================] - 19s 719us/sample - loss: 0.1158 - f1: 0.6855 - val_loss: 0.3077 - val_f1: 0.6969\n",
      "Epoch 68/100\n",
      "26301/26301 [==============================] - 19s 719us/sample - loss: 0.1174 - f1: 0.6854 - val_loss: 0.9171 - val_f1: 0.6958\n",
      "Epoch 69/100\n",
      "26301/26301 [==============================] - 19s 723us/sample - loss: 0.1168 - f1: 0.6857 - val_loss: 0.7497 - val_f1: 0.6950\n",
      "Epoch 70/100\n",
      "26301/26301 [==============================] - 19s 721us/sample - loss: 0.1177 - f1: 0.6855 - val_loss: 0.6039 - val_f1: 0.6960\n",
      "Epoch 71/100\n",
      "26301/26301 [==============================] - 19s 721us/sample - loss: 0.1177 - f1: 0.6854 - val_loss: 0.8643 - val_f1: 0.6960\n",
      "Epoch 72/100\n",
      "26301/26301 [==============================] - 19s 721us/sample - loss: 0.1145 - f1: 0.6860 - val_loss: 1.1053 - val_f1: 0.6955\n",
      "Epoch 73/100\n",
      "26301/26301 [==============================] - 19s 720us/sample - loss: 0.1136 - f1: 0.6857 - val_loss: 0.4761 - val_f1: 0.6958\n",
      "Epoch 74/100\n",
      "26301/26301 [==============================] - 19s 719us/sample - loss: 0.1139 - f1: 0.6856 - val_loss: 0.5402 - val_f1: 0.6956\n",
      "Epoch 75/100\n",
      "26301/26301 [==============================] - 19s 723us/sample - loss: 0.1075 - f1: 0.6854 - val_loss: 0.4905 - val_f1: 0.6947\n",
      "Epoch 76/100\n",
      "26301/26301 [==============================] - 19s 720us/sample - loss: 0.1104 - f1: 0.6858 - val_loss: 0.9431 - val_f1: 0.6956\n",
      "Epoch 77/100\n",
      "26301/26301 [==============================] - 19s 722us/sample - loss: 0.1131 - f1: 0.6855 - val_loss: 0.6274 - val_f1: 0.6954\n",
      "Epoch 78/100\n",
      "26301/26301 [==============================] - 19s 721us/sample - loss: 0.1162 - f1: 0.6858 - val_loss: 0.6568 - val_f1: 0.6963\n",
      "Epoch 79/100\n",
      "26301/26301 [==============================] - 19s 721us/sample - loss: 0.1039 - f1: 0.6854 - val_loss: 0.6447 - val_f1: 0.6971\n",
      "Epoch 80/100\n",
      "26301/26301 [==============================] - 19s 721us/sample - loss: 0.1023 - f1: 0.6856 - val_loss: 0.7993 - val_f1: 0.6961\n",
      "Epoch 81/100\n",
      "26301/26301 [==============================] - 19s 721us/sample - loss: 0.1061 - f1: 0.6857 - val_loss: 0.6865 - val_f1: 0.6963\n",
      "Epoch 82/100\n",
      "26301/26301 [==============================] - 19s 726us/sample - loss: 0.1081 - f1: 0.6856 - val_loss: 0.5540 - val_f1: 0.6967\n",
      "Epoch 83/100\n",
      "26301/26301 [==============================] - 19s 723us/sample - loss: 0.1008 - f1: 0.6855 - val_loss: 0.7266 - val_f1: 0.6959\n",
      "Epoch 84/100\n",
      "26301/26301 [==============================] - 19s 716us/sample - loss: 0.1167 - f1: 0.6858 - val_loss: 0.4555 - val_f1: 0.6954\n",
      "Epoch 85/100\n",
      "26301/26301 [==============================] - 19s 717us/sample - loss: 0.0966 - f1: 0.6856 - val_loss: 1.1190 - val_f1: 0.6947\n",
      "Epoch 86/100\n",
      "26301/26301 [==============================] - 19s 722us/sample - loss: 0.1082 - f1: 0.6860 - val_loss: 0.7755 - val_f1: 0.6969\n",
      "Epoch 87/100\n",
      "26301/26301 [==============================] - 19s 724us/sample - loss: 0.1003 - f1: 0.6857 - val_loss: 0.4515 - val_f1: 0.6965\n",
      "Epoch 88/100\n",
      "26301/26301 [==============================] - 19s 732us/sample - loss: 0.1004 - f1: 0.6860 - val_loss: 0.6131 - val_f1: 0.6954\n",
      "Epoch 89/100\n",
      "26301/26301 [==============================] - 19s 716us/sample - loss: 0.0968 - f1: 0.6862 - val_loss: 0.7186 - val_f1: 0.6965\n",
      "Epoch 90/100\n",
      "26301/26301 [==============================] - 19s 726us/sample - loss: 0.0999 - f1: 0.6859 - val_loss: 0.8160 - val_f1: 0.6946\n",
      "Epoch 91/100\n",
      "26301/26301 [==============================] - 19s 729us/sample - loss: 0.0950 - f1: 0.6856 - val_loss: 0.5646 - val_f1: 0.6957\n",
      "Epoch 92/100\n",
      "26301/26301 [==============================] - 19s 714us/sample - loss: 0.0976 - f1: 0.6856 - val_loss: 0.5735 - val_f1: 0.6950\n",
      "Epoch 93/100\n",
      "26301/26301 [==============================] - 19s 731us/sample - loss: 0.0999 - f1: 0.6855 - val_loss: 0.6628 - val_f1: 0.6952\n",
      "Epoch 94/100\n",
      "26301/26301 [==============================] - 19s 728us/sample - loss: 0.0962 - f1: 0.6851 - val_loss: 1.2825 - val_f1: 0.6959\n",
      "Epoch 95/100\n",
      "26301/26301 [==============================] - 19s 716us/sample - loss: 0.0941 - f1: 0.6856 - val_loss: 0.8632 - val_f1: 0.6954\n",
      "Epoch 96/100\n",
      "26301/26301 [==============================] - 19s 731us/sample - loss: 0.0908 - f1: 0.6853 - val_loss: 1.4788 - val_f1: 0.6962\n",
      "Epoch 97/100\n",
      "26301/26301 [==============================] - 19s 723us/sample - loss: 0.0891 - f1: 0.6853 - val_loss: 0.4601 - val_f1: 0.6973\n",
      "Epoch 98/100\n",
      "26301/26301 [==============================] - 19s 712us/sample - loss: 0.0908 - f1: 0.6857 - val_loss: 1.3087 - val_f1: 0.6956\n",
      "Epoch 99/100\n",
      "26301/26301 [==============================] - 19s 724us/sample - loss: 0.0909 - f1: 0.6858 - val_loss: 1.3151 - val_f1: 0.6959\n",
      "Epoch 100/100\n",
      "26301/26301 [==============================] - 19s 724us/sample - loss: 0.0898 - f1: 0.6855 - val_loss: 0.6128 - val_f1: 0.6962\n",
      "FIT\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0816 20:51:09.279698 140241072178944 ag_logging.py:145] Entity <function standard_lstm at 0x7f8c0ce8f268> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: No module named 'tensorflow_core.contrib'\n",
      "W0816 20:51:09.366507 140241072178944 ag_logging.py:145] Entity <function cudnn_lstm at 0x7f8c0ce8f2f0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: No module named 'tensorflow_core.contrib'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PREDICT\n",
      "Group 3\n",
      "[0.74807628 0.8342505 ]\n",
      "macro 0.7911633874798245\n",
      "3\n",
      "50\n",
      "WARNING: Entity <function standard_lstm at 0x7f8c0ce8f268> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: No module named 'tensorflow_core.contrib'\n",
      "WARNING: Entity <function cudnn_lstm at 0x7f8c0ce8f2f0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: No module named 'tensorflow_core.contrib'\n",
      "OKKKK\n",
      "YOOOO\n",
      "Train on 26384 samples, validate on 3683 samples\n",
      "Epoch 1/100\n",
      "26384/26384 [==============================] - 20s 751us/sample - loss: 0.7099 - f1: 0.6788 - val_loss: 0.6945 - val_f1: 0.6770\n",
      "Epoch 2/100\n",
      "26384/26384 [==============================] - 19s 712us/sample - loss: 0.6666 - f1: 0.6865 - val_loss: 0.9138 - val_f1: 0.6749\n",
      "Epoch 3/100\n",
      "26384/26384 [==============================] - 19s 714us/sample - loss: 0.5115 - f1: 0.6884 - val_loss: 1.0218 - val_f1: 0.6727\n",
      "Epoch 4/100\n",
      "26384/26384 [==============================] - 19s 714us/sample - loss: 0.4224 - f1: 0.6889 - val_loss: 1.3513 - val_f1: 0.6749\n",
      "Epoch 5/100\n",
      "26384/26384 [==============================] - 19s 716us/sample - loss: 0.3353 - f1: 0.6884 - val_loss: 1.5419 - val_f1: 0.6732\n",
      "Epoch 6/100\n",
      "26384/26384 [==============================] - 19s 713us/sample - loss: 0.3128 - f1: 0.6887 - val_loss: 1.5380 - val_f1: 0.6754\n",
      "Epoch 7/100\n",
      "26384/26384 [==============================] - 19s 718us/sample - loss: 0.2982 - f1: 0.6886 - val_loss: 1.3311 - val_f1: 0.6717\n",
      "Epoch 8/100\n",
      "26384/26384 [==============================] - 19s 708us/sample - loss: 0.2858 - f1: 0.6891 - val_loss: 1.4367 - val_f1: 0.6761\n",
      "Epoch 9/100\n",
      "26384/26384 [==============================] - 19s 717us/sample - loss: 0.2786 - f1: 0.6882 - val_loss: 1.5425 - val_f1: 0.6750\n",
      "Epoch 10/100\n",
      "26384/26384 [==============================] - 19s 715us/sample - loss: 0.2659 - f1: 0.6885 - val_loss: 2.1750 - val_f1: 0.6754\n",
      "Epoch 11/100\n",
      "26384/26384 [==============================] - 19s 717us/sample - loss: 0.2717 - f1: 0.6892 - val_loss: 1.7982 - val_f1: 0.6734\n",
      "Epoch 12/100\n",
      "26384/26384 [==============================] - 19s 721us/sample - loss: 0.2478 - f1: 0.6888 - val_loss: 2.0332 - val_f1: 0.6768\n",
      "Epoch 13/100\n",
      "26384/26384 [==============================] - 19s 721us/sample - loss: 0.2323 - f1: 0.6887 - val_loss: 1.7693 - val_f1: 0.6730\n",
      "Epoch 14/100\n",
      "26384/26384 [==============================] - 19s 717us/sample - loss: 0.2172 - f1: 0.6890 - val_loss: 2.6510 - val_f1: 0.6717\n",
      "Epoch 15/100\n",
      "26384/26384 [==============================] - 19s 712us/sample - loss: 0.2173 - f1: 0.6887 - val_loss: 2.8579 - val_f1: 0.6756\n",
      "Epoch 16/100\n",
      "26384/26384 [==============================] - 19s 717us/sample - loss: 0.2062 - f1: 0.6889 - val_loss: 2.0383 - val_f1: 0.6692\n",
      "Epoch 17/100\n",
      "26384/26384 [==============================] - 19s 718us/sample - loss: 0.1894 - f1: 0.6887 - val_loss: 2.6510 - val_f1: 0.6753\n",
      "Epoch 18/100\n",
      "26384/26384 [==============================] - 19s 716us/sample - loss: 0.1863 - f1: 0.6890 - val_loss: 3.0641 - val_f1: 0.6745\n",
      "Epoch 19/100\n",
      "26384/26384 [==============================] - 19s 719us/sample - loss: 0.1824 - f1: 0.6885 - val_loss: 1.9746 - val_f1: 0.6688\n",
      "Epoch 20/100\n",
      "26384/26384 [==============================] - 19s 718us/sample - loss: 0.1755 - f1: 0.6887 - val_loss: 2.6762 - val_f1: 0.6760\n",
      "Epoch 21/100\n",
      "26384/26384 [==============================] - 19s 718us/sample - loss: 0.1751 - f1: 0.6882 - val_loss: 1.8908 - val_f1: 0.6742\n",
      "Epoch 22/100\n",
      "26384/26384 [==============================] - 19s 717us/sample - loss: 0.1698 - f1: 0.6886 - val_loss: 2.1570 - val_f1: 0.6751\n",
      "Epoch 23/100\n",
      "26384/26384 [==============================] - 19s 718us/sample - loss: 0.1680 - f1: 0.6888 - val_loss: 2.7462 - val_f1: 0.6762\n",
      "Epoch 24/100\n",
      "26384/26384 [==============================] - 19s 717us/sample - loss: 0.1648 - f1: 0.6885 - val_loss: 2.7805 - val_f1: 0.6736\n",
      "Epoch 25/100\n",
      "26384/26384 [==============================] - 19s 718us/sample - loss: 0.1623 - f1: 0.6886 - val_loss: 2.1309 - val_f1: 0.6748\n",
      "Epoch 26/100\n",
      "26384/26384 [==============================] - 19s 718us/sample - loss: 0.1547 - f1: 0.6887 - val_loss: 3.0204 - val_f1: 0.6752\n",
      "Epoch 27/100\n",
      "26384/26384 [==============================] - 19s 718us/sample - loss: 0.1531 - f1: 0.6890 - val_loss: 3.0827 - val_f1: 0.6727\n",
      "Epoch 28/100\n",
      "26384/26384 [==============================] - 19s 717us/sample - loss: 0.1491 - f1: 0.6888 - val_loss: 1.9971 - val_f1: 0.6742\n",
      "Epoch 29/100\n",
      "26384/26384 [==============================] - 19s 725us/sample - loss: 0.1462 - f1: 0.6886 - val_loss: 2.0742 - val_f1: 0.6766\n",
      "Epoch 30/100\n",
      "26384/26384 [==============================] - 19s 729us/sample - loss: 0.1478 - f1: 0.6884 - val_loss: 3.3144 - val_f1: 0.6760\n",
      "Epoch 31/100\n",
      "26384/26384 [==============================] - 19s 716us/sample - loss: 0.1432 - f1: 0.6891 - val_loss: 3.6274 - val_f1: 0.6750\n",
      "Epoch 32/100\n",
      "26384/26384 [==============================] - 20s 740us/sample - loss: 0.1461 - f1: 0.6884 - val_loss: 3.4038 - val_f1: 0.6686\n",
      "Epoch 33/100\n",
      "26384/26384 [==============================] - 19s 722us/sample - loss: 0.1437 - f1: 0.6887 - val_loss: 2.6477 - val_f1: 0.6725\n",
      "Epoch 34/100\n",
      "26384/26384 [==============================] - 19s 715us/sample - loss: 0.1418 - f1: 0.6886 - val_loss: 2.4987 - val_f1: 0.6760\n",
      "Epoch 35/100\n",
      "26384/26384 [==============================] - 19s 727us/sample - loss: 0.1339 - f1: 0.6888 - val_loss: 2.6404 - val_f1: 0.6682\n",
      "Epoch 36/100\n",
      "26384/26384 [==============================] - 19s 725us/sample - loss: 0.1365 - f1: 0.6884 - val_loss: 2.6206 - val_f1: 0.6731\n",
      "Epoch 37/100\n",
      "26384/26384 [==============================] - 19s 730us/sample - loss: 0.1349 - f1: 0.6887 - val_loss: 2.4954 - val_f1: 0.6723\n",
      "Epoch 38/100\n",
      "26384/26384 [==============================] - 19s 727us/sample - loss: 0.1322 - f1: 0.6886 - val_loss: 2.1565 - val_f1: 0.6693\n",
      "Epoch 39/100\n",
      "26384/26384 [==============================] - 19s 713us/sample - loss: 0.1290 - f1: 0.6885 - val_loss: 3.0613 - val_f1: 0.6762\n",
      "Epoch 40/100\n",
      "26384/26384 [==============================] - 19s 725us/sample - loss: 0.1307 - f1: 0.6885 - val_loss: 2.5953 - val_f1: 0.6749\n",
      "Epoch 41/100\n",
      "26384/26384 [==============================] - 20s 747us/sample - loss: 0.1332 - f1: 0.6889 - val_loss: 3.1438 - val_f1: 0.6728\n",
      "Epoch 42/100\n",
      "26384/26384 [==============================] - 19s 728us/sample - loss: 0.1309 - f1: 0.6888 - val_loss: 2.8296 - val_f1: 0.6768\n",
      "Epoch 43/100\n",
      "26384/26384 [==============================] - 19s 729us/sample - loss: 0.1262 - f1: 0.6884 - val_loss: 2.3240 - val_f1: 0.6743\n",
      "Epoch 44/100\n",
      "26384/26384 [==============================] - 19s 733us/sample - loss: 0.1246 - f1: 0.6885 - val_loss: 2.8120 - val_f1: 0.6741\n",
      "Epoch 45/100\n",
      "26384/26384 [==============================] - 19s 732us/sample - loss: 0.1203 - f1: 0.6885 - val_loss: 2.7255 - val_f1: 0.6728\n",
      "Epoch 46/100\n",
      "26384/26384 [==============================] - 19s 726us/sample - loss: 0.1221 - f1: 0.6887 - val_loss: 2.5836 - val_f1: 0.6746\n",
      "Epoch 47/100\n",
      "26384/26384 [==============================] - 19s 725us/sample - loss: 0.1155 - f1: 0.6885 - val_loss: 2.9573 - val_f1: 0.6688\n",
      "Epoch 48/100\n",
      "26384/26384 [==============================] - 19s 725us/sample - loss: 0.1206 - f1: 0.6888 - val_loss: 2.8821 - val_f1: 0.6755\n",
      "Epoch 49/100\n",
      "26384/26384 [==============================] - 19s 725us/sample - loss: 0.1164 - f1: 0.6891 - val_loss: 1.9769 - val_f1: 0.6723\n",
      "Epoch 50/100\n",
      "26384/26384 [==============================] - 19s 724us/sample - loss: 0.1171 - f1: 0.6889 - val_loss: 3.4677 - val_f1: 0.6754\n",
      "Epoch 51/100\n",
      "26384/26384 [==============================] - 19s 728us/sample - loss: 0.1132 - f1: 0.6886 - val_loss: 4.0962 - val_f1: 0.6755\n",
      "Epoch 52/100\n",
      "26384/26384 [==============================] - 19s 726us/sample - loss: 0.1136 - f1: 0.6886 - val_loss: 2.5705 - val_f1: 0.6750\n",
      "Epoch 53/100\n",
      "26384/26384 [==============================] - 19s 713us/sample - loss: 0.1175 - f1: 0.6885 - val_loss: 2.0145 - val_f1: 0.6731\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 54/100\n",
      "26384/26384 [==============================] - 19s 717us/sample - loss: 0.1083 - f1: 0.6887 - val_loss: 3.3633 - val_f1: 0.6751\n",
      "Epoch 55/100\n",
      "26384/26384 [==============================] - 19s 718us/sample - loss: 0.1097 - f1: 0.6888 - val_loss: 3.3117 - val_f1: 0.6772\n",
      "Epoch 56/100\n",
      "26384/26384 [==============================] - 19s 718us/sample - loss: 0.1081 - f1: 0.6889 - val_loss: 4.0600 - val_f1: 0.6754\n",
      "Epoch 57/100\n",
      "26384/26384 [==============================] - 19s 719us/sample - loss: 0.1050 - f1: 0.6887 - val_loss: 2.5087 - val_f1: 0.6756\n",
      "Epoch 58/100\n",
      "26384/26384 [==============================] - 19s 718us/sample - loss: 0.1051 - f1: 0.6885 - val_loss: 3.4272 - val_f1: 0.6743\n",
      "Epoch 59/100\n",
      "26384/26384 [==============================] - 19s 719us/sample - loss: 0.1054 - f1: 0.6891 - val_loss: 3.4840 - val_f1: 0.6727\n",
      "Epoch 60/100\n",
      "26384/26384 [==============================] - 19s 719us/sample - loss: 0.1010 - f1: 0.6889 - val_loss: 2.7910 - val_f1: 0.6731\n",
      "Epoch 61/100\n",
      "26384/26384 [==============================] - 19s 717us/sample - loss: 0.1090 - f1: 0.6885 - val_loss: 2.9957 - val_f1: 0.6756\n",
      "Epoch 62/100\n",
      "26384/26384 [==============================] - 19s 718us/sample - loss: 0.1027 - f1: 0.6884 - val_loss: 3.2311 - val_f1: 0.6730\n",
      "Epoch 63/100\n",
      "26384/26384 [==============================] - 19s 719us/sample - loss: 0.1024 - f1: 0.6887 - val_loss: 2.9305 - val_f1: 0.6763\n",
      "Epoch 64/100\n",
      "26384/26384 [==============================] - 19s 715us/sample - loss: 0.1001 - f1: 0.6887 - val_loss: 3.8695 - val_f1: 0.6726\n",
      "Epoch 65/100\n",
      "26384/26384 [==============================] - 19s 719us/sample - loss: 0.0937 - f1: 0.6893 - val_loss: 3.5950 - val_f1: 0.6749\n",
      "Epoch 66/100\n",
      "26384/26384 [==============================] - 19s 720us/sample - loss: 0.0950 - f1: 0.6886 - val_loss: 3.3335 - val_f1: 0.6723\n",
      "Epoch 67/100\n",
      "26384/26384 [==============================] - 19s 718us/sample - loss: 0.0998 - f1: 0.6885 - val_loss: 3.2922 - val_f1: 0.6779\n",
      "Epoch 68/100\n",
      "26384/26384 [==============================] - 19s 720us/sample - loss: 0.0940 - f1: 0.6889 - val_loss: 3.4597 - val_f1: 0.6731\n",
      "Epoch 69/100\n",
      "26384/26384 [==============================] - 19s 719us/sample - loss: 0.0917 - f1: 0.6891 - val_loss: 3.6377 - val_f1: 0.6722\n",
      "Epoch 70/100\n",
      "26384/26384 [==============================] - 19s 722us/sample - loss: 0.0926 - f1: 0.6889 - val_loss: 2.7951 - val_f1: 0.6772\n",
      "Epoch 71/100\n",
      "26384/26384 [==============================] - 19s 720us/sample - loss: 0.0895 - f1: 0.6890 - val_loss: 2.9052 - val_f1: 0.6698\n",
      "Epoch 72/100\n",
      "26384/26384 [==============================] - 19s 723us/sample - loss: 0.0939 - f1: 0.6889 - val_loss: 3.8364 - val_f1: 0.6726\n",
      "Epoch 73/100\n",
      "26384/26384 [==============================] - 19s 720us/sample - loss: 0.0895 - f1: 0.6885 - val_loss: 2.8036 - val_f1: 0.6691\n",
      "Epoch 74/100\n",
      "26384/26384 [==============================] - 19s 718us/sample - loss: 0.0952 - f1: 0.6887 - val_loss: 3.2735 - val_f1: 0.6695\n",
      "Epoch 75/100\n",
      "26384/26384 [==============================] - 19s 713us/sample - loss: 0.0878 - f1: 0.6891 - val_loss: 2.5446 - val_f1: 0.6761\n",
      "Epoch 76/100\n",
      "26384/26384 [==============================] - 19s 723us/sample - loss: 0.0838 - f1: 0.6887 - val_loss: 3.9532 - val_f1: 0.6689\n",
      "Epoch 77/100\n",
      "26384/26384 [==============================] - 19s 720us/sample - loss: 0.0923 - f1: 0.6890 - val_loss: 2.6340 - val_f1: 0.6726\n",
      "Epoch 78/100\n",
      "26384/26384 [==============================] - 19s 720us/sample - loss: 0.0868 - f1: 0.6886 - val_loss: 3.5996 - val_f1: 0.6766\n",
      "Epoch 79/100\n",
      "26384/26384 [==============================] - 19s 721us/sample - loss: 0.0850 - f1: 0.6886 - val_loss: 3.2394 - val_f1: 0.6751\n",
      "Epoch 80/100\n",
      "26384/26384 [==============================] - 19s 723us/sample - loss: 0.0870 - f1: 0.6885 - val_loss: 3.2294 - val_f1: 0.6685\n",
      "Epoch 81/100\n",
      "26384/26384 [==============================] - 19s 721us/sample - loss: 0.0779 - f1: 0.6892 - val_loss: 4.2209 - val_f1: 0.6724\n",
      "Epoch 82/100\n",
      "26384/26384 [==============================] - 19s 724us/sample - loss: 0.0810 - f1: 0.6893 - val_loss: 3.6907 - val_f1: 0.6757\n",
      "Epoch 83/100\n",
      "26384/26384 [==============================] - 19s 721us/sample - loss: 0.0801 - f1: 0.6890 - val_loss: 3.0001 - val_f1: 0.6760\n",
      "Epoch 84/100\n",
      "26384/26384 [==============================] - 19s 724us/sample - loss: 0.0810 - f1: 0.6891 - val_loss: 3.1055 - val_f1: 0.6730\n",
      "Epoch 85/100\n",
      "26384/26384 [==============================] - 19s 724us/sample - loss: 0.0835 - f1: 0.6887 - val_loss: 3.6031 - val_f1: 0.6757\n",
      "Epoch 86/100\n",
      "26384/26384 [==============================] - 19s 723us/sample - loss: 0.0840 - f1: 0.6886 - val_loss: 3.9734 - val_f1: 0.6729\n",
      "Epoch 87/100\n",
      "26384/26384 [==============================] - 19s 723us/sample - loss: 0.0763 - f1: 0.6888 - val_loss: 2.4557 - val_f1: 0.6692\n",
      "Epoch 88/100\n",
      "26384/26384 [==============================] - 19s 723us/sample - loss: 0.0736 - f1: 0.6886 - val_loss: 3.1888 - val_f1: 0.6765\n",
      "Epoch 89/100\n",
      "26384/26384 [==============================] - 19s 725us/sample - loss: 0.0813 - f1: 0.6887 - val_loss: 2.9359 - val_f1: 0.6733\n",
      "Epoch 90/100\n",
      "26384/26384 [==============================] - 19s 724us/sample - loss: 0.0762 - f1: 0.6886 - val_loss: 4.4405 - val_f1: 0.6755\n",
      "Epoch 91/100\n",
      "26384/26384 [==============================] - 19s 724us/sample - loss: 0.0816 - f1: 0.6885 - val_loss: 3.2995 - val_f1: 0.6686\n",
      "Epoch 92/100\n",
      "26384/26384 [==============================] - 19s 722us/sample - loss: 0.0746 - f1: 0.6887 - val_loss: 3.5539 - val_f1: 0.6726\n",
      "Epoch 93/100\n",
      "26384/26384 [==============================] - 19s 716us/sample - loss: 0.0804 - f1: 0.6891 - val_loss: 4.4721 - val_f1: 0.6753\n",
      "Epoch 94/100\n",
      "26384/26384 [==============================] - 19s 718us/sample - loss: 0.0713 - f1: 0.6887 - val_loss: 3.3578 - val_f1: 0.6751\n",
      "Epoch 95/100\n",
      "26384/26384 [==============================] - 19s 725us/sample - loss: 0.0687 - f1: 0.6888 - val_loss: 4.2169 - val_f1: 0.6758\n",
      "Epoch 96/100\n",
      "26384/26384 [==============================] - 19s 724us/sample - loss: 0.0775 - f1: 0.6885 - val_loss: 3.3517 - val_f1: 0.6768\n",
      "Epoch 97/100\n",
      "26384/26384 [==============================] - 19s 726us/sample - loss: 0.0735 - f1: 0.6887 - val_loss: 3.9920 - val_f1: 0.6730\n",
      "Epoch 98/100\n",
      "26384/26384 [==============================] - 19s 724us/sample - loss: 0.0753 - f1: 0.6889 - val_loss: 3.9350 - val_f1: 0.6727\n",
      "Epoch 99/100\n",
      "26384/26384 [==============================] - 19s 724us/sample - loss: 0.0697 - f1: 0.6882 - val_loss: 3.3995 - val_f1: 0.6678\n",
      "Epoch 100/100\n",
      "26384/26384 [==============================] - 19s 724us/sample - loss: 0.0702 - f1: 0.6885 - val_loss: 3.5014 - val_f1: 0.6671\n",
      "FIT\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0816 21:22:57.092158 140241072178944 ag_logging.py:145] Entity <function standard_lstm at 0x7f8c0ce8f268> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: No module named 'tensorflow_core.contrib'\n",
      "W0816 21:22:57.178158 140241072178944 ag_logging.py:145] Entity <function cudnn_lstm at 0x7f8c0ce8f2f0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: No module named 'tensorflow_core.contrib'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PREDICT\n",
      "Group 4\n",
      "[0.18244237 0.68706589]\n",
      "macro 0.4347541322289322\n",
      "3\n",
      "50\n",
      "WARNING: Entity <function standard_lstm at 0x7f8c0ce8f268> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: No module named 'tensorflow_core.contrib'\n",
      "WARNING: Entity <function cudnn_lstm at 0x7f8c0ce8f2f0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: No module named 'tensorflow_core.contrib'\n",
      "OKKKK\n",
      "YOOOO\n",
      "Train on 27572 samples, validate on 2495 samples\n",
      "Epoch 1/100\n",
      "27572/27572 [==============================] - 20s 732us/sample - loss: 0.7079 - f1: 0.6770 - val_loss: 0.6946 - val_f1: 0.6672\n",
      "Epoch 2/100\n",
      "27572/27572 [==============================] - 19s 700us/sample - loss: 0.6937 - f1: 0.6875 - val_loss: 0.6946 - val_f1: 0.6679\n",
      "Epoch 3/100\n",
      "27572/27572 [==============================] - 19s 701us/sample - loss: 0.6315 - f1: 0.6873 - val_loss: 0.7518 - val_f1: 0.6672\n",
      "Epoch 4/100\n",
      "27572/27572 [==============================] - 19s 695us/sample - loss: 0.5206 - f1: 0.6884 - val_loss: 1.0183 - val_f1: 0.6680\n",
      "Epoch 5/100\n",
      "27572/27572 [==============================] - 19s 696us/sample - loss: 0.4455 - f1: 0.6889 - val_loss: 0.3117 - val_f1: 0.6676\n",
      "Epoch 6/100\n",
      "27572/27572 [==============================] - 19s 701us/sample - loss: 0.4077 - f1: 0.6889 - val_loss: 0.5077 - val_f1: 0.6677\n",
      "Epoch 7/100\n",
      "27572/27572 [==============================] - 19s 703us/sample - loss: 0.3607 - f1: 0.6886 - val_loss: 0.3859 - val_f1: 0.6677\n",
      "Epoch 8/100\n",
      "27572/27572 [==============================] - 19s 701us/sample - loss: 0.3202 - f1: 0.6890 - val_loss: 0.3192 - val_f1: 0.6675\n",
      "Epoch 9/100\n",
      "27572/27572 [==============================] - 19s 703us/sample - loss: 0.2941 - f1: 0.6890 - val_loss: 0.2460 - val_f1: 0.6672\n",
      "Epoch 10/100\n",
      "27572/27572 [==============================] - 19s 701us/sample - loss: 0.2790 - f1: 0.6886 - val_loss: 0.2312 - val_f1: 0.6682\n",
      "Epoch 11/100\n",
      "27572/27572 [==============================] - 19s 703us/sample - loss: 0.2622 - f1: 0.6884 - val_loss: 0.3768 - val_f1: 0.6675\n",
      "Epoch 12/100\n",
      "27572/27572 [==============================] - 19s 704us/sample - loss: 0.2593 - f1: 0.6888 - val_loss: 0.2967 - val_f1: 0.6679\n",
      "Epoch 13/100\n",
      "27572/27572 [==============================] - 19s 704us/sample - loss: 0.2557 - f1: 0.6889 - val_loss: 0.2392 - val_f1: 0.6664\n",
      "Epoch 14/100\n",
      "27572/27572 [==============================] - 19s 701us/sample - loss: 0.2519 - f1: 0.6887 - val_loss: 0.3091 - val_f1: 0.6688\n",
      "Epoch 15/100\n",
      "27572/27572 [==============================] - 19s 704us/sample - loss: 0.2467 - f1: 0.6890 - val_loss: 0.2507 - val_f1: 0.6684\n",
      "Epoch 16/100\n",
      "27572/27572 [==============================] - 19s 703us/sample - loss: 0.2398 - f1: 0.6889 - val_loss: 0.2743 - val_f1: 0.6686\n",
      "Epoch 17/100\n",
      "27572/27572 [==============================] - 19s 706us/sample - loss: 0.2405 - f1: 0.6892 - val_loss: 0.2989 - val_f1: 0.6659\n",
      "Epoch 18/100\n",
      "27572/27572 [==============================] - 20s 719us/sample - loss: 0.2332 - f1: 0.6889 - val_loss: 0.2880 - val_f1: 0.6680\n",
      "Epoch 19/100\n",
      "27572/27572 [==============================] - 20s 719us/sample - loss: 0.2357 - f1: 0.6888 - val_loss: 0.2248 - val_f1: 0.6682\n",
      "Epoch 20/100\n",
      "27572/27572 [==============================] - 20s 725us/sample - loss: 0.2374 - f1: 0.6883 - val_loss: 0.1928 - val_f1: 0.6673\n",
      "Epoch 21/100\n",
      "27572/27572 [==============================] - 20s 724us/sample - loss: 0.2274 - f1: 0.6884 - val_loss: 0.2096 - val_f1: 0.6675\n",
      "Epoch 22/100\n",
      "27572/27572 [==============================] - 20s 723us/sample - loss: 0.2240 - f1: 0.6886 - val_loss: 0.4315 - val_f1: 0.6676\n",
      "Epoch 23/100\n",
      "27572/27572 [==============================] - 20s 721us/sample - loss: 0.2167 - f1: 0.6889 - val_loss: 0.3145 - val_f1: 0.6682\n",
      "Epoch 24/100\n",
      "27572/27572 [==============================] - 20s 722us/sample - loss: 0.2125 - f1: 0.6887 - val_loss: 0.2406 - val_f1: 0.6672\n",
      "Epoch 25/100\n",
      "27572/27572 [==============================] - 20s 725us/sample - loss: 0.2005 - f1: 0.6889 - val_loss: 0.3028 - val_f1: 0.6680\n",
      "Epoch 26/100\n",
      "27572/27572 [==============================] - 20s 724us/sample - loss: 0.1974 - f1: 0.6886 - val_loss: 0.3443 - val_f1: 0.6666\n",
      "Epoch 27/100\n",
      "27572/27572 [==============================] - 20s 725us/sample - loss: 0.1928 - f1: 0.6882 - val_loss: 0.2394 - val_f1: 0.6679\n",
      "Epoch 28/100\n",
      "27572/27572 [==============================] - 20s 725us/sample - loss: 0.1939 - f1: 0.6880 - val_loss: 0.2674 - val_f1: 0.6680\n",
      "Epoch 29/100\n",
      "27572/27572 [==============================] - 20s 723us/sample - loss: 0.1805 - f1: 0.6890 - val_loss: 0.2229 - val_f1: 0.6673\n",
      "Epoch 30/100\n",
      "27572/27572 [==============================] - 20s 725us/sample - loss: 0.1850 - f1: 0.6888 - val_loss: 0.4199 - val_f1: 0.6671\n",
      "Epoch 31/100\n",
      "27572/27572 [==============================] - 20s 724us/sample - loss: 0.1745 - f1: 0.6886 - val_loss: 0.2738 - val_f1: 0.6670\n",
      "Epoch 32/100\n",
      "27572/27572 [==============================] - 20s 718us/sample - loss: 0.1711 - f1: 0.6887 - val_loss: 0.2824 - val_f1: 0.6679\n",
      "Epoch 33/100\n",
      "27572/27572 [==============================] - 20s 709us/sample - loss: 0.1664 - f1: 0.6883 - val_loss: 0.2596 - val_f1: 0.6672\n",
      "Epoch 34/100\n",
      "27572/27572 [==============================] - 20s 709us/sample - loss: 0.1655 - f1: 0.6885 - val_loss: 0.2304 - val_f1: 0.6678\n",
      "Epoch 35/100\n",
      "27572/27572 [==============================] - 20s 709us/sample - loss: 0.1621 - f1: 0.6888 - val_loss: 0.2633 - val_f1: 0.6670\n",
      "Epoch 36/100\n",
      "27572/27572 [==============================] - 20s 709us/sample - loss: 0.1598 - f1: 0.6886 - val_loss: 0.2260 - val_f1: 0.6679\n",
      "Epoch 37/100\n",
      "27572/27572 [==============================] - 20s 707us/sample - loss: 0.1650 - f1: 0.6892 - val_loss: 0.2132 - val_f1: 0.6677\n",
      "Epoch 38/100\n",
      "27572/27572 [==============================] - 20s 710us/sample - loss: 0.1568 - f1: 0.6888 - val_loss: 0.2278 - val_f1: 0.6663\n",
      "Epoch 39/100\n",
      "27572/27572 [==============================] - 20s 716us/sample - loss: 0.1566 - f1: 0.6889 - val_loss: 0.2865 - val_f1: 0.6656\n",
      "Epoch 40/100\n",
      "27572/27572 [==============================] - 19s 697us/sample - loss: 0.1549 - f1: 0.6887 - val_loss: 0.2378 - val_f1: 0.6680\n",
      "Epoch 41/100\n",
      "27572/27572 [==============================] - 20s 710us/sample - loss: 0.1485 - f1: 0.6888 - val_loss: 0.1812 - val_f1: 0.6682\n",
      "Epoch 42/100\n",
      "27572/27572 [==============================] - 20s 709us/sample - loss: 0.1510 - f1: 0.6883 - val_loss: 0.1879 - val_f1: 0.6674\n",
      "Epoch 43/100\n",
      "27572/27572 [==============================] - 20s 714us/sample - loss: 0.1486 - f1: 0.6882 - val_loss: 0.2768 - val_f1: 0.6679\n",
      "Epoch 44/100\n",
      "27572/27572 [==============================] - 20s 710us/sample - loss: 0.1463 - f1: 0.6891 - val_loss: 0.2122 - val_f1: 0.6677\n",
      "Epoch 45/100\n",
      "27572/27572 [==============================] - 20s 710us/sample - loss: 0.1489 - f1: 0.6886 - val_loss: 0.2301 - val_f1: 0.6677\n",
      "Epoch 46/100\n",
      "27572/27572 [==============================] - 20s 709us/sample - loss: 0.1445 - f1: 0.6889 - val_loss: 0.2321 - val_f1: 0.6675\n",
      "Epoch 47/100\n",
      "27572/27572 [==============================] - 20s 710us/sample - loss: 0.1453 - f1: 0.6884 - val_loss: 0.1537 - val_f1: 0.6671\n",
      "Epoch 48/100\n",
      "27572/27572 [==============================] - 20s 712us/sample - loss: 0.1415 - f1: 0.6884 - val_loss: 0.2734 - val_f1: 0.6684\n",
      "Epoch 49/100\n",
      "27572/27572 [==============================] - 20s 711us/sample - loss: 0.1353 - f1: 0.6892 - val_loss: 0.1801 - val_f1: 0.6677\n",
      "Epoch 50/100\n",
      "27572/27572 [==============================] - 20s 714us/sample - loss: 0.1412 - f1: 0.6889 - val_loss: 0.2158 - val_f1: 0.6663\n",
      "Epoch 51/100\n",
      "27572/27572 [==============================] - 20s 710us/sample - loss: 0.1390 - f1: 0.6884 - val_loss: 0.2071 - val_f1: 0.6669\n",
      "Epoch 52/100\n",
      "27572/27572 [==============================] - 20s 712us/sample - loss: 0.1362 - f1: 0.6885 - val_loss: 0.2412 - val_f1: 0.6670\n",
      "Epoch 53/100\n",
      "27572/27572 [==============================] - 20s 711us/sample - loss: 0.1351 - f1: 0.6883 - val_loss: 0.2288 - val_f1: 0.6664\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 54/100\n",
      "27572/27572 [==============================] - 19s 703us/sample - loss: 0.1307 - f1: 0.6886 - val_loss: 0.2341 - val_f1: 0.6685\n",
      "Epoch 55/100\n",
      "27572/27572 [==============================] - 19s 697us/sample - loss: 0.1288 - f1: 0.6884 - val_loss: 0.1914 - val_f1: 0.6685\n",
      "Epoch 56/100\n",
      "27572/27572 [==============================] - 19s 705us/sample - loss: 0.1282 - f1: 0.6887 - val_loss: 0.3046 - val_f1: 0.6674\n",
      "Epoch 57/100\n",
      "27572/27572 [==============================] - 19s 703us/sample - loss: 0.1253 - f1: 0.6887 - val_loss: 0.2592 - val_f1: 0.6666\n",
      "Epoch 58/100\n",
      "27572/27572 [==============================] - 19s 704us/sample - loss: 0.1285 - f1: 0.6885 - val_loss: 0.2977 - val_f1: 0.6677\n",
      "Epoch 59/100\n",
      "27572/27572 [==============================] - 19s 704us/sample - loss: 0.1241 - f1: 0.6888 - val_loss: 0.2683 - val_f1: 0.6683\n",
      "Epoch 60/100\n",
      "27572/27572 [==============================] - 19s 704us/sample - loss: 0.1284 - f1: 0.6885 - val_loss: 0.1910 - val_f1: 0.6685\n",
      "Epoch 61/100\n",
      "27572/27572 [==============================] - 19s 706us/sample - loss: 0.1247 - f1: 0.6887 - val_loss: 0.2628 - val_f1: 0.6684\n",
      "Epoch 62/100\n",
      "27572/27572 [==============================] - 19s 707us/sample - loss: 0.1274 - f1: 0.6884 - val_loss: 0.2626 - val_f1: 0.6675\n",
      "Epoch 63/100\n",
      "27572/27572 [==============================] - 19s 705us/sample - loss: 0.1233 - f1: 0.6888 - val_loss: 0.2039 - val_f1: 0.6679\n",
      "Epoch 64/100\n",
      "27572/27572 [==============================] - 19s 705us/sample - loss: 0.1453 - f1: 0.6885 - val_loss: 0.2303 - val_f1: 0.6690\n",
      "Epoch 65/100\n",
      "27572/27572 [==============================] - 19s 705us/sample - loss: 0.1242 - f1: 0.6888 - val_loss: 0.2050 - val_f1: 0.6677\n",
      "Epoch 66/100\n",
      "27572/27572 [==============================] - 19s 704us/sample - loss: 0.1171 - f1: 0.6886 - val_loss: 0.2261 - val_f1: 0.6683\n",
      "Epoch 67/100\n",
      "27572/27572 [==============================] - 19s 706us/sample - loss: 0.1173 - f1: 0.6887 - val_loss: 0.2782 - val_f1: 0.6674\n",
      "Epoch 68/100\n",
      "27572/27572 [==============================] - 19s 703us/sample - loss: 0.1117 - f1: 0.6884 - val_loss: 0.2785 - val_f1: 0.6674\n",
      "Epoch 69/100\n",
      "27572/27572 [==============================] - 19s 705us/sample - loss: 0.1161 - f1: 0.6885 - val_loss: 0.1818 - val_f1: 0.6681\n",
      "Epoch 70/100\n",
      "27572/27572 [==============================] - 19s 705us/sample - loss: 0.1139 - f1: 0.6888 - val_loss: 0.3057 - val_f1: 0.6672\n",
      "Epoch 71/100\n",
      "27572/27572 [==============================] - 19s 699us/sample - loss: 0.1116 - f1: 0.6889 - val_loss: 0.2208 - val_f1: 0.6673\n",
      "Epoch 72/100\n",
      "27572/27572 [==============================] - 19s 704us/sample - loss: 0.1211 - f1: 0.6887 - val_loss: 0.2815 - val_f1: 0.6676\n",
      "Epoch 73/100\n",
      "27572/27572 [==============================] - 19s 707us/sample - loss: 0.1122 - f1: 0.6885 - val_loss: 0.2685 - val_f1: 0.6684\n",
      "Epoch 74/100\n",
      "27572/27572 [==============================] - 19s 706us/sample - loss: 0.1076 - f1: 0.6884 - val_loss: 0.2476 - val_f1: 0.6675\n",
      "Epoch 75/100\n",
      "27572/27572 [==============================] - 20s 708us/sample - loss: 0.1092 - f1: 0.6887 - val_loss: 0.3109 - val_f1: 0.6675\n",
      "Epoch 76/100\n",
      "27572/27572 [==============================] - 19s 707us/sample - loss: 0.1062 - f1: 0.6887 - val_loss: 0.2538 - val_f1: 0.6672\n",
      "Epoch 77/100\n",
      "27572/27572 [==============================] - 20s 707us/sample - loss: 0.1048 - f1: 0.6887 - val_loss: 0.2346 - val_f1: 0.6688\n",
      "Epoch 78/100\n",
      "27572/27572 [==============================] - 19s 706us/sample - loss: 0.1122 - f1: 0.6887 - val_loss: 0.2646 - val_f1: 0.6674\n",
      "Epoch 79/100\n",
      "27572/27572 [==============================] - 19s 706us/sample - loss: 0.1043 - f1: 0.6891 - val_loss: 0.3013 - val_f1: 0.6680\n",
      "Epoch 80/100\n",
      "27572/27572 [==============================] - 20s 708us/sample - loss: 0.1041 - f1: 0.6886 - val_loss: 0.2884 - val_f1: 0.6682\n",
      "Epoch 81/100\n",
      "27572/27572 [==============================] - 20s 710us/sample - loss: 0.1025 - f1: 0.6886 - val_loss: 0.3682 - val_f1: 0.6677\n",
      "Epoch 82/100\n",
      "27572/27572 [==============================] - 19s 706us/sample - loss: 0.1099 - f1: 0.6888 - val_loss: 0.2714 - val_f1: 0.6693\n",
      "Epoch 83/100\n",
      "27572/27572 [==============================] - 20s 708us/sample - loss: 0.1000 - f1: 0.6885 - val_loss: 0.2362 - val_f1: 0.6675\n",
      "Epoch 84/100\n",
      "27572/27572 [==============================] - 20s 709us/sample - loss: 0.1013 - f1: 0.6881 - val_loss: 0.2634 - val_f1: 0.6684\n",
      "Epoch 85/100\n",
      "27572/27572 [==============================] - 20s 708us/sample - loss: 0.0988 - f1: 0.6890 - val_loss: 0.2323 - val_f1: 0.6671\n",
      "Epoch 86/100\n",
      "27572/27572 [==============================] - 19s 707us/sample - loss: 0.0972 - f1: 0.6886 - val_loss: 0.2254 - val_f1: 0.6679\n",
      "Epoch 87/100\n",
      "27572/27572 [==============================] - 20s 710us/sample - loss: 0.0934 - f1: 0.6886 - val_loss: 0.3380 - val_f1: 0.6684\n",
      "Epoch 88/100\n",
      "27572/27572 [==============================] - 20s 709us/sample - loss: 0.1018 - f1: 0.6889 - val_loss: 0.2351 - val_f1: 0.6681\n",
      "Epoch 89/100\n",
      "27572/27572 [==============================] - 20s 708us/sample - loss: 0.0959 - f1: 0.6884 - val_loss: 0.2580 - val_f1: 0.6678\n",
      "Epoch 90/100\n",
      "27572/27572 [==============================] - 20s 708us/sample - loss: 0.0976 - f1: 0.6886 - val_loss: 0.2258 - val_f1: 0.6676\n",
      "Epoch 91/100\n",
      "27572/27572 [==============================] - 20s 708us/sample - loss: 0.0986 - f1: 0.6890 - val_loss: 0.2987 - val_f1: 0.6674\n",
      "Epoch 92/100\n",
      "27572/27572 [==============================] - 20s 708us/sample - loss: 0.0908 - f1: 0.6882 - val_loss: 0.2893 - val_f1: 0.6669\n",
      "Epoch 93/100\n",
      "27572/27572 [==============================] - 20s 711us/sample - loss: 0.0915 - f1: 0.6887 - val_loss: 0.2689 - val_f1: 0.6682\n",
      "Epoch 94/100\n",
      "27572/27572 [==============================] - 20s 709us/sample - loss: 0.0924 - f1: 0.6885 - val_loss: 0.2734 - val_f1: 0.6685\n",
      "Epoch 95/100\n",
      "27572/27572 [==============================] - 20s 708us/sample - loss: 0.0926 - f1: 0.6886 - val_loss: 0.2460 - val_f1: 0.6684\n",
      "Epoch 96/100\n",
      "27572/27572 [==============================] - 19s 701us/sample - loss: 0.0936 - f1: 0.6883 - val_loss: 0.2506 - val_f1: 0.6672\n",
      "Epoch 97/100\n",
      "27572/27572 [==============================] - 19s 704us/sample - loss: 0.0875 - f1: 0.6885 - val_loss: 0.3122 - val_f1: 0.6667\n",
      "Epoch 98/100\n",
      "27572/27572 [==============================] - 20s 712us/sample - loss: 0.0879 - f1: 0.6889 - val_loss: 0.3107 - val_f1: 0.6680\n",
      "Epoch 99/100\n",
      "27572/27572 [==============================] - 20s 710us/sample - loss: 0.0855 - f1: 0.6886 - val_loss: 0.2173 - val_f1: 0.6671\n",
      "Epoch 100/100\n",
      "27572/27572 [==============================] - 20s 709us/sample - loss: 0.0866 - f1: 0.6890 - val_loss: 0.2904 - val_f1: 0.6665\n",
      "FIT\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0816 21:55:35.956749 140241072178944 ag_logging.py:145] Entity <function standard_lstm at 0x7f8c0ce8f268> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: No module named 'tensorflow_core.contrib'\n",
      "W0816 21:55:36.043704 140241072178944 ag_logging.py:145] Entity <function cudnn_lstm at 0x7f8c0ce8f2f0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: No module named 'tensorflow_core.contrib'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PREDICT\n",
      "Group 5\n",
      "[0.9288871  0.92922831]\n",
      "macro 0.9290577059654244\n",
      "3\n",
      "50\n",
      "WARNING: Entity <function standard_lstm at 0x7f8c0ce8f268> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: No module named 'tensorflow_core.contrib'\n",
      "WARNING: Entity <function cudnn_lstm at 0x7f8c0ce8f2f0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: No module named 'tensorflow_core.contrib'\n",
      "OKKKK\n",
      "YOOOO\n",
      "Train on 26579 samples, validate on 3488 samples\n",
      "Epoch 1/100\n",
      "26579/26579 [==============================] - 20s 750us/sample - loss: 0.7096 - f1: 0.6791 - val_loss: 0.6932 - val_f1: 0.6600\n",
      "Epoch 2/100\n",
      "26579/26579 [==============================] - 19s 715us/sample - loss: 0.6937 - f1: 0.6894 - val_loss: 0.6977 - val_f1: 0.6596\n",
      "Epoch 3/100\n",
      "26579/26579 [==============================] - 19s 712us/sample - loss: 0.6915 - f1: 0.6895 - val_loss: 0.6843 - val_f1: 0.6613\n",
      "Epoch 4/100\n",
      "26579/26579 [==============================] - 19s 713us/sample - loss: 0.6344 - f1: 0.6892 - val_loss: 0.5739 - val_f1: 0.6604\n",
      "Epoch 5/100\n",
      "26579/26579 [==============================] - 19s 711us/sample - loss: 0.5630 - f1: 0.6904 - val_loss: 0.3460 - val_f1: 0.6594\n",
      "Epoch 6/100\n",
      "26579/26579 [==============================] - 19s 711us/sample - loss: 0.4721 - f1: 0.6905 - val_loss: 0.3619 - val_f1: 0.6608\n",
      "Epoch 7/100\n",
      "26579/26579 [==============================] - 19s 712us/sample - loss: 0.4051 - f1: 0.6905 - val_loss: 0.4171 - val_f1: 0.6610\n",
      "Epoch 8/100\n",
      "26579/26579 [==============================] - 19s 714us/sample - loss: 0.3805 - f1: 0.6904 - val_loss: 0.4969 - val_f1: 0.6606\n",
      "Epoch 9/100\n",
      "26579/26579 [==============================] - 19s 713us/sample - loss: 0.3634 - f1: 0.6903 - val_loss: 0.7347 - val_f1: 0.6600\n",
      "Epoch 10/100\n",
      "26579/26579 [==============================] - 19s 713us/sample - loss: 0.3824 - f1: 0.6901 - val_loss: 0.3757 - val_f1: 0.6605\n",
      "Epoch 11/100\n",
      "26579/26579 [==============================] - 19s 714us/sample - loss: 0.3377 - f1: 0.6900 - val_loss: 0.3299 - val_f1: 0.6605\n",
      "Epoch 12/100\n",
      "26579/26579 [==============================] - 19s 716us/sample - loss: 0.3267 - f1: 0.6904 - val_loss: 0.2277 - val_f1: 0.6616\n",
      "Epoch 13/100\n",
      "26579/26579 [==============================] - 19s 714us/sample - loss: 0.3258 - f1: 0.6901 - val_loss: 0.3539 - val_f1: 0.6599\n",
      "Epoch 14/100\n",
      "26579/26579 [==============================] - 19s 713us/sample - loss: 0.2920 - f1: 0.6902 - val_loss: 0.2868 - val_f1: 0.6596\n",
      "Epoch 15/100\n",
      "26579/26579 [==============================] - 19s 715us/sample - loss: 0.2706 - f1: 0.6903 - val_loss: 0.2633 - val_f1: 0.6600\n",
      "Epoch 16/100\n",
      "26579/26579 [==============================] - 19s 712us/sample - loss: 0.2542 - f1: 0.6908 - val_loss: 0.2641 - val_f1: 0.6615\n",
      "Epoch 17/100\n",
      "26579/26579 [==============================] - 19s 718us/sample - loss: 0.2555 - f1: 0.6903 - val_loss: 0.2183 - val_f1: 0.6611\n",
      "Epoch 18/100\n",
      "26579/26579 [==============================] - 19s 721us/sample - loss: 0.2222 - f1: 0.6905 - val_loss: 0.2517 - val_f1: 0.6604\n",
      "Epoch 19/100\n",
      "26579/26579 [==============================] - 19s 715us/sample - loss: 0.2180 - f1: 0.6906 - val_loss: 0.2206 - val_f1: 0.6594\n",
      "Epoch 20/100\n",
      "26579/26579 [==============================] - 19s 716us/sample - loss: 0.2071 - f1: 0.6902 - val_loss: 0.2127 - val_f1: 0.6606\n",
      "Epoch 21/100\n",
      "26579/26579 [==============================] - 19s 713us/sample - loss: 0.2028 - f1: 0.6909 - val_loss: 0.2062 - val_f1: 0.6604\n",
      "Epoch 22/100\n",
      "26579/26579 [==============================] - 19s 722us/sample - loss: 0.1968 - f1: 0.6901 - val_loss: 0.2208 - val_f1: 0.6613\n",
      "Epoch 23/100\n",
      "26579/26579 [==============================] - 19s 711us/sample - loss: 0.1866 - f1: 0.6903 - val_loss: 0.1899 - val_f1: 0.6609\n",
      "Epoch 24/100\n",
      "26579/26579 [==============================] - 19s 729us/sample - loss: 0.1802 - f1: 0.6903 - val_loss: 0.1767 - val_f1: 0.6613\n",
      "Epoch 25/100\n",
      "26579/26579 [==============================] - 19s 712us/sample - loss: 0.1747 - f1: 0.6906 - val_loss: 0.2099 - val_f1: 0.6610\n",
      "Epoch 26/100\n",
      "26579/26579 [==============================] - 19s 721us/sample - loss: 0.1702 - f1: 0.6899 - val_loss: 0.1804 - val_f1: 0.6615\n",
      "Epoch 27/100\n",
      "26579/26579 [==============================] - 19s 721us/sample - loss: 0.1704 - f1: 0.6904 - val_loss: 0.1784 - val_f1: 0.6603\n",
      "Epoch 28/100\n",
      "26579/26579 [==============================] - 19s 722us/sample - loss: 0.1613 - f1: 0.6901 - val_loss: 0.1751 - val_f1: 0.6606\n",
      "Epoch 29/100\n",
      "26579/26579 [==============================] - 19s 721us/sample - loss: 0.1593 - f1: 0.6902 - val_loss: 0.1742 - val_f1: 0.6605\n",
      "Epoch 30/100\n",
      "26579/26579 [==============================] - 19s 721us/sample - loss: 0.1569 - f1: 0.6901 - val_loss: 0.1799 - val_f1: 0.6614\n",
      "Epoch 31/100\n",
      "26579/26579 [==============================] - 19s 725us/sample - loss: 0.1567 - f1: 0.6903 - val_loss: 0.1872 - val_f1: 0.6610\n",
      "Epoch 32/100\n",
      "26579/26579 [==============================] - 19s 713us/sample - loss: 0.1563 - f1: 0.6904 - val_loss: 0.1731 - val_f1: 0.6608\n",
      "Epoch 33/100\n",
      "26579/26579 [==============================] - 19s 727us/sample - loss: 0.1514 - f1: 0.6900 - val_loss: 0.1708 - val_f1: 0.6607\n",
      "Epoch 34/100\n",
      "26579/26579 [==============================] - 19s 725us/sample - loss: 0.1524 - f1: 0.6906 - val_loss: 0.1846 - val_f1: 0.6606\n",
      "Epoch 35/100\n",
      "26579/26579 [==============================] - 19s 721us/sample - loss: 0.1463 - f1: 0.6902 - val_loss: 0.1778 - val_f1: 0.6594\n",
      "Epoch 36/100\n",
      "26579/26579 [==============================] - 19s 720us/sample - loss: 0.1449 - f1: 0.6898 - val_loss: 0.2219 - val_f1: 0.6607\n",
      "Epoch 37/100\n",
      "26579/26579 [==============================] - 19s 717us/sample - loss: 0.1449 - f1: 0.6905 - val_loss: 0.2029 - val_f1: 0.6600\n",
      "Epoch 38/100\n",
      "26579/26579 [==============================] - 19s 716us/sample - loss: 0.1428 - f1: 0.6904 - val_loss: 0.1951 - val_f1: 0.6609\n",
      "Epoch 39/100\n",
      "26579/26579 [==============================] - 19s 721us/sample - loss: 0.1429 - f1: 0.6902 - val_loss: 0.2099 - val_f1: 0.6592\n",
      "Epoch 40/100\n",
      "26579/26579 [==============================] - 19s 721us/sample - loss: 0.1376 - f1: 0.6909 - val_loss: 0.2024 - val_f1: 0.6604\n",
      "Epoch 41/100\n",
      "26579/26579 [==============================] - 19s 722us/sample - loss: 0.1361 - f1: 0.6899 - val_loss: 0.1864 - val_f1: 0.6608\n",
      "Epoch 42/100\n",
      "26579/26579 [==============================] - 19s 722us/sample - loss: 0.1331 - f1: 0.6903 - val_loss: 0.1919 - val_f1: 0.6606\n",
      "Epoch 43/100\n",
      "26579/26579 [==============================] - 19s 725us/sample - loss: 0.1280 - f1: 0.6901 - val_loss: 0.1854 - val_f1: 0.6604\n",
      "Epoch 44/100\n",
      "26579/26579 [==============================] - 19s 723us/sample - loss: 0.1311 - f1: 0.6901 - val_loss: 0.1930 - val_f1: 0.6610\n",
      "Epoch 45/100\n",
      "26579/26579 [==============================] - 19s 723us/sample - loss: 0.1306 - f1: 0.6901 - val_loss: 0.2075 - val_f1: 0.6610\n",
      "Epoch 46/100\n",
      "26579/26579 [==============================] - 19s 723us/sample - loss: 0.1244 - f1: 0.6904 - val_loss: 0.2030 - val_f1: 0.6595\n",
      "Epoch 47/100\n",
      "26579/26579 [==============================] - 19s 722us/sample - loss: 0.1287 - f1: 0.6904 - val_loss: 0.2246 - val_f1: 0.6613\n",
      "Epoch 48/100\n",
      "26579/26579 [==============================] - 19s 722us/sample - loss: 0.1295 - f1: 0.6901 - val_loss: 0.1957 - val_f1: 0.6605\n",
      "Epoch 49/100\n",
      "26579/26579 [==============================] - 19s 726us/sample - loss: 0.1219 - f1: 0.6902 - val_loss: 0.2182 - val_f1: 0.6609\n",
      "Epoch 50/100\n",
      "26579/26579 [==============================] - 19s 725us/sample - loss: 0.1238 - f1: 0.6901 - val_loss: 0.1970 - val_f1: 0.6606\n",
      "Epoch 51/100\n",
      "26579/26579 [==============================] - 19s 725us/sample - loss: 0.1239 - f1: 0.6902 - val_loss: 0.2373 - val_f1: 0.6602\n",
      "Epoch 52/100\n",
      "26579/26579 [==============================] - 19s 723us/sample - loss: 0.1218 - f1: 0.6903 - val_loss: 0.2171 - val_f1: 0.6604\n",
      "Epoch 53/100\n",
      "26579/26579 [==============================] - 19s 724us/sample - loss: 0.1177 - f1: 0.6901 - val_loss: 0.2219 - val_f1: 0.6621\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 54/100\n",
      "26579/26579 [==============================] - 19s 715us/sample - loss: 0.1192 - f1: 0.6905 - val_loss: 0.2218 - val_f1: 0.6595\n",
      "Epoch 55/100\n",
      "26579/26579 [==============================] - 19s 716us/sample - loss: 0.1182 - f1: 0.6901 - val_loss: 0.2115 - val_f1: 0.6607\n",
      "Epoch 56/100\n",
      "26579/26579 [==============================] - 19s 717us/sample - loss: 0.1190 - f1: 0.6901 - val_loss: 0.2213 - val_f1: 0.6621\n",
      "Epoch 57/100\n",
      "26579/26579 [==============================] - 19s 712us/sample - loss: 0.1151 - f1: 0.6903 - val_loss: 0.2497 - val_f1: 0.6590\n",
      "Epoch 58/100\n",
      "26579/26579 [==============================] - 19s 713us/sample - loss: 0.1098 - f1: 0.6902 - val_loss: 0.2436 - val_f1: 0.6612\n",
      "Epoch 59/100\n",
      "26579/26579 [==============================] - 19s 717us/sample - loss: 0.1131 - f1: 0.6901 - val_loss: 0.3152 - val_f1: 0.6604\n",
      "Epoch 60/100\n",
      "26579/26579 [==============================] - 19s 716us/sample - loss: 0.1131 - f1: 0.6902 - val_loss: 0.2351 - val_f1: 0.6611\n",
      "Epoch 61/100\n",
      "26579/26579 [==============================] - 19s 717us/sample - loss: 0.1084 - f1: 0.6907 - val_loss: 0.2785 - val_f1: 0.6616\n",
      "Epoch 62/100\n",
      "26579/26579 [==============================] - 19s 720us/sample - loss: 0.1072 - f1: 0.6903 - val_loss: 0.2284 - val_f1: 0.6620\n",
      "Epoch 63/100\n",
      "26579/26579 [==============================] - 19s 713us/sample - loss: 0.1052 - f1: 0.6902 - val_loss: 0.3017 - val_f1: 0.6608\n",
      "Epoch 64/100\n",
      "26579/26579 [==============================] - 19s 717us/sample - loss: 0.1101 - f1: 0.6901 - val_loss: 0.3829 - val_f1: 0.6590\n",
      "Epoch 65/100\n",
      "26579/26579 [==============================] - 19s 717us/sample - loss: 0.1133 - f1: 0.6902 - val_loss: 0.2309 - val_f1: 0.6599\n",
      "Epoch 66/100\n",
      "26579/26579 [==============================] - 19s 717us/sample - loss: 0.1051 - f1: 0.6899 - val_loss: 0.2486 - val_f1: 0.6610\n",
      "Epoch 67/100\n",
      "26579/26579 [==============================] - 19s 709us/sample - loss: 0.1011 - f1: 0.6905 - val_loss: 0.4121 - val_f1: 0.6610\n",
      "Epoch 68/100\n",
      "26579/26579 [==============================] - 19s 720us/sample - loss: 0.1068 - f1: 0.6905 - val_loss: 0.2462 - val_f1: 0.6616\n",
      "Epoch 69/100\n",
      "26579/26579 [==============================] - 19s 733us/sample - loss: 0.1011 - f1: 0.6903 - val_loss: 0.2306 - val_f1: 0.6608\n",
      "Epoch 70/100\n",
      "26579/26579 [==============================] - 19s 732us/sample - loss: 0.1039 - f1: 0.6903 - val_loss: 0.2725 - val_f1: 0.6608\n",
      "Epoch 71/100\n",
      "26579/26579 [==============================] - 19s 731us/sample - loss: 0.1024 - f1: 0.6905 - val_loss: 0.3253 - val_f1: 0.6609\n",
      "Epoch 72/100\n",
      "26579/26579 [==============================] - 20s 735us/sample - loss: 0.1039 - f1: 0.6905 - val_loss: 0.2542 - val_f1: 0.6598\n",
      "Epoch 73/100\n",
      "26579/26579 [==============================] - 19s 733us/sample - loss: 0.1002 - f1: 0.6901 - val_loss: 0.5031 - val_f1: 0.6609\n",
      "Epoch 74/100\n",
      "26579/26579 [==============================] - 20s 735us/sample - loss: 0.1008 - f1: 0.6906 - val_loss: 0.3787 - val_f1: 0.6613\n",
      "Epoch 75/100\n",
      "26579/26579 [==============================] - 20s 734us/sample - loss: 0.0957 - f1: 0.6902 - val_loss: 0.3657 - val_f1: 0.6610\n",
      "Epoch 76/100\n",
      "26579/26579 [==============================] - 20s 747us/sample - loss: 0.0972 - f1: 0.6903 - val_loss: 0.6398 - val_f1: 0.6608\n",
      "Epoch 77/100\n",
      "26579/26579 [==============================] - 25s 929us/sample - loss: 0.0999 - f1: 0.6904 - val_loss: 0.3146 - val_f1: 0.6599\n",
      "Epoch 78/100\n",
      "26579/26579 [==============================] - 26s 982us/sample - loss: 0.0931 - f1: 0.6904 - val_loss: 0.6460 - val_f1: 0.6608\n",
      "Epoch 79/100\n",
      "26579/26579 [==============================] - 25s 952us/sample - loss: 0.0950 - f1: 0.6902 - val_loss: 0.3262 - val_f1: 0.6606\n",
      "Epoch 80/100\n",
      "26579/26579 [==============================] - 26s 974us/sample - loss: 0.0910 - f1: 0.6902 - val_loss: 0.7048 - val_f1: 0.6600\n",
      "Epoch 81/100\n",
      "26579/26579 [==============================] - 25s 954us/sample - loss: 0.0941 - f1: 0.6902 - val_loss: 0.3357 - val_f1: 0.6603\n",
      "Epoch 82/100\n",
      "26579/26579 [==============================] - 25s 926us/sample - loss: 0.0938 - f1: 0.6901 - val_loss: 0.4472 - val_f1: 0.6619\n",
      "Epoch 83/100\n",
      "26579/26579 [==============================] - 24s 902us/sample - loss: 0.0915 - f1: 0.6901 - val_loss: 0.5174 - val_f1: 0.6612\n",
      "Epoch 84/100\n",
      "26579/26579 [==============================] - 25s 925us/sample - loss: 0.0952 - f1: 0.6899 - val_loss: 0.7801 - val_f1: 0.6605\n",
      "Epoch 85/100\n",
      "26579/26579 [==============================] - 23s 874us/sample - loss: 0.0908 - f1: 0.6902 - val_loss: 0.5439 - val_f1: 0.6609\n",
      "Epoch 86/100\n",
      "26579/26579 [==============================] - 23s 872us/sample - loss: 0.0899 - f1: 0.6901 - val_loss: 0.5650 - val_f1: 0.6606\n",
      "Epoch 87/100\n",
      "26579/26579 [==============================] - 24s 900us/sample - loss: 0.0868 - f1: 0.6907 - val_loss: 1.0474 - val_f1: 0.6617\n",
      "Epoch 88/100\n",
      "26579/26579 [==============================] - 23s 875us/sample - loss: 0.0897 - f1: 0.6904 - val_loss: 0.6270 - val_f1: 0.6613\n",
      "Epoch 89/100\n",
      "26579/26579 [==============================] - 23s 881us/sample - loss: 0.0854 - f1: 0.6905 - val_loss: 0.6701 - val_f1: 0.6610\n",
      "Epoch 90/100\n",
      "26579/26579 [==============================] - 23s 875us/sample - loss: 0.0831 - f1: 0.6907 - val_loss: 0.4582 - val_f1: 0.6601\n",
      "Epoch 91/100\n",
      "26579/26579 [==============================] - 23s 874us/sample - loss: 0.0873 - f1: 0.6901 - val_loss: 0.7691 - val_f1: 0.6616\n",
      "Epoch 92/100\n",
      "26579/26579 [==============================] - 23s 874us/sample - loss: 0.0873 - f1: 0.6899 - val_loss: 0.3793 - val_f1: 0.6604\n",
      "Epoch 93/100\n",
      "26579/26579 [==============================] - 23s 875us/sample - loss: 0.0845 - f1: 0.6899 - val_loss: 0.4615 - val_f1: 0.6612\n",
      "Epoch 94/100\n",
      "26579/26579 [==============================] - 23s 873us/sample - loss: 0.0808 - f1: 0.6901 - val_loss: 0.9920 - val_f1: 0.6593\n",
      "Epoch 95/100\n",
      "26579/26579 [==============================] - 23s 879us/sample - loss: 0.0910 - f1: 0.6904 - val_loss: 0.3633 - val_f1: 0.6613\n",
      "Epoch 96/100\n",
      "26579/26579 [==============================] - 24s 887us/sample - loss: 0.0800 - f1: 0.6904 - val_loss: 0.8772 - val_f1: 0.6613\n",
      "Epoch 97/100\n",
      "26579/26579 [==============================] - 24s 910us/sample - loss: 0.0856 - f1: 0.6901 - val_loss: 0.3518 - val_f1: 0.6609\n",
      "Epoch 98/100\n",
      "26579/26579 [==============================] - 23s 881us/sample - loss: 0.0778 - f1: 0.6903 - val_loss: 0.9115 - val_f1: 0.6609\n",
      "Epoch 99/100\n",
      "26579/26579 [==============================] - 23s 881us/sample - loss: 0.0813 - f1: 0.6907 - val_loss: 0.6911 - val_f1: 0.6610\n",
      "Epoch 100/100\n",
      "26579/26579 [==============================] - 24s 885us/sample - loss: 0.0866 - f1: 0.6902 - val_loss: 0.5486 - val_f1: 0.6612\n",
      "FIT\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0816 22:29:30.276611 140241072178944 ag_logging.py:145] Entity <function standard_lstm at 0x7f8c0ce8f268> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: No module named 'tensorflow_core.contrib'\n",
      "W0816 22:29:30.384380 140241072178944 ag_logging.py:145] Entity <function cudnn_lstm at 0x7f8c0ce8f2f0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: No module named 'tensorflow_core.contrib'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PREDICT\n",
      "Group 6\n",
      "[0.57314329 0.73596288]\n",
      "macro 0.6545530814258089\n",
      "3\n",
      "50\n",
      "WARNING: Entity <function standard_lstm at 0x7f8c0ce8f268> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: No module named 'tensorflow_core.contrib'\n",
      "WARNING: Entity <function cudnn_lstm at 0x7f8c0ce8f2f0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: No module named 'tensorflow_core.contrib'\n",
      "OKKKK\n",
      "YOOOO\n",
      "Train on 25035 samples, validate on 5032 samples\n",
      "Epoch 1/100\n",
      "25035/25035 [==============================] - 23s 899us/sample - loss: 0.7059 - f1: 0.6793 - val_loss: 0.6927 - val_f1: 0.6717\n",
      "Epoch 2/100\n",
      "25035/25035 [==============================] - 22s 865us/sample - loss: 0.6865 - f1: 0.6894 - val_loss: 0.6627 - val_f1: 0.6734\n",
      "Epoch 3/100\n",
      "25035/25035 [==============================] - 22s 868us/sample - loss: 0.5799 - f1: 0.6895 - val_loss: 0.5778 - val_f1: 0.6714\n",
      "Epoch 4/100\n",
      "25035/25035 [==============================] - 22s 869us/sample - loss: 0.5438 - f1: 0.6900 - val_loss: 0.6822 - val_f1: 0.6722\n",
      "Epoch 5/100\n",
      "25035/25035 [==============================] - 22s 873us/sample - loss: 0.5018 - f1: 0.6900 - val_loss: 0.6968 - val_f1: 0.6704\n",
      "Epoch 6/100\n",
      "25035/25035 [==============================] - 22s 871us/sample - loss: 0.5561 - f1: 0.6901 - val_loss: 0.4468 - val_f1: 0.6715\n",
      "Epoch 7/100\n",
      "25035/25035 [==============================] - 22s 871us/sample - loss: 0.4913 - f1: 0.6902 - val_loss: 0.5278 - val_f1: 0.6718\n",
      "Epoch 8/100\n",
      "25035/25035 [==============================] - 22s 872us/sample - loss: 0.6188 - f1: 0.6899 - val_loss: 0.5479 - val_f1: 0.6703\n",
      "Epoch 9/100\n",
      "25035/25035 [==============================] - 22s 875us/sample - loss: 0.4619 - f1: 0.6902 - val_loss: 0.8884 - val_f1: 0.6702\n",
      "Epoch 10/100\n",
      "25035/25035 [==============================] - 22s 877us/sample - loss: 0.4202 - f1: 0.6898 - val_loss: 0.3758 - val_f1: 0.6705\n",
      "Epoch 11/100\n",
      "25035/25035 [==============================] - 22s 872us/sample - loss: 0.3909 - f1: 0.6900 - val_loss: 0.2821 - val_f1: 0.6720\n",
      "Epoch 12/100\n",
      "25035/25035 [==============================] - 22s 878us/sample - loss: 0.3943 - f1: 0.6897 - val_loss: 0.5231 - val_f1: 0.6720\n",
      "Epoch 13/100\n",
      "25035/25035 [==============================] - 22s 875us/sample - loss: 0.4037 - f1: 0.6904 - val_loss: 0.2313 - val_f1: 0.6704\n",
      "Epoch 14/100\n",
      "25035/25035 [==============================] - 23s 926us/sample - loss: 0.3460 - f1: 0.6903 - val_loss: 0.2618 - val_f1: 0.6715\n",
      "Epoch 15/100\n",
      "25035/25035 [==============================] - 23s 900us/sample - loss: 0.3735 - f1: 0.6904 - val_loss: 0.3462 - val_f1: 0.6706\n",
      "Epoch 16/100\n",
      "25035/25035 [==============================] - 23s 902us/sample - loss: 0.3615 - f1: 0.6895 - val_loss: 0.4697 - val_f1: 0.6722\n",
      "Epoch 17/100\n",
      "25035/25035 [==============================] - 23s 904us/sample - loss: 0.3182 - f1: 0.6903 - val_loss: 0.2436 - val_f1: 0.6727\n",
      "Epoch 18/100\n",
      "25035/25035 [==============================] - 23s 901us/sample - loss: 0.3127 - f1: 0.6899 - val_loss: 0.3688 - val_f1: 0.6712\n",
      "Epoch 19/100\n",
      "25035/25035 [==============================] - 23s 906us/sample - loss: 0.2927 - f1: 0.6899 - val_loss: 0.2734 - val_f1: 0.6726\n",
      "Epoch 20/100\n",
      "25035/25035 [==============================] - 23s 903us/sample - loss: 0.2898 - f1: 0.6896 - val_loss: 0.2472 - val_f1: 0.6722\n",
      "Epoch 21/100\n",
      "25035/25035 [==============================] - 23s 908us/sample - loss: 0.2839 - f1: 0.6900 - val_loss: 0.3667 - val_f1: 0.6699\n",
      "Epoch 22/100\n",
      "25035/25035 [==============================] - 23s 905us/sample - loss: 0.2904 - f1: 0.6899 - val_loss: 0.4572 - val_f1: 0.6714\n",
      "Epoch 23/100\n",
      "25035/25035 [==============================] - 23s 905us/sample - loss: 0.2655 - f1: 0.6897 - val_loss: 0.3885 - val_f1: 0.6718\n",
      "Epoch 24/100\n",
      "25035/25035 [==============================] - 22s 898us/sample - loss: 0.2663 - f1: 0.6896 - val_loss: 0.2263 - val_f1: 0.6713\n",
      "Epoch 25/100\n",
      "25035/25035 [==============================] - 23s 908us/sample - loss: 0.2633 - f1: 0.6901 - val_loss: 0.2099 - val_f1: 0.6716\n",
      "Epoch 26/100\n",
      "25035/25035 [==============================] - 23s 910us/sample - loss: 0.2669 - f1: 0.6900 - val_loss: 0.1821 - val_f1: 0.6723\n",
      "Epoch 27/100\n",
      "25035/25035 [==============================] - 23s 904us/sample - loss: 0.2661 - f1: 0.6897 - val_loss: 0.2390 - val_f1: 0.6726\n",
      "Epoch 28/100\n",
      "25035/25035 [==============================] - 23s 906us/sample - loss: 0.2499 - f1: 0.6902 - val_loss: 0.1983 - val_f1: 0.6721\n",
      "Epoch 29/100\n",
      "25035/25035 [==============================] - 24s 943us/sample - loss: 0.2496 - f1: 0.6905 - val_loss: 0.1998 - val_f1: 0.6683\n",
      "Epoch 30/100\n",
      "25035/25035 [==============================] - 23s 911us/sample - loss: 0.2415 - f1: 0.6896 - val_loss: 0.2952 - val_f1: 0.6707\n",
      "Epoch 31/100\n",
      "25035/25035 [==============================] - 23s 909us/sample - loss: 0.2368 - f1: 0.6901 - val_loss: 0.2043 - val_f1: 0.6702\n",
      "Epoch 32/100\n",
      "25035/25035 [==============================] - 23s 917us/sample - loss: 0.2341 - f1: 0.6896 - val_loss: 0.3635 - val_f1: 0.6729\n",
      "Epoch 33/100\n",
      "25035/25035 [==============================] - 23s 913us/sample - loss: 0.2417 - f1: 0.6902 - val_loss: 0.2505 - val_f1: 0.6720\n",
      "Epoch 34/100\n",
      "25035/25035 [==============================] - 23s 916us/sample - loss: 0.2390 - f1: 0.6900 - val_loss: 0.2204 - val_f1: 0.6713\n",
      "Epoch 35/100\n",
      "25035/25035 [==============================] - 23s 916us/sample - loss: 0.2262 - f1: 0.6901 - val_loss: 0.2015 - val_f1: 0.6715\n",
      "Epoch 36/100\n",
      "25035/25035 [==============================] - 23s 914us/sample - loss: 0.2259 - f1: 0.6902 - val_loss: 0.1786 - val_f1: 0.6722\n",
      "Epoch 37/100\n",
      "25035/25035 [==============================] - 23s 917us/sample - loss: 0.2222 - f1: 0.6900 - val_loss: 0.1896 - val_f1: 0.6711\n",
      "Epoch 38/100\n",
      "25035/25035 [==============================] - 23s 913us/sample - loss: 0.2207 - f1: 0.6899 - val_loss: 0.2713 - val_f1: 0.6720\n",
      "Epoch 39/100\n",
      "25035/25035 [==============================] - 23s 918us/sample - loss: 0.2163 - f1: 0.6899 - val_loss: 0.3538 - val_f1: 0.6706\n",
      "Epoch 40/100\n",
      "25035/25035 [==============================] - 23s 916us/sample - loss: 0.2190 - f1: 0.6898 - val_loss: 0.3059 - val_f1: 0.6726\n",
      "Epoch 41/100\n",
      "25035/25035 [==============================] - 23s 916us/sample - loss: 0.2129 - f1: 0.6897 - val_loss: 0.1908 - val_f1: 0.6704\n",
      "Epoch 42/100\n",
      "25035/25035 [==============================] - 23s 921us/sample - loss: 0.2120 - f1: 0.6899 - val_loss: 0.2793 - val_f1: 0.6706\n",
      "Epoch 43/100\n",
      "25035/25035 [==============================] - 23s 921us/sample - loss: 0.2021 - f1: 0.6904 - val_loss: 0.1818 - val_f1: 0.6712\n",
      "Epoch 44/100\n",
      "25035/25035 [==============================] - 23s 920us/sample - loss: 0.2062 - f1: 0.6900 - val_loss: 0.2022 - val_f1: 0.6728\n",
      "Epoch 45/100\n",
      "25035/25035 [==============================] - 23s 921us/sample - loss: 0.1959 - f1: 0.6905 - val_loss: 0.1491 - val_f1: 0.6702\n",
      "Epoch 46/100\n",
      "25035/25035 [==============================] - 23s 920us/sample - loss: 0.1933 - f1: 0.6898 - val_loss: 0.5120 - val_f1: 0.6723\n",
      "Epoch 47/100\n",
      "25035/25035 [==============================] - 24s 961us/sample - loss: 0.1888 - f1: 0.6900 - val_loss: 0.1947 - val_f1: 0.6705\n",
      "Epoch 48/100\n",
      "25035/25035 [==============================] - 24s 950us/sample - loss: 0.1829 - f1: 0.6898 - val_loss: 0.1613 - val_f1: 0.6704\n",
      "Epoch 49/100\n",
      "25035/25035 [==============================] - 24s 954us/sample - loss: 0.1780 - f1: 0.6896 - val_loss: 0.2918 - val_f1: 0.6713\n",
      "Epoch 50/100\n",
      "25035/25035 [==============================] - 24s 944us/sample - loss: 0.1777 - f1: 0.6899 - val_loss: 0.1474 - val_f1: 0.6713\n",
      "Epoch 51/100\n",
      "25035/25035 [==============================] - 24s 944us/sample - loss: 0.1801 - f1: 0.6901 - val_loss: 0.1810 - val_f1: 0.6702\n",
      "Epoch 52/100\n",
      "25035/25035 [==============================] - 24s 954us/sample - loss: 0.1755 - f1: 0.6899 - val_loss: 0.1660 - val_f1: 0.6714\n",
      "Epoch 53/100\n",
      "25035/25035 [==============================] - 24s 950us/sample - loss: 0.1688 - f1: 0.6897 - val_loss: 0.2268 - val_f1: 0.6722\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 54/100\n",
      "25035/25035 [==============================] - 22s 895us/sample - loss: 0.1720 - f1: 0.6901 - val_loss: 0.1681 - val_f1: 0.6711\n",
      "Epoch 55/100\n",
      "25035/25035 [==============================] - 23s 904us/sample - loss: 0.1694 - f1: 0.6903 - val_loss: 0.1670 - val_f1: 0.6721\n",
      "Epoch 56/100\n",
      "25035/25035 [==============================] - 22s 894us/sample - loss: 0.1626 - f1: 0.6896 - val_loss: 0.1345 - val_f1: 0.6711\n",
      "Epoch 57/100\n",
      "25035/25035 [==============================] - 22s 888us/sample - loss: 0.1637 - f1: 0.6905 - val_loss: 0.1564 - val_f1: 0.6722\n",
      "Epoch 58/100\n",
      "25035/25035 [==============================] - 23s 908us/sample - loss: 0.1623 - f1: 0.6901 - val_loss: 0.2399 - val_f1: 0.6717\n",
      "Epoch 59/100\n",
      "25035/25035 [==============================] - 23s 907us/sample - loss: 0.1572 - f1: 0.6895 - val_loss: 0.1429 - val_f1: 0.6721\n",
      "Epoch 60/100\n",
      "25035/25035 [==============================] - 22s 889us/sample - loss: 0.1620 - f1: 0.6897 - val_loss: 0.4872 - val_f1: 0.6707\n",
      "Epoch 61/100\n",
      "25035/25035 [==============================] - 22s 884us/sample - loss: 0.1591 - f1: 0.6901 - val_loss: 0.2121 - val_f1: 0.6713\n",
      "Epoch 62/100\n",
      "25035/25035 [==============================] - 23s 916us/sample - loss: 0.1590 - f1: 0.6897 - val_loss: 0.1734 - val_f1: 0.6707\n",
      "Epoch 63/100\n",
      "25035/25035 [==============================] - 22s 883us/sample - loss: 0.1570 - f1: 0.6897 - val_loss: 1.0535 - val_f1: 0.6707\n",
      "Epoch 64/100\n",
      "25035/25035 [==============================] - 22s 875us/sample - loss: 0.1662 - f1: 0.6897 - val_loss: 0.2155 - val_f1: 0.6713\n",
      "Epoch 65/100\n",
      "25035/25035 [==============================] - 22s 882us/sample - loss: 0.1492 - f1: 0.6899 - val_loss: 0.1424 - val_f1: 0.6715\n",
      "Epoch 66/100\n",
      "25035/25035 [==============================] - 22s 877us/sample - loss: 0.1484 - f1: 0.6901 - val_loss: 0.1432 - val_f1: 0.6701\n",
      "Epoch 67/100\n",
      "25035/25035 [==============================] - 22s 879us/sample - loss: 0.1514 - f1: 0.6899 - val_loss: 0.1935 - val_f1: 0.6721\n",
      "Epoch 68/100\n",
      "25035/25035 [==============================] - 22s 883us/sample - loss: 0.1455 - f1: 0.6902 - val_loss: 0.3209 - val_f1: 0.6702\n",
      "Epoch 69/100\n",
      "25035/25035 [==============================] - 22s 882us/sample - loss: 0.1456 - f1: 0.6898 - val_loss: 0.1349 - val_f1: 0.6709\n",
      "Epoch 70/100\n",
      "25035/25035 [==============================] - 22s 888us/sample - loss: 0.1450 - f1: 0.6897 - val_loss: 0.2130 - val_f1: 0.6734\n",
      "Epoch 71/100\n",
      "25035/25035 [==============================] - 22s 884us/sample - loss: 0.1451 - f1: 0.6902 - val_loss: 0.1718 - val_f1: 0.6715\n",
      "Epoch 72/100\n",
      "25035/25035 [==============================] - 22s 884us/sample - loss: 0.1431 - f1: 0.6901 - val_loss: 0.2180 - val_f1: 0.6720\n",
      "Epoch 73/100\n",
      "25035/25035 [==============================] - 22s 884us/sample - loss: 0.1446 - f1: 0.6903 - val_loss: 0.1986 - val_f1: 0.6692\n",
      "Epoch 74/100\n",
      "25035/25035 [==============================] - 22s 887us/sample - loss: 0.1431 - f1: 0.6901 - val_loss: 0.4211 - val_f1: 0.6698\n",
      "Epoch 75/100\n",
      "25035/25035 [==============================] - 22s 886us/sample - loss: 0.1397 - f1: 0.6901 - val_loss: 0.1538 - val_f1: 0.6733\n",
      "Epoch 76/100\n",
      "25035/25035 [==============================] - 22s 885us/sample - loss: 0.1385 - f1: 0.6898 - val_loss: 0.2107 - val_f1: 0.6706\n",
      "Epoch 77/100\n",
      "25035/25035 [==============================] - 22s 885us/sample - loss: 0.1318 - f1: 0.6899 - val_loss: 0.2535 - val_f1: 0.6724\n",
      "Epoch 78/100\n",
      "25035/25035 [==============================] - 22s 889us/sample - loss: 0.1368 - f1: 0.6901 - val_loss: 0.4332 - val_f1: 0.6714\n",
      "Epoch 79/100\n",
      "25035/25035 [==============================] - 23s 930us/sample - loss: 0.1350 - f1: 0.6895 - val_loss: 0.3080 - val_f1: 0.6728\n",
      "Epoch 80/100\n",
      "25035/25035 [==============================] - 22s 894us/sample - loss: 0.1391 - f1: 0.6898 - val_loss: 0.1752 - val_f1: 0.6712\n",
      "Epoch 81/100\n",
      "25035/25035 [==============================] - 22s 898us/sample - loss: 0.1351 - f1: 0.6898 - val_loss: 0.2025 - val_f1: 0.6698\n",
      "Epoch 82/100\n",
      "25035/25035 [==============================] - 23s 906us/sample - loss: 0.1290 - f1: 0.6904 - val_loss: 0.1931 - val_f1: 0.6718\n",
      "Epoch 83/100\n",
      "25035/25035 [==============================] - 23s 910us/sample - loss: 0.1277 - f1: 0.6899 - val_loss: 0.2208 - val_f1: 0.6708\n",
      "Epoch 84/100\n",
      "25035/25035 [==============================] - 23s 908us/sample - loss: 0.1284 - f1: 0.6901 - val_loss: 0.2911 - val_f1: 0.6712\n",
      "Epoch 85/100\n",
      "25035/25035 [==============================] - 24s 968us/sample - loss: 0.1332 - f1: 0.6902 - val_loss: 0.3030 - val_f1: 0.6707\n",
      "Epoch 86/100\n",
      "25035/25035 [==============================] - 24s 962us/sample - loss: 0.1317 - f1: 0.6895 - val_loss: 0.1472 - val_f1: 0.6694\n",
      "Epoch 87/100\n",
      "25035/25035 [==============================] - 24s 944us/sample - loss: 0.1279 - f1: 0.6900 - val_loss: 0.1324 - val_f1: 0.6724\n",
      "Epoch 88/100\n",
      "25035/25035 [==============================] - 22s 893us/sample - loss: 0.1277 - f1: 0.6904 - val_loss: 0.3790 - val_f1: 0.6717\n",
      "Epoch 89/100\n",
      "25035/25035 [==============================] - 22s 887us/sample - loss: 0.1251 - f1: 0.6900 - val_loss: 0.2160 - val_f1: 0.6715\n",
      "Epoch 90/100\n",
      "25035/25035 [==============================] - 22s 891us/sample - loss: 0.1220 - f1: 0.6899 - val_loss: 0.3484 - val_f1: 0.6720\n",
      "Epoch 91/100\n",
      "25035/25035 [==============================] - 22s 891us/sample - loss: 0.1262 - f1: 0.6904 - val_loss: 0.3079 - val_f1: 0.6708\n",
      "Epoch 92/100\n",
      "25035/25035 [==============================] - 22s 890us/sample - loss: 0.1244 - f1: 0.6901 - val_loss: 0.2720 - val_f1: 0.6708\n",
      "Epoch 93/100\n",
      "25035/25035 [==============================] - 22s 896us/sample - loss: 0.1219 - f1: 0.6901 - val_loss: 0.1876 - val_f1: 0.6702\n",
      "Epoch 94/100\n",
      "25035/25035 [==============================] - 23s 927us/sample - loss: 0.1180 - f1: 0.6903 - val_loss: 0.3489 - val_f1: 0.6718\n",
      "Epoch 95/100\n",
      "25035/25035 [==============================] - 23s 903us/sample - loss: 0.1190 - f1: 0.6901 - val_loss: 0.3056 - val_f1: 0.6719\n",
      "Epoch 96/100\n",
      "25035/25035 [==============================] - 22s 896us/sample - loss: 0.1168 - f1: 0.6904 - val_loss: 0.2552 - val_f1: 0.6725\n",
      "Epoch 97/100\n",
      "25035/25035 [==============================] - 23s 900us/sample - loss: 0.1269 - f1: 0.6905 - val_loss: 0.2812 - val_f1: 0.6729\n",
      "Epoch 98/100\n",
      "25035/25035 [==============================] - 22s 898us/sample - loss: 0.1216 - f1: 0.6898 - val_loss: 0.1974 - val_f1: 0.6714\n",
      "Epoch 99/100\n",
      "25035/25035 [==============================] - 22s 898us/sample - loss: 0.1153 - f1: 0.6900 - val_loss: 0.2734 - val_f1: 0.6718\n",
      "Epoch 100/100\n",
      "25035/25035 [==============================] - 23s 908us/sample - loss: 0.1139 - f1: 0.6901 - val_loss: 0.2065 - val_f1: 0.6721\n",
      "FIT\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0816 23:07:17.282341 140241072178944 ag_logging.py:145] Entity <function standard_lstm at 0x7f8c0ce8f268> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: No module named 'tensorflow_core.contrib'\n",
      "W0816 23:07:17.390686 140241072178944 ag_logging.py:145] Entity <function cudnn_lstm at 0x7f8c0ce8f2f0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: No module named 'tensorflow_core.contrib'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PREDICT\n",
      "Group 7\n",
      "[0.9381295  0.94210425]\n",
      "macro 0.9401168736101713\n",
      "3\n",
      "50\n",
      "WARNING: Entity <function standard_lstm at 0x7f8c0ce8f268> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: No module named 'tensorflow_core.contrib'\n",
      "WARNING: Entity <function cudnn_lstm at 0x7f8c0ce8f2f0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: No module named 'tensorflow_core.contrib'\n",
      "OKKKK\n",
      "YOOOO\n",
      "Train on 29133 samples, validate on 934 samples\n",
      "Epoch 1/100\n",
      "29133/29133 [==============================] - 25s 854us/sample - loss: 0.7065 - f1: 0.6746 - val_loss: 0.6796 - val_f1: 0.7603\n",
      "Epoch 2/100\n",
      "29133/29133 [==============================] - 24s 811us/sample - loss: 0.6936 - f1: 0.6841 - val_loss: 0.6885 - val_f1: 0.7593\n",
      "Epoch 3/100\n",
      "29133/29133 [==============================] - 24s 813us/sample - loss: 0.6625 - f1: 0.6835 - val_loss: 0.4217 - val_f1: 0.7577\n",
      "Epoch 4/100\n",
      "29133/29133 [==============================] - 24s 815us/sample - loss: 0.5548 - f1: 0.6844 - val_loss: 0.3473 - val_f1: 0.7597\n",
      "Epoch 5/100\n",
      "29133/29133 [==============================] - 24s 818us/sample - loss: 0.5084 - f1: 0.6843 - val_loss: 0.4756 - val_f1: 0.7611\n",
      "Epoch 6/100\n",
      "29133/29133 [==============================] - 24s 816us/sample - loss: 0.3965 - f1: 0.6842 - val_loss: 0.3283 - val_f1: 0.7570\n",
      "Epoch 7/100\n",
      "29133/29133 [==============================] - 24s 817us/sample - loss: 0.3365 - f1: 0.6851 - val_loss: 0.2161 - val_f1: 0.7542\n",
      "Epoch 8/100\n",
      "29133/29133 [==============================] - 25s 842us/sample - loss: 0.2987 - f1: 0.6851 - val_loss: 0.2049 - val_f1: 0.7517\n",
      "Epoch 9/100\n",
      "29133/29133 [==============================] - 24s 822us/sample - loss: 0.2851 - f1: 0.6846 - val_loss: 0.1644 - val_f1: 0.7575\n",
      "Epoch 10/100\n",
      "29133/29133 [==============================] - 25s 855us/sample - loss: 0.2681 - f1: 0.6846 - val_loss: 0.1504 - val_f1: 0.7535\n",
      "Epoch 11/100\n",
      "29133/29133 [==============================] - 25s 875us/sample - loss: 0.2587 - f1: 0.6840 - val_loss: 0.1732 - val_f1: 0.7633\n",
      "Epoch 12/100\n",
      "29133/29133 [==============================] - 24s 830us/sample - loss: 0.2527 - f1: 0.6847 - val_loss: 0.1761 - val_f1: 0.7566\n",
      "Epoch 13/100\n",
      "29133/29133 [==============================] - 24s 826us/sample - loss: 0.2465 - f1: 0.6845 - val_loss: 0.1425 - val_f1: 0.7552\n",
      "Epoch 14/100\n",
      "29133/29133 [==============================] - 25s 869us/sample - loss: 0.2450 - f1: 0.6848 - val_loss: 0.1106 - val_f1: 0.7493\n",
      "Epoch 15/100\n",
      "29133/29133 [==============================] - 27s 918us/sample - loss: 0.2438 - f1: 0.6842 - val_loss: 0.2109 - val_f1: 0.7608\n",
      "Epoch 16/100\n",
      "29133/29133 [==============================] - 26s 906us/sample - loss: 0.2263 - f1: 0.6847 - val_loss: 0.1096 - val_f1: 0.7568\n",
      "Epoch 17/100\n",
      "29133/29133 [==============================] - 28s 970us/sample - loss: 0.2229 - f1: 0.6847 - val_loss: 0.1582 - val_f1: 0.7578\n",
      "Epoch 18/100\n",
      "29133/29133 [==============================] - 26s 907us/sample - loss: 0.2172 - f1: 0.6848 - val_loss: 0.1766 - val_f1: 0.7581\n",
      "Epoch 19/100\n",
      "29133/29133 [==============================] - 26s 909us/sample - loss: 0.2051 - f1: 0.6845 - val_loss: 0.1402 - val_f1: 0.7569\n",
      "Epoch 20/100\n",
      "29133/29133 [==============================] - 27s 912us/sample - loss: 0.2036 - f1: 0.6845 - val_loss: 0.2908 - val_f1: 0.7577\n",
      "Epoch 21/100\n",
      "29133/29133 [==============================] - 26s 908us/sample - loss: 0.1984 - f1: 0.6845 - val_loss: 0.1290 - val_f1: 0.7569\n",
      "Epoch 22/100\n",
      "29133/29133 [==============================] - 27s 923us/sample - loss: 0.1924 - f1: 0.6847 - val_loss: 0.2053 - val_f1: 0.7578\n",
      "Epoch 23/100\n",
      "29133/29133 [==============================] - 28s 954us/sample - loss: 0.1910 - f1: 0.6845 - val_loss: 0.4046 - val_f1: 0.7568\n",
      "Epoch 24/100\n",
      "29133/29133 [==============================] - 27s 934us/sample - loss: 0.1831 - f1: 0.6849 - val_loss: 0.2490 - val_f1: 0.7435\n",
      "Epoch 25/100\n",
      "29133/29133 [==============================] - 30s 1ms/sample - loss: 0.1787 - f1: 0.6846 - val_loss: 0.1134 - val_f1: 0.7593\n",
      "Epoch 26/100\n",
      "29133/29133 [==============================] - 27s 933us/sample - loss: 0.1789 - f1: 0.6847 - val_loss: 0.0977 - val_f1: 0.7633\n",
      "Epoch 27/100\n",
      "29133/29133 [==============================] - 27s 916us/sample - loss: 0.1739 - f1: 0.6846 - val_loss: 0.3567 - val_f1: 0.7570\n",
      "Epoch 28/100\n",
      "29133/29133 [==============================] - 27s 933us/sample - loss: 0.1731 - f1: 0.6848 - val_loss: 0.1528 - val_f1: 0.7349\n",
      "Epoch 29/100\n",
      "29133/29133 [==============================] - 26s 897us/sample - loss: 0.1680 - f1: 0.6842 - val_loss: 0.1592 - val_f1: 0.7511\n",
      "Epoch 30/100\n",
      "29133/29133 [==============================] - 25s 862us/sample - loss: 0.1664 - f1: 0.6846 - val_loss: 0.3427 - val_f1: 0.7551\n",
      "Epoch 31/100\n",
      "29133/29133 [==============================] - 23s 794us/sample - loss: 0.1671 - f1: 0.6848 - val_loss: 0.0992 - val_f1: 0.7589\n",
      "Epoch 32/100\n",
      "29133/29133 [==============================] - 23s 781us/sample - loss: 0.1645 - f1: 0.6845 - val_loss: 0.1685 - val_f1: 0.7495\n",
      "Epoch 33/100\n",
      "29133/29133 [==============================] - 23s 788us/sample - loss: 0.1561 - f1: 0.6845 - val_loss: 0.2004 - val_f1: 0.7595\n",
      "Epoch 34/100\n",
      "29133/29133 [==============================] - 23s 778us/sample - loss: 0.1574 - f1: 0.6842 - val_loss: 0.2073 - val_f1: 0.7601\n",
      "Epoch 35/100\n",
      "29133/29133 [==============================] - 23s 806us/sample - loss: 0.1593 - f1: 0.6847 - val_loss: 0.2178 - val_f1: 0.7499\n",
      "Epoch 36/100\n",
      "29133/29133 [==============================] - 24s 823us/sample - loss: 0.1517 - f1: 0.6849 - val_loss: 0.1606 - val_f1: 0.7635\n",
      "Epoch 37/100\n",
      "29133/29133 [==============================] - 23s 782us/sample - loss: 0.1502 - f1: 0.6845 - val_loss: 0.0932 - val_f1: 0.7606\n",
      "Epoch 38/100\n",
      "29133/29133 [==============================] - 23s 785us/sample - loss: 0.1506 - f1: 0.6846 - val_loss: 0.3038 - val_f1: 0.7603\n",
      "Epoch 39/100\n",
      "29133/29133 [==============================] - 23s 781us/sample - loss: 0.1472 - f1: 0.6844 - val_loss: 0.1178 - val_f1: 0.7560\n",
      "Epoch 40/100\n",
      "29133/29133 [==============================] - 23s 783us/sample - loss: 0.1487 - f1: 0.6847 - val_loss: 0.8016 - val_f1: 0.7480\n",
      "Epoch 41/100\n",
      "29133/29133 [==============================] - 23s 781us/sample - loss: 0.1454 - f1: 0.6848 - val_loss: 0.5111 - val_f1: 0.7540\n",
      "Epoch 42/100\n",
      "29133/29133 [==============================] - 23s 783us/sample - loss: 0.1402 - f1: 0.6844 - val_loss: 0.1528 - val_f1: 0.7580\n",
      "Epoch 43/100\n",
      "29133/29133 [==============================] - 23s 782us/sample - loss: 0.1404 - f1: 0.6846 - val_loss: 0.3227 - val_f1: 0.7583\n",
      "Epoch 44/100\n",
      "29133/29133 [==============================] - 23s 787us/sample - loss: 0.1423 - f1: 0.6845 - val_loss: 0.3090 - val_f1: 0.7583\n",
      "Epoch 45/100\n",
      "29133/29133 [==============================] - 23s 785us/sample - loss: 0.1421 - f1: 0.6845 - val_loss: 0.1534 - val_f1: 0.7577\n",
      "Epoch 46/100\n",
      "29133/29133 [==============================] - 23s 788us/sample - loss: 0.1353 - f1: 0.6842 - val_loss: 0.1984 - val_f1: 0.7551\n",
      "Epoch 47/100\n",
      "29133/29133 [==============================] - 23s 787us/sample - loss: 0.1309 - f1: 0.6846 - val_loss: 0.1784 - val_f1: 0.7547\n",
      "Epoch 48/100\n",
      "29133/29133 [==============================] - 23s 789us/sample - loss: 0.1364 - f1: 0.6848 - val_loss: 0.2349 - val_f1: 0.7492\n",
      "Epoch 49/100\n",
      "29133/29133 [==============================] - 23s 792us/sample - loss: 0.1306 - f1: 0.6849 - val_loss: 0.5313 - val_f1: 0.7586\n",
      "Epoch 50/100\n",
      "29133/29133 [==============================] - 23s 789us/sample - loss: 0.1342 - f1: 0.6848 - val_loss: 0.3867 - val_f1: 0.7574\n",
      "Epoch 51/100\n",
      "29133/29133 [==============================] - 23s 792us/sample - loss: 0.1296 - f1: 0.6840 - val_loss: 0.2909 - val_f1: 0.7608\n",
      "Epoch 52/100\n",
      "29133/29133 [==============================] - 23s 793us/sample - loss: 0.1269 - f1: 0.6846 - val_loss: 0.2680 - val_f1: 0.7529\n",
      "Epoch 53/100\n",
      "29133/29133 [==============================] - 23s 795us/sample - loss: 0.1247 - f1: 0.6842 - val_loss: 0.8732 - val_f1: 0.7583\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 54/100\n",
      "29133/29133 [==============================] - 22s 742us/sample - loss: 0.1240 - f1: 0.6845 - val_loss: 0.0795 - val_f1: 0.7580\n",
      "Epoch 55/100\n",
      "29133/29133 [==============================] - 22s 740us/sample - loss: 0.1228 - f1: 0.6846 - val_loss: 0.3595 - val_f1: 0.7636\n",
      "Epoch 56/100\n",
      "29133/29133 [==============================] - 22s 743us/sample - loss: 0.1241 - f1: 0.6848 - val_loss: 0.1542 - val_f1: 0.7532\n",
      "Epoch 57/100\n",
      "29133/29133 [==============================] - 22s 742us/sample - loss: 0.1271 - f1: 0.6847 - val_loss: 0.1000 - val_f1: 0.7553\n",
      "Epoch 58/100\n",
      "29133/29133 [==============================] - 22s 742us/sample - loss: 0.1219 - f1: 0.6843 - val_loss: 0.1479 - val_f1: 0.7604\n",
      "Epoch 59/100\n",
      "29133/29133 [==============================] - 22s 744us/sample - loss: 0.1224 - f1: 0.6846 - val_loss: 0.7428 - val_f1: 0.7490\n",
      "Epoch 60/100\n",
      "29133/29133 [==============================] - 22s 748us/sample - loss: 0.1192 - f1: 0.6844 - val_loss: 0.1402 - val_f1: 0.7483\n",
      "Epoch 61/100\n",
      "29133/29133 [==============================] - 22s 746us/sample - loss: 0.1156 - f1: 0.6847 - val_loss: 0.1233 - val_f1: 0.7532\n",
      "Epoch 62/100\n",
      "29133/29133 [==============================] - 22s 744us/sample - loss: 0.1219 - f1: 0.6842 - val_loss: 0.2463 - val_f1: 0.7496\n",
      "Epoch 63/100\n",
      "29133/29133 [==============================] - 22s 739us/sample - loss: 0.1214 - f1: 0.6847 - val_loss: 0.1986 - val_f1: 0.7575\n",
      "Epoch 64/100\n",
      "29133/29133 [==============================] - 21s 734us/sample - loss: 0.1119 - f1: 0.6844 - val_loss: 0.3621 - val_f1: 0.7542\n",
      "Epoch 65/100\n",
      "29133/29133 [==============================] - 22s 739us/sample - loss: 0.1136 - f1: 0.6844 - val_loss: 0.3496 - val_f1: 0.7579\n",
      "Epoch 66/100\n",
      "29133/29133 [==============================] - 21s 737us/sample - loss: 0.1141 - f1: 0.6844 - val_loss: 0.3263 - val_f1: 0.7546\n",
      "Epoch 67/100\n",
      "29133/29133 [==============================] - 21s 736us/sample - loss: 0.1097 - f1: 0.6844 - val_loss: 0.5714 - val_f1: 0.7538\n",
      "Epoch 68/100\n",
      "29133/29133 [==============================] - 21s 737us/sample - loss: 0.1220 - f1: 0.6846 - val_loss: 0.1009 - val_f1: 0.7637\n",
      "Epoch 69/100\n",
      "29133/29133 [==============================] - 21s 737us/sample - loss: 0.1066 - f1: 0.6846 - val_loss: 0.2771 - val_f1: 0.7541\n",
      "Epoch 70/100\n",
      "29133/29133 [==============================] - 22s 739us/sample - loss: 0.1109 - f1: 0.6848 - val_loss: 0.2502 - val_f1: 0.7608\n",
      "Epoch 71/100\n",
      "29133/29133 [==============================] - 22s 741us/sample - loss: 0.1064 - f1: 0.6844 - val_loss: 0.1376 - val_f1: 0.7604\n",
      "Epoch 72/100\n",
      "29133/29133 [==============================] - 22s 741us/sample - loss: 0.1072 - f1: 0.6849 - val_loss: 0.2091 - val_f1: 0.7499\n",
      "Epoch 73/100\n",
      "29133/29133 [==============================] - 22s 740us/sample - loss: 0.1062 - f1: 0.6846 - val_loss: 0.3017 - val_f1: 0.7479\n",
      "Epoch 74/100\n",
      "29133/29133 [==============================] - 22s 741us/sample - loss: 0.1037 - f1: 0.6843 - val_loss: 0.5077 - val_f1: 0.7550\n",
      "Epoch 75/100\n",
      "29133/29133 [==============================] - 22s 741us/sample - loss: 0.1034 - f1: 0.6844 - val_loss: 0.3040 - val_f1: 0.7537\n",
      "Epoch 76/100\n",
      "29133/29133 [==============================] - 22s 746us/sample - loss: 0.1045 - f1: 0.6844 - val_loss: 0.1858 - val_f1: 0.7611\n",
      "Epoch 77/100\n",
      "29133/29133 [==============================] - 22s 742us/sample - loss: 0.1034 - f1: 0.6846 - val_loss: 0.3644 - val_f1: 0.7570\n",
      "Epoch 78/100\n",
      "29133/29133 [==============================] - 22s 745us/sample - loss: 0.1009 - f1: 0.6845 - val_loss: 0.5496 - val_f1: 0.7492\n",
      "Epoch 79/100\n",
      "29133/29133 [==============================] - 22s 744us/sample - loss: 0.0974 - f1: 0.6847 - val_loss: 0.2559 - val_f1: 0.7499\n",
      "Epoch 80/100\n",
      "29133/29133 [==============================] - 22s 746us/sample - loss: 0.1025 - f1: 0.6845 - val_loss: 0.4296 - val_f1: 0.7528\n",
      "Epoch 81/100\n",
      "29133/29133 [==============================] - 22s 744us/sample - loss: 0.1065 - f1: 0.6849 - val_loss: 0.3163 - val_f1: 0.7580\n",
      "Epoch 82/100\n",
      "29133/29133 [==============================] - 22s 751us/sample - loss: 0.0982 - f1: 0.6843 - val_loss: 0.1993 - val_f1: 0.7573\n",
      "Epoch 83/100\n",
      "29133/29133 [==============================] - 22s 748us/sample - loss: 0.0964 - f1: 0.6844 - val_loss: 0.3377 - val_f1: 0.7600\n",
      "Epoch 84/100\n",
      "29133/29133 [==============================] - 22s 746us/sample - loss: 0.0966 - f1: 0.6843 - val_loss: 0.2750 - val_f1: 0.7608\n",
      "Epoch 85/100\n",
      "29133/29133 [==============================] - 22s 749us/sample - loss: 0.1012 - f1: 0.6845 - val_loss: 0.3702 - val_f1: 0.7605\n",
      "Epoch 86/100\n",
      "29133/29133 [==============================] - 22s 746us/sample - loss: 0.0986 - f1: 0.6847 - val_loss: 0.1939 - val_f1: 0.7548\n",
      "Epoch 87/100\n",
      "29133/29133 [==============================] - 22s 752us/sample - loss: 0.0959 - f1: 0.6846 - val_loss: 0.2795 - val_f1: 0.7618\n",
      "Epoch 88/100\n",
      "29133/29133 [==============================] - 22s 752us/sample - loss: 0.0963 - f1: 0.6851 - val_loss: 0.3036 - val_f1: 0.7569\n",
      "Epoch 89/100\n",
      "29133/29133 [==============================] - 22s 754us/sample - loss: 0.0915 - f1: 0.6849 - val_loss: 0.6790 - val_f1: 0.7582\n",
      "Epoch 90/100\n",
      "29133/29133 [==============================] - 22s 751us/sample - loss: 0.0941 - f1: 0.6852 - val_loss: 0.9410 - val_f1: 0.7615\n",
      "Epoch 91/100\n",
      "29133/29133 [==============================] - 22s 753us/sample - loss: 0.0976 - f1: 0.6847 - val_loss: 0.4720 - val_f1: 0.7526\n",
      "Epoch 92/100\n",
      "29133/29133 [==============================] - 22s 754us/sample - loss: 0.0953 - f1: 0.6847 - val_loss: 0.1276 - val_f1: 0.7537\n",
      "Epoch 93/100\n",
      "29133/29133 [==============================] - 22s 763us/sample - loss: 0.0898 - f1: 0.6846 - val_loss: 0.2475 - val_f1: 0.7551\n",
      "Epoch 94/100\n",
      "29133/29133 [==============================] - 22s 756us/sample - loss: 0.0873 - f1: 0.6844 - val_loss: 0.4579 - val_f1: 0.7566\n",
      "Epoch 95/100\n",
      "29133/29133 [==============================] - 22s 755us/sample - loss: 0.0926 - f1: 0.6847 - val_loss: 0.6272 - val_f1: 0.7577\n",
      "Epoch 96/100\n",
      "29133/29133 [==============================] - 22s 755us/sample - loss: 0.0938 - f1: 0.6849 - val_loss: 0.1105 - val_f1: 0.7475\n",
      "Epoch 97/100\n",
      "29133/29133 [==============================] - 22s 759us/sample - loss: 0.0864 - f1: 0.6846 - val_loss: 0.5540 - val_f1: 0.7478\n",
      "Epoch 98/100\n",
      "29133/29133 [==============================] - 22s 763us/sample - loss: 0.0891 - f1: 0.6848 - val_loss: 0.4656 - val_f1: 0.7636\n",
      "Epoch 99/100\n",
      "29133/29133 [==============================] - 22s 758us/sample - loss: 0.0879 - f1: 0.6846 - val_loss: 0.3036 - val_f1: 0.7530\n",
      "Epoch 100/100\n",
      "29133/29133 [==============================] - 22s 762us/sample - loss: 0.0883 - f1: 0.6842 - val_loss: 0.3096 - val_f1: 0.7607\n",
      "FIT\n",
      "PREDICT\n",
      "Group 8\n",
      "[0.78730159 0.8917609 ]\n",
      "macro 0.8395312459932815\n",
      "Average f1 macro 0.7988263192097561\n",
      "[0.75029846 0.84735418]\n",
      "[0.90592657811929, 0.9157763684555895, 0.7785574996094827, 0.7911633874798245, 0.4347541322289322, 0.9290577059654244, 0.6545530814258089, 0.9401168736101713, 0.8395312459932815]\n"
     ]
    }
   ],
   "source": [
    "## Correct way to do nested LOOCV\n",
    "# nested LOOCV with the all combis and hyperparameter tuning\n",
    "from sklearn.model_selection import LeaveOneGroupOut\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.metrics import f1_score\n",
    "from os import listdir\n",
    "from os import path\n",
    "import re\n",
    "import csv\n",
    "from keras import backend as K\n",
    "\n",
    "n_features, n_timesteps = 1, 2\n",
    "\n",
    "def evaluate_model(trainX, trainy, testX, testy, y_true, model):\n",
    "#     trainy, testy = trainy[:,0], testy[:,0]\n",
    "    print('YOOOO')\n",
    "\n",
    "    epochs, batch_size = 100, 32\n",
    "    # fit the model\n",
    "    history = model.fit(trainX, trainy, validation_data=(testX, testy), epochs = epochs, batch_size=batch_size)\n",
    "    print('FIT')\n",
    "    # make predictions\n",
    "    yhat = model.predict_classes(testX, batch_size=batch_size)\n",
    "#     print(yhat)\n",
    "#     print(y_true)\n",
    "\n",
    "#     hat, test = 0,0\n",
    "#     for i in range(len(yhat)):\n",
    "#         if yhat[i] == 0:\n",
    "#             hat += 1\n",
    "#         if testy[i][0] == 0:\n",
    "#             test += 1\n",
    "#     print('hat', hat)\n",
    "#     print('test', test)\n",
    "    # evaluate predictions\n",
    "#     accuracy = balanced_accuracy_score(testy, yhat)\n",
    "\n",
    "    print('PREDICT')\n",
    "    f1_macro = f1_score(y_true, yhat, average='macro')\n",
    "    f1 = f1_score(y_true, yhat, average=None)\n",
    "#     _, accuracy = model.evaluate(testX, testy, verbose=verbose)\n",
    "\n",
    "#     print('accuracy:', accuracy)\n",
    "#     print(classification_report(testy, yhat))\n",
    "#     print(confusion_matrix(testy, yhat))\n",
    "    return f1, f1_macro, history\n",
    "\n",
    "def f1(y_true, y_pred):\n",
    "    def recall(y_true, y_pred):\n",
    "        \"\"\"Recall metric.\n",
    "\n",
    "        Only computes a batch-wise average of recall.\n",
    "\n",
    "        Computes the recall, a metric for multi-label classification of\n",
    "        how many relevant items are selected.\n",
    "        \"\"\"\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "        recall = true_positives / (possible_positives + K.epsilon())\n",
    "        return recall\n",
    "\n",
    "    def precision(y_true, y_pred):\n",
    "        \"\"\"Precision metric.\n",
    "\n",
    "        Only computes a batch-wise average of precision.\n",
    "\n",
    "        Computes the precision, a metric for multi-label classification of\n",
    "        how many selected items are relevant.\n",
    "        \"\"\"\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "        precision = true_positives / (predicted_positives + K.epsilon())\n",
    "        return precision\n",
    "    precision = precision(y_true, y_pred)\n",
    "    recall = recall(y_true, y_pred)\n",
    "    return 2*((precision*recall)/(precision+recall+K.epsilon()))\n",
    "\n",
    "def f1_new(y_true, y_pred):\n",
    "    y_pred = K.round(y_pred)\n",
    "    tp = K.sum(K.cast(y_true*y_pred, 'float'), axis=0)\n",
    "    tn = K.sum(K.cast((1-y_true)*(1-y_pred), 'float'), axis=0)\n",
    "    fp = K.sum(K.cast((1-y_true)*y_pred, 'float'), axis=0)\n",
    "    fn = K.sum(K.cast(y_true*(1-y_pred), 'float'), axis=0)\n",
    "\n",
    "    p = tp / (tp + fp + K.epsilon())\n",
    "    r = tp / (tp + fn + K.epsilon())\n",
    "\n",
    "    f1 = 2*p*r / (p+r+K.epsilon())\n",
    "    f1 = tf.where(tf.math.is_nan(f1), tf.zeros_like(f1), f1)\n",
    "    return K.mean(f1)\n",
    "\n",
    "def f1_loss(y_true, y_pred):\n",
    "    \n",
    "    tp = K.sum(K.cast(y_true*y_pred, 'float'), axis=0)\n",
    "    tn = K.sum(K.cast((1-y_true)*(1-y_pred), 'float'), axis=0)\n",
    "    fp = K.sum(K.cast((1-y_true)*y_pred, 'float'), axis=0)\n",
    "    fn = K.sum(K.cast(y_true*(1-y_pred), 'float'), axis=0)\n",
    "\n",
    "    p = tp / (tp + fp + K.epsilon())\n",
    "    r = tp / (tp + fn + K.epsilon())\n",
    "\n",
    "    f1 = 2*p*r / (p+r+K.epsilon())\n",
    "    f1 = tf.where(tf.math.is_nan(f1), tf.zeros_like(f1), f1)\n",
    "    return 1 - K.mean(f1)\n",
    "\n",
    "def create_model():\n",
    "    clf = Sequential()\n",
    "    clf.add(LSTM(100, input_shape=(n_timesteps,n_features)))\n",
    "    clf.add(Dropout(0.5))\n",
    "    clf.add(Dense(100, activation='relu'))\n",
    "#     clf.add(Flatten())\n",
    "    clf.add(Dense(4, activation='softmax'))\n",
    "    clf.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=[f1])\n",
    "\n",
    "    return clf\n",
    "\n",
    "def run_nested_logo(source, dest, key):    \n",
    "    global n_features\n",
    "    global n_timesteps\n",
    "    \n",
    "    logo = LeaveOneGroupOut()\n",
    "\n",
    "    i = 1\n",
    "    \n",
    "    done = ['30_15_4', '10_5_1', '5_3_2', '60_30_8', '60_90_0', '5_5_4', '30_45_23',\n",
    "        '5_5_0', '30_30_8', '60_90_68', '50_100_75', '30_30_15', '60_120_90',\n",
    "        '10_10_8', '10_20_0', '30_15_0', '60_30_23', '50_25_0', '50_25_6', '30_45_0',\n",
    "        '5_10_8', '30_15_11']\n",
    "    \n",
    "    hist_per_group = list()\n",
    "    \n",
    "    for name in listdir(source):\n",
    "        filename = source + '/' + name\n",
    "        if not name.endswith('csv') or not name.startswith('total_acc_x_train_'):\n",
    "            continue\n",
    "#         pattern = 'total_acc_x_train_' + '[0-9]*[0-9]_[0-9]*[0-9]_[0-9]*[0-9]' + '.csv'\n",
    "        pattern = 'total_acc_x_train_' + '50_50_38' + '.csv'\n",
    "        match = re.search(pattern, name)\n",
    "        if not match:\n",
    "            continue\n",
    "\n",
    "        combi = re.search('train_(.+?).csv', name)\n",
    "        print(combi)\n",
    "        if combi:\n",
    "            combi = combi.group(1)\n",
    "        print(combi)            \n",
    "            \n",
    "        print(i, 'out of 79 files')\n",
    "        print('Reading file', name)\n",
    "        \n",
    "        X_all, y_all, subjects = load_dataset(comb=combi, prefix=source)\n",
    "        for i in range(len(y_all)):\n",
    "            if y_all[i] == 2:\n",
    "                y_all[i] = 0\n",
    "            elif y_all[i] == 3:\n",
    "                y_all[i] = 1\n",
    "        # dummy dataset just for logo.split\n",
    "        X_dummy = np.arange(len(X_all))\n",
    "\n",
    "#         ind = subjects.index[subjects[0] != 'laura'].tolist()\n",
    "#         X_dummy = X_dummy[ind]\n",
    "#         groups = subjects[subjects[0] != 'laura'].iloc[:,0]\n",
    "#         print(len(groups))\n",
    "        groups = subjects.iloc[:,0]\n",
    "#         print(groups)\n",
    "        \n",
    "#         train_ind = subjects.index[subjects[0] == 'lenin'].tolist()\n",
    "#         train_ind.extend(subjects.index[subjects[0] == 'bojan'].tolist())\n",
    "#         train_ind.extend(subjects.index[subjects[0] == 'sue'].tolist())\n",
    "#         train_ind.extend(subjects.index[subjects[0] == 'jacob'].tolist())\n",
    "#         train_ind.extend(subjects.index[subjects[0] == 'dilhan'].tolist())\n",
    "#         train_ind.extend(subjects.index[subjects[0] == 'miguel'].tolist())\n",
    "#         train_ind.extend(subjects.index[subjects[0] == 'laura'].tolist())\n",
    "#         test_ind = subjects.index[subjects[0] == 'daniel'].tolist()\n",
    "#         test_ind.extend(subjects.index[subjects[0] == 'saeid'].tolist())\n",
    "#         test_ind.extend(subjects.index[subjects[0] == 'daniel'].tolist())\n",
    "#         test_ind.extend(subjects.index[subjects[0] == 'miguel'].tolist())\n",
    "        \n",
    "#         print(train_ind)\n",
    "#         print(test_ind)\n",
    "#         X_train, X_test = X_all[train_ind], X_all[test_ind]\n",
    "#         y_train, y_test = y_all[train_ind], y_all[test_ind]\n",
    "        \n",
    "#         y_train = to_categorical(y_train)\n",
    "#         y_true = y_test\n",
    "#         y_test = to_categorical(y_test)\n",
    "\n",
    "#         n_features = X_train.shape[2]\n",
    "#         n_timesteps = X_train.shape[1]\n",
    "        \n",
    "#         clf = create_model()\n",
    "        \n",
    "#         f1, f1_macro, test_history = evaluate_model(X_train, y_train, X_test, y_test, y_true, clf)\n",
    "\n",
    "#         hist_per_group.append(test_history)\n",
    "#         print('f1',f1)\n",
    "#         print('f1_macro', f1_macro)\n",
    "        \n",
    "#         results = run_logo(trainX, trainy, subjects.iloc[:,0], X_dummy)\n",
    "\n",
    "#         all_df = pd.read_csv(filename)\n",
    "\n",
    "#         X_all = all_df.drop(['state', 'name'], axis=1)\n",
    "#         y_all = pd.DataFrame(all_df['state'])\n",
    "#         groups = all_df['name']\n",
    "\n",
    "        # counting the number of samples per class\n",
    "#         freq = [0,0,0,0]\n",
    "#         for val in y_all['state']:\n",
    "#             freq[val] += 1\n",
    "\n",
    "#         print('class frequencies', freq)\n",
    "    \n",
    "        group = 0\n",
    "        \n",
    "        f1s = []\n",
    "        f1_macros = []\n",
    "        best_params = []\n",
    "        best_scores = []\n",
    "    \n",
    "        hist_per_group = list()\n",
    "        for train_index, test_index in logo.split(X_dummy, groups=groups):\n",
    "#             if group > 6:\n",
    "#                 group += 1\n",
    "#                 continue\n",
    "            X_train, X_test = X_all[train_index], X_all[test_index]\n",
    "            y_train, y_test = y_all[train_index], y_all[test_index]\n",
    "                \n",
    "#             y_train = to_categorical(y_train)\n",
    "            y_true = y_test\n",
    "#             y_test = to_categorical(y_test)\n",
    "            \n",
    "            n_features = X_train.shape[2]\n",
    "            n_timesteps = X_train.shape[1]\n",
    "            \n",
    "            print(n_features)\n",
    "            print(n_timesteps)\n",
    "#             print(n_outputs)\n",
    "            \n",
    "            clf = create_model()\n",
    "            \n",
    "            print('OKKKK')\n",
    "            f1, f1_macro, history = evaluate_model(X_train, y_train, X_test, y_test, y_true, clf)\n",
    "            print('Group', group)\n",
    "#             print(grid_obj.best_params_)\n",
    "            print(f1)\n",
    "            print('macro', f1_macro)\n",
    "#             print(grid_obj.best_score_)\n",
    "            f1s.append(f1)\n",
    "            f1_macros.append(f1_macro)\n",
    "#             best_params.append(grid_obj.best_params_)\n",
    "#             best_scores.append(grid_obj.best_score_)\n",
    "            \n",
    "            # Storing history object in list\n",
    "            hist_per_group.append(history)\n",
    "#             plt.plot(history.history['loss'])\n",
    "#             plt.plot(history.history['val_loss'])\n",
    "#             plt.title('model loss')\n",
    "#             plt.ylabel('loss')\n",
    "#             plt.xlabel('epoch')\n",
    "#             plt.legend(['train', 'test'], loc='upper left')\n",
    "#             plt.show()\n",
    "            \n",
    "            group += 1\n",
    "\n",
    "# #         header = ['comb']\n",
    "# #         row = [combi]\n",
    "        \n",
    "# #         # create header\n",
    "# #         for j in range(9):\n",
    "# #             header.append('f1-0'+'.'+str(j))\n",
    "# #             header.append('f1-1'+'.'+str(j))\n",
    "# #             header.append('f1-2'+'.'+str(j))\n",
    "# #             header.append('f1-3'+'.'+str(j))\n",
    "# #             header.append('macro'+'.'+str(j))\n",
    "# #             header.append('best_score_'+'.'+str())\n",
    "# #             header.append('hyper'+'.'+str(j))\n",
    "            \n",
    "# #             row.extend(f1s[j])\n",
    "# #             row.append(f1_macros[j])\n",
    "# #             row.append(best_scores[j])\n",
    "# #             row.append(best_params[j])\n",
    "\n",
    "# #         outFilename = dest + '/' + key + '.csv'\n",
    "# #         if not path.isfile(outFilename):\n",
    "# #             print('creating new file', outFilename)\n",
    "# #             with open(outFilename, 'w') as outFile:\n",
    "# #                 writer = csv.writer(outFile)\n",
    "# #                 writer.writerow(header)\n",
    "# #                 writer.writerow(row)\n",
    "# #                 outFile.close()\n",
    "# #         else:\n",
    "# #             print('opening existing file', outFilename)\n",
    "# #             with open(outFilename, 'a+') as outFile:\n",
    "# #                 writer = csv.writer(outFile)\n",
    "# #                 writer.writerow(row)\n",
    "# #                 outFile.close()\n",
    "#         i += 1\n",
    "        \n",
    "    print('Average f1 macro', np.average(f1_macros))\n",
    "    print(np.average(f1s, axis=0))\n",
    "    print(f1_macros)\n",
    "#     return np.average(f1s, axis=0).tolist(), [np.average(f1_macros).tolist()], [np.average(f1_micros).tolist()], best_params, best_scores\n",
    "    return np.average(f1_macros), hist_per_group\n",
    "\n",
    "source = '../data/processed/train/keras/done/'\n",
    "dest = 'results/'\n",
    "\n",
    "k_history = list()\n",
    "k_macro = list()\n",
    "for k in range(1):\n",
    "    avg_macro, test_history = run_nested_logo(source, dest, 'lstm')\n",
    "    k_history.append(test_history)\n",
    "    k_macro.append(k_macro)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              0\n",
      "count  5.000000\n",
      "mean   0.797754\n",
      "std    0.028011\n",
      "min    0.749803\n",
      "25%    0.798826\n",
      "50%    0.805530\n",
      "75%    0.814758\n",
      "max    0.819851\n",
      "              0\n",
      "count  5.000000\n",
      "mean   0.746127\n",
      "std    0.041940\n",
      "min    0.674789\n",
      "25%    0.750298\n",
      "50%    0.755727\n",
      "75%    0.765424\n",
      "max    0.784399\n",
      "              0\n",
      "count  5.000000\n",
      "mean   0.849380\n",
      "std    0.017694\n",
      "min    0.824817\n",
      "25%    0.845637\n",
      "50%    0.847354\n",
      "75%    0.855303\n",
      "max    0.873789\n"
     ]
    }
   ],
   "source": [
    "o = [0.819851,0.8147578473634383,0.7498026610342032,0.8055300928921322,0.7988263192097561]\n",
    "c_0 = [0.784399,0.75572681,0.67478851,0.76542358,0.75029846]\n",
    "c_1 = [0.855303,0.87378888,0.82481681,0.8456366,0.84735418]\n",
    "print(pd.DataFrame(o).describe())\n",
    "print(pd.DataFrame(c_0).describe())\n",
    "print(pd.DataFrame(c_1).describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              0\n",
      "count  9.000000\n",
      "mean   0.495128\n",
      "std    0.259485\n",
      "min    0.159863\n",
      "25%    0.307221\n",
      "50%    0.513505\n",
      "75%    0.740796\n",
      "max    0.828857\n"
     ]
    }
   ],
   "source": [
    "z_50_50_38 = 0.49512783109969344\n",
    "z_50_50_38 = [0.7780049163917333, 0.7407961948482509, 0.33234433468679037, 0.5135050376949816, 0.15986331732545253, 0.8288569831366656, 0.307220661228845, 0.6138957762341468, 0.1816632583503749]\n",
    "\n",
    "# z_50_50_38 = [0.46847288,0.70839441,0.41008564,0.3935584]\n",
    "print(pd.DataFrame(z_50_50_38).describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              0\n",
      "count  5.000000\n",
      "mean   0.712288\n",
      "std    0.013486\n",
      "min    0.695157\n",
      "25%    0.704577\n",
      "50%    0.709957\n",
      "75%    0.725734\n",
      "max    0.726013\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.81175258, 0.86100729, 0.63706872, 0.61523495]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Results of k runs of the LOOCV, k=5\n",
    "# For LSTM\n",
    "\n",
    "skill_class = [[0.74140706,0.83758414,0.62350707,0.57813085],[0.81175258,0.86100729,0.62479065,0.60650221],[0.77143733,0.84981969,0.62583481,0.59273488], [0.80809392,0.8577807,0.62182461,0.61523495], [0.74634393,0.84721071,0.63706872,0.58768451]]\n",
    "skill = [0.7260131819408451, 0.6951572786506066, 0.7099566756796223, 0.7257335440216042, 0.7045769698537201]\n",
    "\n",
    "# For LSTM (binary)\n",
    "skill_bin =[0.8198511007283771, ]\n",
    "\n",
    "print(pd.DataFrame(skill).describe())\n",
    "np.max(skill_class, axis=0).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              0\n",
      "count  9.000000\n",
      "mean   0.819851\n",
      "std    0.167102\n",
      "min    0.429701\n",
      "25%    0.757293\n",
      "50%    0.892949\n",
      "75%    0.931914\n",
      "max    0.937856\n",
      "              0\n",
      "count  9.000000\n",
      "mean   0.784399\n",
      "std    0.241483\n",
      "min    0.177302\n",
      "25%    0.730041\n",
      "50%    0.877979\n",
      "75%    0.916444\n",
      "max    0.937963\n",
      "              0\n",
      "count  9.000000\n",
      "mean   0.855303\n",
      "std    0.105316\n",
      "min    0.682101\n",
      "25%    0.788421\n",
      "50%    0.907919\n",
      "75%    0.934487\n",
      "max    0.950211\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.837577"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bin_100_50_50_38 = [0.9378559964813934, 0.8929494149303193, 0.716604286538927, 0.7572929488990512, 0.42970100908642594, 0.9362251726215078, 0.8570826302751577, 0.9190347633690205, 0.9319136843535902]\n",
    "print(pd.DataFrame(bin_100_50_50_38).describe())\n",
    "bin_100_50_50_38_0 = [0.92750885, 0.87797937, 0.73004115, 0.72616509, 0.17730151, 0.93796332, 0.85257549, 0.91644426, 0.9136164]\n",
    "bin_100_50_50_38_1 = [0.94820314, 0.90791946, 0.70316742, 0.7884208, 0.68210051, 0.93448702, 0.86158977, 0.92162526, 0.95021097]\n",
    "\n",
    "print(pd.DataFrame(bin_100_50_50_38_0).describe())\n",
    "print(pd.DataFrame(bin_100_50_50_38_1).describe())\n",
    "np.mean([0.819851,0.855303])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tensorflow.python.keras.callbacks.History object at 0x7fc6fbb2a5f8>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7814623772990722"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "binary_30_60_45 = [0.9177016742040217, 0.9040154192097656, 0.8099751409515213, 0.4151093565067566, 0.3824148824148824, 0.9014, 0.9221951219512197, 0.8150633529572973, 0.9652864474961853]\n",
    "print(test_history[0])\n",
    "\n",
    "np.mean(binary)\n",
    "# np.std(binary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              0\n",
      "count  7.000000\n",
      "mean   0.765332\n",
      "std    0.180910\n",
      "min    0.429707\n",
      "25%    0.695580\n",
      "50%    0.790852\n",
      "75%    0.898252\n",
      "max    0.949098\n"
     ]
    }
   ],
   "source": [
    "binary_50_50_38 = [0.9260071960389603, 0.8811644738232993, 0.7219658876541559, 0.8860866064585742, 0.4255144719611421, 0.8883315924303563, 0.9308432932659894, 0.9153020813881809, 0.9637262183903024]\n",
    "np.mean(binary_50_50_38)\n",
    "np.std(binary_50_50_38)\n",
    "\n",
    "binary = [0.8966425740228005, 0.8998617109999707, 0.7415948599016959, 0.6495659808456997, 0.4297066474198839, 0.9490981636849097, 0.7908518950185617]\n",
    "print(pd.DataFrame(binary).describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              0\n",
      "count  9.000000\n",
      "mean   0.710472\n",
      "std    0.188854\n",
      "min    0.296613\n",
      "25%    0.644060\n",
      "50%    0.803332\n",
      "75%    0.851316\n",
      "max    0.875981\n"
     ]
    }
   ],
   "source": [
    "lstm = [0.8759806457906162, 0.8052480907534614, 0.5590059194182064, 0.8513156402148749, 0.2966129475409525, 0.8579945943480476, 0.6440595030767626, 0.8033322486954174, 0.7007016560011539]\n",
    "print(pd.DataFrame(lstm).describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['val_f1', 'loss', 'f1', 'val_loss'])\n"
     ]
    }
   ],
   "source": [
    "print(test_history[0].history.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['val_loss', 'loss', 'f1', 'val_f1'])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "h = k_history[0][8]\n",
    "# list all data in history\n",
    "print(h.history.keys())\n",
    "# summarize history for accuracy\n",
    "plt.plot(h.history['loss'])\n",
    "plt.plot(h.history['val_loss'])\n",
    "# plt.title()\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'])\n",
    "plt.savefig(\"z_loss_subj8.png\", bbox_inches = 'tight', pad_inches = 0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['val_loss', 'categorical_accuracy', 'loss', 'val_categorical_accuracy'])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "history0 = history[0]\n",
    "\n",
    "# list all data in history\n",
    "print(history[1].history.keys())\n",
    "# summarize history for accuracy\n",
    "plt.plot(history[8].history['categorical_accuracy'])\n",
    "plt.plot(history[8].history['val_categorical_accuracy'])\n",
    "# plt.title('model loss')\n",
    "plt.ylabel('categorical accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.savefig(\"acc_subj8.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get summary statistics of each train/test pairings\n",
    "## Correct way to do nested LOOCV\n",
    "# nested LOOCV with the all combis and hyperparameter tuning\n",
    "from sklearn.model_selection import LeaveOneGroupOut\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.metrics import f1_score\n",
    "from os import listdir\n",
    "from os import path\n",
    "import re\n",
    "import csv\n",
    "from keras import backend as K\n",
    "\n",
    "n_features, n_timesteps = 1, 2\n",
    "\n",
    "def evaluate_model(trainX, trainy, testX, testy, y_true, model):\n",
    "#     trainy, testy = trainy[:,0], testy[:,0]\n",
    "    print('YOOOO')\n",
    "\n",
    "    epochs, batch_size = 100, 32\n",
    "    # fit the model\n",
    "    history = model.fit(trainX, trainy, validation_data=(testX, testy), epochs = epochs, batch_size=batch_size)\n",
    "    print('FIT')\n",
    "    # make predictions\n",
    "    yhat = model.predict_classes(testX, batch_size=batch_size)\n",
    "\n",
    "\n",
    "    print('PREDICT')\n",
    "    f1_macro = f1_score(y_true, yhat, average='macro')\n",
    "    f1 = f1_score(y_true, yhat, average=None)\n",
    "#     _, accuracy = model.evaluate(testX, testy, verbose=verbose)\n",
    "    return f1, f1_macro, history\n",
    "\n",
    "def f1(y_true, y_pred):\n",
    "    def recall(y_true, y_pred):\n",
    "        \"\"\"Recall metric.\n",
    "\n",
    "        Only computes a batch-wise average of recall.\n",
    "\n",
    "        Computes the recall, a metric for multi-label classification of\n",
    "        how many relevant items are selected.\n",
    "        \"\"\"\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "        recall = true_positives / (possible_positives + K.epsilon())\n",
    "        return recall\n",
    "\n",
    "    def precision(y_true, y_pred):\n",
    "        \"\"\"Precision metric.\n",
    "\n",
    "        Only computes a batch-wise average of precision.\n",
    "\n",
    "        Computes the precision, a metric for multi-label classification of\n",
    "        how many selected items are relevant.\n",
    "        \"\"\"\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "        precision = true_positives / (predicted_positives + K.epsilon())\n",
    "        return precision\n",
    "    precision = precision(y_true, y_pred)\n",
    "    recall = recall(y_true, y_pred)\n",
    "    return 2*((precision*recall)/(precision+recall+K.epsilon()))\n",
    "\n",
    "def create_model():\n",
    "    clf = Sequential()\n",
    "    clf.add(LSTM(100, input_shape=(n_timesteps,n_features)))\n",
    "    clf.add(Dropout(0.5))\n",
    "    clf.add(Dense(100, activation='relu'))\n",
    "#     clf.add(Flatten())\n",
    "    clf.add(Dense(2, activation='softmax'))\n",
    "    clf.compile(loss='binary_crossentropy', optimizer='adam', metrics=[f1])\n",
    "\n",
    "    return clf\n",
    "\n",
    "def run_nested_logo(source, dest, key):    \n",
    "    global n_features\n",
    "    global n_timesteps\n",
    "    \n",
    "    logo = LeaveOneGroupOut()\n",
    "\n",
    "    i = 1\n",
    "    \n",
    "    done = ['30_15_4', '10_5_1', '5_3_2', '60_30_8', '60_90_0', '5_5_4', '30_45_23',\n",
    "        '5_5_0', '30_30_8', '60_90_68', '50_100_75', '30_30_15', '60_120_90',\n",
    "        '10_10_8', '10_20_0', '30_15_0', '60_30_23', '50_25_0', '50_25_6', '30_45_0',\n",
    "        '5_10_8', '30_15_11']\n",
    "    \n",
    "    hist_per_group = list()\n",
    "    \n",
    "    for name in listdir(source):\n",
    "        filename = source + '/' + name\n",
    "        if not name.endswith('csv') or not name.startswith('total_acc_x_train_'):\n",
    "            continue\n",
    "#         pattern = 'total_acc_x_train_' + '[0-9]*[0-9]_[0-9]*[0-9]_[0-9]*[0-9]' + '.csv'\n",
    "        pattern = 'total_acc_x_train_' + '50_50_38' + '.csv'\n",
    "        match = re.search(pattern, name)\n",
    "        if not match:\n",
    "            continue\n",
    "\n",
    "        combi = re.search('train_(.+?).csv', name)\n",
    "        print(combi)\n",
    "        if combi:\n",
    "            combi = combi.group(1)\n",
    "        print(combi)            \n",
    "            \n",
    "        print(i, 'out of 79 files')\n",
    "        print('Reading file', name)\n",
    "        \n",
    "        X_all, y_all, subjects = load_dataset(comb=combi, prefix=source)\n",
    "        for i in range(len(y_all)):\n",
    "            if y_all[i] == 2:\n",
    "                y_all[i] = 0\n",
    "            elif y_all[i] == 3:\n",
    "                y_all[i] = 1\n",
    "        # dummy dataset just for logo.split\n",
    "        X_dummy = np.arange(len(X_all))\n",
    "\n",
    "#         ind = subjects.index[subjects[0] != 'laura'].tolist()\n",
    "#         X_dummy = X_dummy[ind]\n",
    "#         groups = subjects[subjects[0] != 'laura'].iloc[:,0]\n",
    "#         print(len(groups))\n",
    "        groups = subjects.iloc[:,0]\n",
    "#         print(groups)\n",
    "        \n",
    "#         train_ind = subjects.index[subjects[0] == 'lenin'].tolist()\n",
    "#         train_ind.extend(subjects.index[subjects[0] == 'bojan'].tolist())\n",
    "#         train_ind.extend(subjects.index[subjects[0] == 'sue'].tolist())\n",
    "#         train_ind.extend(subjects.index[subjects[0] == 'jacob'].tolist())\n",
    "#         train_ind.extend(subjects.index[subjects[0] == 'dilhan'].tolist())\n",
    "#         train_ind.extend(subjects.index[subjects[0] == 'miguel'].tolist())\n",
    "#         train_ind.extend(subjects.index[subjects[0] == 'laura'].tolist())\n",
    "#         test_ind = subjects.index[subjects[0] == 'daniel'].tolist()\n",
    "#         test_ind.extend(subjects.index[subjects[0] == 'saeid'].tolist())\n",
    "#         test_ind.extend(subjects.index[subjects[0] == 'daniel'].tolist())\n",
    "#         test_ind.extend(subjects.index[subjects[0] == 'miguel'].tolist())\n",
    "        \n",
    "#         print(train_ind)\n",
    "#         print(test_ind)\n",
    "#         X_train, X_test = X_all[train_ind], X_all[test_ind]\n",
    "#         y_train, y_test = y_all[train_ind], y_all[test_ind]\n",
    "        \n",
    "#         y_train = to_categorical(y_train)\n",
    "#         y_true = y_test\n",
    "#         y_test = to_categorical(y_test)\n",
    "\n",
    "#         n_features = X_train.shape[2]\n",
    "#         n_timesteps = X_train.shape[1]\n",
    "        \n",
    "#         clf = create_model()\n",
    "        \n",
    "#         f1, f1_macro, test_history = evaluate_model(X_train, y_train, X_test, y_test, y_true, clf)\n",
    "\n",
    "#         hist_per_group.append(test_history)\n",
    "#         print('f1',f1)\n",
    "#         print('f1_macro', f1_macro)\n",
    "        \n",
    "#         results = run_logo(trainX, trainy, subjects.iloc[:,0], X_dummy)\n",
    "\n",
    "#         all_df = pd.read_csv(filename)\n",
    "\n",
    "#         X_all = all_df.drop(['state', 'name'], axis=1)\n",
    "#         y_all = pd.DataFrame(all_df['state'])\n",
    "#         groups = all_df['name']\n",
    "\n",
    "        # counting the number of samples per class\n",
    "#         freq = [0,0,0,0]\n",
    "#         for val in y_all['state']:\n",
    "#             freq[val] += 1\n",
    "\n",
    "#         print('class frequencies', freq)\n",
    "    \n",
    "        group = 0\n",
    "        \n",
    "        f1s = []\n",
    "        f1_macros = []\n",
    "        best_params = []\n",
    "        best_scores = []\n",
    "    \n",
    "        hist_per_group = list()\n",
    "        for train_index, test_index in logo.split(X_dummy, groups=groups):\n",
    "#             if group != 2:\n",
    "#                 group += 1\n",
    "#                 continue\n",
    "            X_train, X_test = X_all[train_index], X_all[test_index]\n",
    "            y_train, y_test = y_all[train_index], y_all[test_index]\n",
    "                \n",
    "            y_train = to_categorical(y_train)\n",
    "            y_true = y_test\n",
    "            y_test = to_categorical(y_test)\n",
    "            \n",
    "            n_features = X_train.shape[2]\n",
    "            n_timesteps = X_train.shape[1]\n",
    "            \n",
    "            print(n_features)\n",
    "            print(n_timesteps)\n",
    "#             print(n_outputs)\n",
    "            \n",
    "            clf = create_model()\n",
    "            \n",
    "            print('OKKKK')\n",
    "            f1, f1_macro, history = evaluate_model(X_train, y_train, X_test, y_test, y_true, clf)\n",
    "            print('Group', group)\n",
    "#             print(grid_obj.best_params_)\n",
    "            print(f1)\n",
    "            print('macro', f1_macro)\n",
    "#             print(grid_obj.best_score_)\n",
    "            f1s.append(f1)\n",
    "            f1_macros.append(f1_macro)\n",
    "#             best_params.append(grid_obj.best_params_)\n",
    "#             best_scores.append(grid_obj.best_score_)\n",
    "            \n",
    "            # Storing history object in list\n",
    "            hist_per_group.append(history)\n",
    "#             plt.plot(history.history['loss'])\n",
    "#             plt.plot(history.history['val_loss'])\n",
    "#             plt.title('model loss')\n",
    "#             plt.ylabel('loss')\n",
    "#             plt.xlabel('epoch')\n",
    "#             plt.legend(['train', 'test'], loc='upper left')\n",
    "#             plt.show()\n",
    "            \n",
    "            group += 1\n",
    "\n",
    "# #         header = ['comb']\n",
    "# #         row = [combi]\n",
    "        \n",
    "# #         # create header\n",
    "# #         for j in range(9):\n",
    "# #             header.append('f1-0'+'.'+str(j))\n",
    "# #             header.append('f1-1'+'.'+str(j))\n",
    "# #             header.append('f1-2'+'.'+str(j))\n",
    "# #             header.append('f1-3'+'.'+str(j))\n",
    "# #             header.append('macro'+'.'+str(j))\n",
    "# #             header.append('best_score_'+'.'+str())\n",
    "# #             header.append('hyper'+'.'+str(j))\n",
    "            \n",
    "# #             row.extend(f1s[j])\n",
    "# #             row.append(f1_macros[j])\n",
    "# #             row.append(best_scores[j])\n",
    "# #             row.append(best_params[j])\n",
    "\n",
    "# #         outFilename = dest + '/' + key + '.csv'\n",
    "# #         if not path.isfile(outFilename):\n",
    "# #             print('creating new file', outFilename)\n",
    "# #             with open(outFilename, 'w') as outFile:\n",
    "# #                 writer = csv.writer(outFile)\n",
    "# #                 writer.writerow(header)\n",
    "# #                 writer.writerow(row)\n",
    "# #                 outFile.close()\n",
    "# #         else:\n",
    "# #             print('opening existing file', outFilename)\n",
    "# #             with open(outFilename, 'a+') as outFile:\n",
    "# #                 writer = csv.writer(outFile)\n",
    "# #                 writer.writerow(row)\n",
    "# #                 outFile.close()\n",
    "#         i += 1\n",
    "        \n",
    "    print(np.average(f1_macros))\n",
    "    print(np.average(f1s, axis=0))\n",
    "    print(f1_macros)\n",
    "#     return np.average(f1s, axis=0).tolist(), [np.average(f1_macros).tolist()], [np.average(f1_micros).tolist()], best_params, best_scores\n",
    "    return hist_per_group\n",
    "\n",
    "source = '../data/processed/train/keras/done/'\n",
    "dest = 'results/'\n",
    "\n",
    "test_history = run_nested_logo(source, dest, 'lstm')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
