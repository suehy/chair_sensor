{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "\n",
    "from sklearn import datasets\n",
    "from sklearn.semi_supervised import label_propagation\n",
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1081 1707  927 ... 1653  559  684]\n",
      "[ 10  11  12  13  14  15  16  17  18  19  20  21  22  23  24  25  26  27\n",
      "  28  29  30  31  32  33  34  35  36  37  38  39  40  41  42  43  44  45\n",
      "  46  47  48  49  50  51  52  53  54  55  56  57  58  59  60  61  62  63\n",
      "  64  65  66  67  68  69  70  71  72  73  74  75  76  77  78  79  80  81\n",
      "  82  83  84  85  86  87  88  89  90  91  92  93  94  95  96  97  98  99\n",
      " 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117\n",
      " 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135\n",
      " 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153\n",
      " 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171\n",
      " 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189\n",
      " 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207\n",
      " 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225\n",
      " 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243\n",
      " 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261\n",
      " 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279\n",
      " 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297\n",
      " 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315\n",
      " 316 317 318 319 320 321 322 323 324 325 326 327 328 329]\n",
      "<class 'numpy.ndarray'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "digits = datasets.load_digits()\n",
    "rng = np.random.RandomState(0)\n",
    "indices = np.arange(len(digits.data))\n",
    "rng.shuffle(indices)\n",
    "\n",
    "print(indices)\n",
    "\n",
    "X = digits.data[indices[:330]]\n",
    "y = digits.target[indices[:330]]\n",
    "images = digits.images[indices[:330]]\n",
    "\n",
    "n_total_samples = len(y)\n",
    "n_labeled_points = 10\n",
    "max_iterations = 0\n",
    "\n",
    "unlabeled_indices = np.arange(n_total_samples)[n_labeled_points:]\n",
    "f = plt.figure()\n",
    "\n",
    "print(unlabeled_indices)\n",
    "print(type(digits.data))\n",
    "\n",
    "for i in range(max_iterations):\n",
    "    if len(unlabeled_indices) == 0:\n",
    "        print(\"No unlabeled items left to label.\")\n",
    "        break\n",
    "    y_train = np.copy(y)\n",
    "    y_train[unlabeled_indices] = -1\n",
    "\n",
    "    lp_model = label_propagation.LabelSpreading(gamma=0.25, max_iter=5)\n",
    "    lp_model.fit(X, y_train)\n",
    "\n",
    "    predicted_labels = lp_model.transduction_[unlabeled_indices]\n",
    "    true_labels = y[unlabeled_indices]\n",
    "\n",
    "    cm = confusion_matrix(true_labels, predicted_labels,\n",
    "                          labels=lp_model.classes_)\n",
    "\n",
    "    print(\"Iteration %i %s\" % (i, 70 * \"_\"))\n",
    "    print(\"Label Spreading model: %d labeled & %d unlabeled (%d total)\"\n",
    "          % (n_labeled_points, n_total_samples - n_labeled_points,\n",
    "             n_total_samples))\n",
    "\n",
    "    print(classification_report(true_labels, predicted_labels))\n",
    "\n",
    "    print(\"Confusion matrix\")\n",
    "    print(cm)\n",
    "\n",
    "    # compute the entropies of transduced label distributions\n",
    "    pred_entropies = stats.distributions.entropy(\n",
    "        lp_model.label_distributions_.T)\n",
    "\n",
    "    # select up to 5 digit examples that the classifier is most uncertain about\n",
    "    uncertainty_index = np.argsort(pred_entropies)[::-1]\n",
    "    uncertainty_index = uncertainty_index[\n",
    "        np.in1d(uncertainty_index, unlabeled_indices)][:5]\n",
    "    \n",
    "    # keep track of indices that we get labels for\n",
    "    delete_indices = np.array([])\n",
    "\n",
    "    # for more than 5 iterations, visualize the gain only on the first 5\n",
    "    if i < 5:\n",
    "        f.text(.05, (1 - (i + 1) * .183),\n",
    "               \"model %d\\n\\nfit with\\n%d labels\" %\n",
    "               ((i + 1), i * 5 + 10), size=10)\n",
    "    for index, image_index in enumerate(uncertainty_index):\n",
    "        image = images[image_index]\n",
    "\n",
    "        # for more than 5 iterations, visualize the gain only on the first 5\n",
    "        if i < 5:\n",
    "            sub = f.add_subplot(5, 5, index + 1 + (5 * i))\n",
    "            sub.imshow(image, cmap=plt.cm.gray_r, interpolation='none')\n",
    "            sub.set_title(\"predict: %i\\ntrue: %i\" % (\n",
    "                lp_model.transduction_[image_index], y[image_index]), size=10)\n",
    "            sub.axis('off')\n",
    "\n",
    "        # labeling 5 points, remote from labeled set\n",
    "        delete_index, = np.where(unlabeled_indices == image_index)\n",
    "        delete_indices = np.concatenate((delete_indices, delete_index))\n",
    "\n",
    "    unlabeled_indices = np.delete(unlabeled_indices, delete_indices)\n",
    "    n_labeled_points += len(uncertainty_index)\n",
    "\n",
    "f.suptitle(\"Active learning with Label Propagation.\\nRows show 5 most \"\n",
    "           \"uncertain labels to learn with the next model.\", y=1.15)\n",
    "plt.subplots_adjust(left=0.2, bottom=0.03, right=0.9, top=0.9, wspace=0.2,\n",
    "                    hspace=0.85)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5000 5001 5002 ... 9997 9998 9999]\n",
      "10983\n",
      "Iteration 0 ______________________________________________________________________\n",
      "Label Spreading model: 5000 labeled & 5000 unlabeled (10000 total)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00      1929\n",
      "           1       0.46      1.00      0.63      2288\n",
      "           2       0.00      0.00      0.00       380\n",
      "           3       0.00      0.00      0.00       403\n",
      "\n",
      "   micro avg       0.46      0.46      0.46      5000\n",
      "   macro avg       0.11      0.25      0.16      5000\n",
      "weighted avg       0.21      0.46      0.29      5000\n",
      "\n",
      "Confusion matrix\n",
      "[[   0 1929    0    0]\n",
      " [   0 2288    0    0]\n",
      " [   0  380    0    0]\n",
      " [   0  403    0    0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/elizabeth/education/chair_sensor/ml_project/venv/lib/python3.5/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/elizabeth/education/chair_sensor/ml_project/venv/lib/python3.5/site-packages/ipykernel_launcher.py:79: DeprecationWarning: using a non-integer array as obj in delete will result in an error in the future\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1 ______________________________________________________________________\n",
      "Label Spreading model: 6000 labeled & 4000 unlabeled (10000 total)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00      1663\n",
      "           1       0.44      1.00      0.61      1774\n",
      "           2       0.00      0.00      0.00       253\n",
      "           3       0.00      0.00      0.00       310\n",
      "\n",
      "   micro avg       0.44      0.44      0.44      4000\n",
      "   macro avg       0.11      0.25      0.15      4000\n",
      "weighted avg       0.20      0.44      0.27      4000\n",
      "\n",
      "Confusion matrix\n",
      "[[   0 1663    0    0]\n",
      " [   0 1774    0    0]\n",
      " [   0  253    0    0]\n",
      " [   0  310    0    0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/elizabeth/education/chair_sensor/ml_project/venv/lib/python3.5/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/elizabeth/education/chair_sensor/ml_project/venv/lib/python3.5/site-packages/ipykernel_launcher.py:79: DeprecationWarning: using a non-integer array as obj in delete will result in an error in the future\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 2 ______________________________________________________________________\n",
      "Label Spreading model: 7000 labeled & 3000 unlabeled (10000 total)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00      1647\n",
      "           1       0.32      1.00      0.49       967\n",
      "           2       0.00      0.00      0.00       141\n",
      "           3       0.00      0.00      0.00       245\n",
      "\n",
      "   micro avg       0.32      0.32      0.32      3000\n",
      "   macro avg       0.08      0.25      0.12      3000\n",
      "weighted avg       0.10      0.32      0.16      3000\n",
      "\n",
      "Confusion matrix\n",
      "[[   0 1647    0    0]\n",
      " [   0  967    0    0]\n",
      " [   0  141    0    0]\n",
      " [   0  245    0    0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/elizabeth/education/chair_sensor/ml_project/venv/lib/python3.5/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/elizabeth/education/chair_sensor/ml_project/venv/lib/python3.5/site-packages/ipykernel_launcher.py:79: DeprecationWarning: using a non-integer array as obj in delete will result in an error in the future\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 3 ______________________________________________________________________\n",
      "Label Spreading model: 8000 labeled & 2000 unlabeled (10000 total)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00      1155\n",
      "           1       0.30      1.00      0.47       606\n",
      "           2       0.00      0.00      0.00        79\n",
      "           3       0.00      0.00      0.00       160\n",
      "\n",
      "   micro avg       0.30      0.30      0.30      2000\n",
      "   macro avg       0.08      0.25      0.12      2000\n",
      "weighted avg       0.09      0.30      0.14      2000\n",
      "\n",
      "Confusion matrix\n",
      "[[   0 1155    0    0]\n",
      " [   0  606    0    0]\n",
      " [   0   79    0    0]\n",
      " [   0  160    0    0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/elizabeth/education/chair_sensor/ml_project/venv/lib/python3.5/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/elizabeth/education/chair_sensor/ml_project/venv/lib/python3.5/site-packages/ipykernel_launcher.py:79: DeprecationWarning: using a non-integer array as obj in delete will result in an error in the future\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 4 ______________________________________________________________________\n",
      "Label Spreading model: 9000 labeled & 1000 unlabeled (10000 total)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       575\n",
      "           1       0.27      1.00      0.43       274\n",
      "           2       0.00      0.00      0.00        55\n",
      "           3       0.00      0.00      0.00        96\n",
      "\n",
      "   micro avg       0.27      0.27      0.27      1000\n",
      "   macro avg       0.07      0.25      0.11      1000\n",
      "weighted avg       0.08      0.27      0.12      1000\n",
      "\n",
      "Confusion matrix\n",
      "[[  0 575   0   0]\n",
      " [  0 274   0   0]\n",
      " [  0  55   0   0]\n",
      " [  0  96   0   0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/elizabeth/education/chair_sensor/ml_project/venv/lib/python3.5/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/elizabeth/education/chair_sensor/ml_project/venv/lib/python3.5/site-packages/ipykernel_launcher.py:79: DeprecationWarning: using a non-integer array as obj in delete will result in an error in the future\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import LeaveOneGroupOut\n",
    "from pandas import DataFrame\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "train_df = pd.read_csv('../data/processed/train.csv')\n",
    "test_df = pd.read_csv('../data/processed/test.csv')\n",
    "\n",
    "X_train = train_df.drop(['state', 'name'], axis=1)\n",
    "y_train = train_df['state']\n",
    "X_test = test_df.drop(['state', 'name'], axis=1)\n",
    "y_test = test_df['state']\n",
    "\n",
    "X_all = X_train.append(X_test).values\n",
    "y_all = y_train.append(y_test).values\n",
    "\n",
    "groups = train_df.append(test_df)['name']\n",
    "\n",
    "rng = np.random.RandomState(0)\n",
    "indices = np.arange(len(X_all))\n",
    "rng.shuffle(indices)\n",
    "\n",
    "X = X_all[indices[:10000]]\n",
    "y = y_all[indices[:10000]]\n",
    "\n",
    "n_total_samples = len(y)\n",
    "n_labeled_points = 5000\n",
    "max_iterations = 5\n",
    "\n",
    "unlabeled_indices = np.arange(n_total_samples)[n_labeled_points:]\n",
    "\n",
    "print(unlabeled_indices)\n",
    "print(len(y_all))\n",
    "\n",
    "for i in range(max_iterations):\n",
    "    if len(unlabeled_indices) == 0:\n",
    "        print(\"No unlabeled items left to label.\")\n",
    "        break\n",
    "    y_train = np.copy(y)\n",
    "    y_train[unlabeled_indices] = -1\n",
    "\n",
    "    lp_model = label_propagation.LabelPropagation(gamma=0.25, max_iter=10)\n",
    "    lp_model.fit(X, y_train)\n",
    "\n",
    "    predicted_labels = lp_model.transduction_[unlabeled_indices]\n",
    "    true_labels = y[unlabeled_indices]\n",
    "\n",
    "    cm = confusion_matrix(true_labels, predicted_labels,\n",
    "                          labels=lp_model.classes_)\n",
    "\n",
    "    print(\"Iteration %i %s\" % (i, 70 * \"_\"))\n",
    "    print(\"Label Spreading model: %d labeled & %d unlabeled (%d total)\"\n",
    "          % (n_labeled_points, n_total_samples - n_labeled_points,\n",
    "             n_total_samples))\n",
    "\n",
    "    print(classification_report(true_labels, predicted_labels))\n",
    "\n",
    "    print(\"Confusion matrix\")\n",
    "    print(cm)\n",
    "\n",
    "    # compute the entropies of transduced label distributions\n",
    "    pred_entropies = stats.distributions.entropy(\n",
    "        lp_model.label_distributions_.T)\n",
    "\n",
    "    # select up to 5 digit examples that the classifier is most uncertain about\n",
    "    uncertainty_index = np.argsort(pred_entropies)[::-1]\n",
    "    uncertainty_index = uncertainty_index[\n",
    "        np.in1d(uncertainty_index, unlabeled_indices)][:1000]\n",
    "    \n",
    "    # keep track of indices that we get labels for\n",
    "    delete_indices = np.array([])\n",
    "\n",
    "    for index, image_index in enumerate(uncertainty_index):\n",
    "        # labeling 5 points, remote from labeled set\n",
    "        delete_index, = np.where(unlabeled_indices == image_index)\n",
    "        delete_indices = np.concatenate((delete_indices, delete_index))\n",
    "        y[image_index] = lp_model.transduction_[image_index]\n",
    "\n",
    "    unlabeled_indices = np.delete(unlabeled_indices, delete_indices)\n",
    "    n_labeled_points += len(uncertainty_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
