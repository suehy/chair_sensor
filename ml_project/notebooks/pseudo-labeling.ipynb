{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import LeaveOneGroupOut\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import balanced_accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('../data/processed/train.csv')\n",
    "test_df = pd.read_csv('../data/processed/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(21418, 150)\n",
      "(21418,)\n",
      "21418\n",
      "6093\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.94      0.93      2566\n",
      "           1       0.89      0.93      0.91      2661\n",
      "           2       0.74      0.62      0.67       395\n",
      "           3       0.82      0.52      0.64       411\n",
      "\n",
      "   micro avg       0.89      0.89      0.89      6033\n",
      "   macro avg       0.84      0.75      0.79      6033\n",
      "weighted avg       0.88      0.89      0.88      6033\n",
      "\n",
      "[[2414   93   17   42]\n",
      " [ 137 2487   33    4]\n",
      " [  75   77  243    0]\n",
      " [  20  141   37  213]]\n",
      "Group 0 accuracy: 0.7522032329601237\n",
      "      cat  label  probs\n",
      "8921    0      0    1.0\n",
      "4563    0      0    1.0\n",
      "4588    0      0    1.0\n",
      "4587    0      0    1.0\n",
      "4586    0      0    1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.93      0.92      2566\n",
      "           1       0.88      0.93      0.91      2661\n",
      "           2       0.70      0.59      0.64       395\n",
      "           3       0.81      0.51      0.63       411\n",
      "\n",
      "   micro avg       0.88      0.88      0.88      6033\n",
      "   macro avg       0.82      0.74      0.77      6033\n",
      "weighted avg       0.88      0.88      0.88      6033\n",
      "\n",
      "[[2395  115   13   43]\n",
      " [ 137 2481   38    5]\n",
      " [  73   87  233    2]\n",
      " [  16  135   50  210]]\n",
      "Group 0 accuracy: 0.7416344734961979\n",
      "10010\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.91      0.91      2566\n",
      "           1       0.87      0.93      0.90      2661\n",
      "           2       0.71      0.63      0.67       395\n",
      "           3       0.81      0.56      0.66       411\n",
      "\n",
      "   micro avg       0.88      0.88      0.88      6033\n",
      "   macro avg       0.83      0.76      0.79      6033\n",
      "weighted avg       0.88      0.88      0.88      6033\n",
      "\n",
      "[[2336  148   34   48]\n",
      " [ 133 2487   37    4]\n",
      " [  61   84  250    0]\n",
      " [  16  136   30  229]]\n",
      "Group 1 accuracy: 0.7587665963428643\n",
      "       cat  label  probs\n",
      "11407    0      1    1.0\n",
      "8862     0      0    1.0\n",
      "8894     0      0    1.0\n",
      "8895     0      0    1.0\n",
      "4457     0      0    1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.92      0.92      2566\n",
      "           1       0.88      0.94      0.91      2661\n",
      "           2       0.71      0.65      0.68       395\n",
      "           3       0.81      0.54      0.65       411\n",
      "\n",
      "   micro avg       0.88      0.88      0.88      6033\n",
      "   macro avg       0.83      0.76      0.79      6033\n",
      "weighted avg       0.88      0.88      0.88      6033\n",
      "\n",
      "[[2356  127   36   47]\n",
      " [ 127 2494   36    4]\n",
      " [  56   83  256    0]\n",
      " [  18  135   35  223]]\n",
      "Group 1 accuracy: 0.7615206352287682\n",
      "12790\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.91      0.92      2566\n",
      "           1       0.87      0.94      0.90      2661\n",
      "           2       0.68      0.70      0.69       395\n",
      "           3       0.84      0.48      0.61       411\n",
      "\n",
      "   micro avg       0.88      0.88      0.88      6033\n",
      "   macro avg       0.83      0.76      0.78      6033\n",
      "weighted avg       0.88      0.88      0.88      6033\n",
      "\n",
      "[[2341  151   39   35]\n",
      " [ 119 2496   44    2]\n",
      " [  45   74  275    1]\n",
      " [  16  149   47  199]]\n",
      "Group 2 accuracy: 0.7576738922741889\n",
      "      cat  label  probs\n",
      "1920    0      1    1.0\n",
      "5894    0      1    1.0\n",
      "1132    0      1    1.0\n",
      "1131    0      1    1.0\n",
      "1130    0      1    1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.90      0.91      2566\n",
      "           1       0.86      0.93      0.89      2661\n",
      "           2       0.66      0.71      0.68       395\n",
      "           3       0.83      0.44      0.58       411\n",
      "\n",
      "   micro avg       0.87      0.87      0.87      6033\n",
      "   macro avg       0.82      0.75      0.77      6033\n",
      "weighted avg       0.87      0.87      0.87      6033\n",
      "\n",
      "[[2306  179   47   34]\n",
      " [ 129 2487   43    2]\n",
      " [  45   69  280    1]\n",
      " [  11  163   55  182]]\n",
      "Group 2 accuracy: 0.7462422932285825\n",
      "17308\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.89      0.91      2566\n",
      "           1       0.86      0.93      0.89      2661\n",
      "           2       0.62      0.72      0.67       395\n",
      "           3       0.85      0.48      0.61       411\n",
      "\n",
      "   micro avg       0.87      0.87      0.87      6033\n",
      "   macro avg       0.82      0.75      0.77      6033\n",
      "weighted avg       0.87      0.87      0.87      6033\n",
      "\n",
      "[[2284  193   59   30]\n",
      " [ 123 2480   55    3]\n",
      " [  39   71  284    1]\n",
      " [  12  145   58  196]]\n",
      "Group 3 accuracy: 0.7544886925086879\n",
      "      cat  label  probs\n",
      "2478    0      1    1.0\n",
      "739     0      1    1.0\n",
      "1366    0      1    1.0\n",
      "1365    0      1    1.0\n",
      "1364    0      1    1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.89      0.91      2566\n",
      "           1       0.86      0.93      0.89      2661\n",
      "           2       0.61      0.70      0.65       395\n",
      "           3       0.82      0.45      0.58       411\n",
      "\n",
      "   micro avg       0.86      0.86      0.86      6033\n",
      "   macro avg       0.80      0.74      0.76      6033\n",
      "weighted avg       0.87      0.86      0.86      6033\n",
      "\n",
      "[[2276  200   55   35]\n",
      " [ 128 2480   49    4]\n",
      " [  42   76  276    1]\n",
      " [   9  140   76  186]]\n",
      "Group 3 accuracy: 0.742563253081808\n",
      "20297\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.90      0.91      2566\n",
      "           1       0.86      0.93      0.90      2661\n",
      "           2       0.64      0.69      0.66       395\n",
      "           3       0.78      0.46      0.58       411\n",
      "\n",
      "   micro avg       0.87      0.87      0.87      6033\n",
      "   macro avg       0.80      0.74      0.76      6033\n",
      "weighted avg       0.87      0.87      0.87      6033\n",
      "\n",
      "[[2311  160   50   45]\n",
      " [ 129 2478   49    5]\n",
      " [  40   82  271    2]\n",
      " [  10  156   56  189]]\n",
      "Group 4 accuracy: 0.7444455909693514\n",
      "     cat  label     probs\n",
      "356    0      1  0.980000\n",
      "18     0      1  0.980000\n",
      "336    0      1  0.979167\n",
      "304    0      1  0.971667\n",
      "718    0      1  0.970000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.89      0.91      2566\n",
      "           1       0.85      0.93      0.89      2661\n",
      "           2       0.63      0.68      0.66       395\n",
      "           3       0.84      0.48      0.62       411\n",
      "\n",
      "   micro avg       0.87      0.87      0.87      6033\n",
      "   macro avg       0.81      0.75      0.77      6033\n",
      "weighted avg       0.87      0.87      0.86      6033\n",
      "\n",
      "[[2280  200   52   34]\n",
      " [ 120 2488   51    2]\n",
      " [  42   82  270    1]\n",
      " [  10  149   53  199]]\n",
      "Group 4 accuracy: 0.7478146360637901\n",
      "21418\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.93      0.93      2566\n",
      "           1       0.88      0.94      0.91      2661\n",
      "           2       0.69      0.69      0.69       395\n",
      "           3       0.80      0.46      0.58       411\n",
      "\n",
      "   micro avg       0.88      0.88      0.88      6033\n",
      "   macro avg       0.82      0.75      0.78      6033\n",
      "weighted avg       0.88      0.88      0.88      6033\n",
      "\n",
      "[[2381  105   35   45]\n",
      " [ 114 2495   50    2]\n",
      " [  56   68  271    0]\n",
      " [  10  175   37  189]]\n",
      "Group 5 accuracy: 0.7528626881348108\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "arrays used as indices must be of integer (or boolean) type",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-417615039826>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    111\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Mean Accuracy: {0}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmean_outcome\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m \u001b[0mrun_pseudo_labeling\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-23-417615039826>\u001b[0m in \u001b[0;36mrun_pseudo_labeling\u001b[0;34m(clf)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;31m#        predictions = clf.predict(X_train.values[unlabeled_index])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m         \u001b[0;31m# Predict and add unlabeled data with highest probability to training set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m         \u001b[0mpred_probs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0munlabeled_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m         \u001b[0mpred_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0me\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpred_probs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m         \u001b[0mmax_pred_probs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0me\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpred_probs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: arrays used as indices must be of integer (or boolean) type"
     ]
    }
   ],
   "source": [
    "#LOOCV increasing the labeled training set with separate test set\n",
    "X_train = train_df.drop(['state', 'name'], axis=1)\n",
    "y_train = train_df['state']\n",
    "X_test = test_df.drop(['state', 'name'], axis=1)\n",
    "y_test = test_df['state']\n",
    "\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "\n",
    "# X_all = X_train.append(X_test)\n",
    "# y_all = y_train.append(y_test)\n",
    "\n",
    "groups = train_df['name']\n",
    "\n",
    "outcomes = []\n",
    "\n",
    "clf = RandomForestClassifier(criterion='gini',\n",
    "                             max_features=None,\n",
    "                             min_samples_split=5,\n",
    "                             n_estimators=100)\n",
    "\n",
    "print(len(groups))\n",
    "def run_pseudo_labeling(clf):\n",
    "    logo = LeaveOneGroupOut()\n",
    "    group = 0\n",
    "    \n",
    "    labeled_index = np.empty(0, int)\n",
    "    unlabeled_index = np.empty(0, int)\n",
    "    \n",
    "    percentage = 0.1\n",
    "    \n",
    "    for train_index, test_index in logo.split(X_train, groups=groups):\n",
    "        labeled_index = np.append(labeled_index, test_index)\n",
    "        unlabeled_index = np.array(list(set(X_train.index.values).symmetric_difference(labeled_index)))\n",
    "        \n",
    "        X_labeled = X_train.values[labeled_index]\n",
    "        y_labeled = y_train.values[labeled_index]\n",
    "        \n",
    "        print(len(X_labeled))\n",
    "\n",
    "        clf.fit(X_labeled, y_labeled)\n",
    "        predictions = clf.predict(X_test)\n",
    "        \n",
    "        print(classification_report(y_test, predictions))\n",
    "        print(confusion_matrix(y_test, predictions))\n",
    "        \n",
    "        accuracy = balanced_accuracy_score(y_test, predictions)\n",
    "#         outcomes.append(accuracy)\n",
    "        print(\"Group {0} accuracy: {1}\".format(group, accuracy))\n",
    "    \n",
    "        # Predict and add unlabeled samples to training set\n",
    "#        predictions = clf.predict(X_train.values[unlabeled_index])\n",
    "        # Predict and add unlabeled data with highest probability to training set\n",
    "        pred_probs = clf.predict_proba(X_train.values[unlabeled_index])\n",
    "        pred_labels = [np.argmax(e) for e in pred_probs]\n",
    "        max_pred_probs = [np.max(e) for e in pred_probs]\n",
    "        \n",
    "#         preds = clf.predict(X_train.values[unlabeled_index])\n",
    "#         print('actual labels')\n",
    "#         sum = 0\n",
    "#         for i in range(len(preds)):\n",
    "#             if preds[i] > 1:\n",
    "#                 print(preds[i])\n",
    "#                 sum += 1\n",
    "#         print(sum)\n",
    "#         for i in range(len(y_train.values[unlabeled_index])):\n",
    "#             print(y_train.values[unlabeled_index][i])\n",
    "#         print('predicted labels')\n",
    "#         sum = 0\n",
    "#         for i in range(len(pred_labels)):\n",
    "#             if pred_labels[i] > 1:\n",
    "#                 print(pred_labels[i])\n",
    "#                 sum += 1\n",
    "#         print(sum)\n",
    "        cat_pred_probs = [0 if e <= 1 else 10 for e in pred_labels]\n",
    "        data_df = { 'probs': max_pred_probs, 'cat': cat_pred_probs, 'label': pred_labels }\n",
    "        max_pred_probs_df = pd.DataFrame(data=data_df)\n",
    "#        max_pred_probs_df = max_pred_probs_df.sort_values(by=['cat', 'probs'], ascending=False)\n",
    "        max_pred_probs_df = max_pred_probs_df.sort_values(by=['probs'], ascending=False)\n",
    "        print(max_pred_probs_df.head())\n",
    "        \n",
    "        pseudo_size = int(percentage * len(unlabeled_index))\n",
    "        max_indices = max_pred_probs_df.index.values[:pseudo_size]\n",
    "        \n",
    "        X_pseudo = np.array(X_train.values[unlabeled_index])[max_indices]\n",
    "        y_pseudo = np.array([np.argmax(e) for e in pred_probs])[max_indices]\n",
    "        \n",
    "        X_aug = X_labeled.copy()\n",
    "        X_aug = np.append(X_aug, X_pseudo, axis=0)\n",
    "        y_aug = y_labeled.copy()\n",
    "        y_aug = np.append(y_aug, y_pseudo)\n",
    "        \n",
    "        clf.fit(X_aug, y_aug)\n",
    "        predictions = clf.predict(X_test)\n",
    "        \n",
    "#        y_augmented = y_train.copy(deep=True)\n",
    "#        y_augmented.values[unlabeled_index] = predictions\n",
    "        \n",
    "#        clf.fit(X_train, y_augmented)\n",
    "#        predictions = clf.predict(X_test)\n",
    "        \n",
    "        print(classification_report(y_test, predictions))\n",
    "        print(confusion_matrix(y_test, predictions))\n",
    "        \n",
    "        accuracy = balanced_accuracy_score(y_test, predictions)\n",
    "#         outcomes.append(accuracy)\n",
    "        print(\"Group {0} accuracy: {1}\".format(group, accuracy))\n",
    "    \n",
    "        group += 1\n",
    "#     mean_outcome = np.mean(outcomes)\n",
    "    print(\"Mean Accuracy: {0}\".format(mean_outcome)) \n",
    "\n",
    "run_pseudo_labeling(clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'max_indices' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-b5ca199ff489>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_indices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'max_indices' is not defined"
     ]
    }
   ],
   "source": [
    "print(max_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/elizabeth/education/chair_sensor/ml_project/venv/lib/python3.5/site-packages/ipykernel_launcher.py:43: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.07890476 0.66990476 0.14735714 0.10383333]\n",
      " [0.06       0.65457143 0.1962619  0.08916667]\n",
      " [0.06533333 0.76040476 0.11309524 0.06116667]\n",
      " ...\n",
      " [0.         1.         0.         0.        ]\n",
      " [0.         1.         0.         0.        ]\n",
      " [0.         1.         0.         0.        ]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.75      0.85      2566\n",
      "           1       0.75      0.98      0.85      2661\n",
      "           2       0.58      0.62      0.60       395\n",
      "           3       0.79      0.31      0.45       411\n",
      "\n",
      "   micro avg       0.81      0.81      0.81      6033\n",
      "   macro avg       0.77      0.66      0.69      6033\n",
      "weighted avg       0.84      0.81      0.81      6033\n",
      "\n",
      "[[1922  554   58   32]\n",
      " [   1 2610   50    0]\n",
      " [  22  127  243    3]\n",
      " [   3  209   70  129]]\n",
      "Group 0 accuracy: 0.6647296200881639\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/elizabeth/education/chair_sensor/ml_project/venv/lib/python3.5/site-packages/ipykernel_launcher.py:55: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.07890476 0.66990476 0.14735714 0.10383333]\n",
      " [0.06       0.65457143 0.1962619  0.08916667]\n",
      " [0.06533333 0.76040476 0.11309524 0.06116667]\n",
      " ...\n",
      " [0.         1.         0.         0.        ]\n",
      " [0.         1.         0.         0.        ]\n",
      " [0.         1.         0.         0.        ]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.70      0.82      2566\n",
      "           1       0.72      0.98      0.83      2661\n",
      "           2       0.57      0.64      0.60       395\n",
      "           3       0.80      0.30      0.44       411\n",
      "\n",
      "   micro avg       0.79      0.79      0.79      6033\n",
      "   macro avg       0.77      0.66      0.67      6033\n",
      "weighted avg       0.83      0.79      0.79      6033\n",
      "\n",
      "[[1806  663   69   28]\n",
      " [   1 2607   51    2]\n",
      " [  13  128  253    1]\n",
      " [   2  217   69  123]]\n",
      "Group 0 accuracy: 0.6558256132579678\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/elizabeth/education/chair_sensor/ml_project/venv/lib/python3.5/site-packages/ipykernel_launcher.py:43: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-8b5d9ad6450c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Mean Accuracy: {0}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmean_outcome\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m \u001b[0mrun_pseudo_labeling\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-9-8b5d9ad6450c>\u001b[0m in \u001b[0;36mrun_pseudo_labeling\u001b[0;34m()\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0;31m# Train the model and use it to predict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m         \u001b[0my_hat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-7-14880eaaa284>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m     41\u001b[0m             )\n\u001b[1;32m     42\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/education/chair_sensor/ml_project/venv/lib/python3.5/site-packages/sklearn/ensemble/forest.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    331\u001b[0m                     \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrees\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    332\u001b[0m                     verbose=self.verbose, class_weight=self.class_weight)\n\u001b[0;32m--> 333\u001b[0;31m                 for i, t in enumerate(trees))\n\u001b[0m\u001b[1;32m    334\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    335\u001b[0m             \u001b[0;31m# Collect newly grown trees\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/education/chair_sensor/ml_project/venv/lib/python3.5/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    918\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    919\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 920\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    921\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    922\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/education/chair_sensor/ml_project/venv/lib/python3.5/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    757\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    758\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 759\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    760\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    761\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/education/chair_sensor/ml_project/venv/lib/python3.5/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    714\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    715\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 716\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    717\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    718\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/education/chair_sensor/ml_project/venv/lib/python3.5/site-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    180\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 182\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    183\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/education/chair_sensor/ml_project/venv/lib/python3.5/site-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    547\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    548\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 549\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    550\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    551\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/education/chair_sensor/ml_project/venv/lib/python3.5/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    223\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 225\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    226\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/education/chair_sensor/ml_project/venv/lib/python3.5/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    223\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 225\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    226\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/education/chair_sensor/ml_project/venv/lib/python3.5/site-packages/sklearn/ensemble/forest.py\u001b[0m in \u001b[0;36m_parallel_build_trees\u001b[0;34m(tree, forest, X, y, sample_weight, tree_idx, n_trees, verbose, class_weight)\u001b[0m\n\u001b[1;32m    117\u001b[0m             \u001b[0mcurr_sample_weight\u001b[0m \u001b[0;34m*=\u001b[0m \u001b[0mcompute_sample_weight\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'balanced'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m         \u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcurr_sample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m         \u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/education/chair_sensor/ml_project/venv/lib/python3.5/site-packages/sklearn/tree/tree.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    799\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    800\u001b[0m             \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcheck_input\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 801\u001b[0;31m             X_idx_sorted=X_idx_sorted)\n\u001b[0m\u001b[1;32m    802\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    803\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/education/chair_sensor/ml_project/venv/lib/python3.5/site-packages/sklearn/tree/tree.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    364\u001b[0m                                            min_impurity_split)\n\u001b[1;32m    365\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 366\u001b[0;31m         \u001b[0mbuilder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_idx_sorted\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    367\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    368\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#LOOCV pseudo-labeling with a separate test set\n",
    "#sample_rate relative to validate set\n",
    "from sklearn.model_selection import LeaveOneGroupOut\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "\n",
    "train_df = pd.read_csv('../data/processed/train.csv')\n",
    "test_df = pd.read_csv('../data/processed/test.csv')\n",
    "\n",
    "X_train = train_df.drop(['state', 'name'], axis=1)\n",
    "y_train = pd.DataFrame(train_df['state'])\n",
    "\n",
    "X_test = test_df.drop(['state', 'name'], axis=1)\n",
    "y_test = pd.DataFrame(test_df['state'])\n",
    "\n",
    "groups = train_df['name']\n",
    "\n",
    "outcomes = []\n",
    "\n",
    "def run_pseudo_labeling():\n",
    "    logo = LeaveOneGroupOut()\n",
    "    group = 0\n",
    "    \n",
    "    for train_index, test_index in logo.split(X_train, groups=groups): \n",
    "\n",
    "        X = pd.DataFrame(data=X_train.values[train_index])\n",
    "        y = pd.DataFrame(data=y_train.values[train_index], columns=['state'])\n",
    "\n",
    "        model = PseudoLabeler(\n",
    "            RandomForestClassifier(criterion='gini',\n",
    "                                   max_features=None,\n",
    "                                   min_samples_split=5,\n",
    "                                   n_estimators=100),\n",
    "        #    GradientBoostingClassifier(n_estimators=100),\n",
    "            pd.DataFrame(X_train.values[test_index]),\n",
    "            'state',\n",
    "            sample_rate=0.0\n",
    "        )\n",
    "        \n",
    "        # Train the model and use it to predict\n",
    "        model.fit(X, y)\n",
    "        y_hat = model.predict(X_test)\n",
    "        \n",
    "        y_prob = model.predict_proba(X_test)\n",
    "        print(y_prob)\n",
    "        print(classification_report(y_test, y_hat))\n",
    "        print(confusion_matrix(y_test, y_hat))        \n",
    "        accuracy = balanced_accuracy_score(y_test, y_hat)\n",
    "        print(\"Group {0} accuracy: {1}\".format(group, accuracy))\n",
    "        \n",
    "        model.set_params(sample_rate=0.3)\n",
    "        model.fit(X, y)\n",
    "        y_hat = model.predict(X_test)\n",
    "        print(y_prob)\n",
    "        \n",
    "        print(classification_report(y_test, y_hat))\n",
    "        print(confusion_matrix(y_test, y_hat))        \n",
    "        accuracy = balanced_accuracy_score(y_test, y_hat)\n",
    "        outcomes.append(accuracy)\n",
    "        print(\"Group {0} accuracy: {1}\".format(group, accuracy))\n",
    "    \n",
    "        group += 1\n",
    "    mean_outcome = np.mean(outcomes)\n",
    "    print(\"Mean Accuracy: {0}\".format(mean_outcome)) \n",
    "\n",
    "run_pseudo_labeling()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.base import BaseEstimator, RegressorMixin\n",
    "import pandas as pd\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "\n",
    "class PseudoLabeler(BaseEstimator, RegressorMixin):\n",
    "    \n",
    "    def __init__(self, model, test, target, sample_rate=0.2, seed=42):\n",
    "        self.sample_rate = sample_rate\n",
    "        self.seed = seed\n",
    "        self.model = model\n",
    "        self.model.seed = seed\n",
    "        \n",
    "        self.test = test\n",
    "        self.target = target\n",
    "        \n",
    "    def get_params(self, deep=True):\n",
    "        return {\n",
    "            \"sample_rate\": self.sample_rate,\n",
    "            \"seed\": self.seed,\n",
    "            \"model\": self.model,\n",
    "            \"test\": self.test,\n",
    "            \"target\": self.target\n",
    "        }\n",
    "    \n",
    "    def set_params(self, **parameters):\n",
    "        for parameter, value in parameters.items():\n",
    "            setattr(self, parameter, value)\n",
    "        return self\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        if self.sample_rate > 0.0:\n",
    "            augmented_X_train, augmented_y_train = self.__create_augmented_train(X, y)\n",
    "            self.model.fit(\n",
    "                augmented_X_train,\n",
    "                augmented_y_train\n",
    "            )\n",
    "        else:\n",
    "            self.model.fit(X, y)\n",
    "            \n",
    "        return self\n",
    "    \n",
    "    def __create_augmented_train(self, X, y):\n",
    "        '''\n",
    "        Create and return the augmented_train set that consists\n",
    "        of pseudo-labeled and labeled data.\n",
    "        '''\n",
    "        num_of_samples = int(len(self.test) * self.sample_rate)\n",
    "        \n",
    "        # Train the model and create the pseudo-labels\n",
    "        self.model.fit(X, y)\n",
    "        pseudo_labels = self.model.predict(self.test)\n",
    "        \n",
    "        # Add the pseudo-labels to the test set\n",
    "        augmented_test = self.test.copy(deep=True)\n",
    "        augmented_test[self.target] = pseudo_labels\n",
    "        \n",
    "        # Take a subset of the test set with pseudo-labels and append in onto\n",
    "        # the training set\n",
    "        sampled_test = augmented_test.sample(n=num_of_samples)\n",
    "        temp_train = pd.concat([X, y], axis=1)\n",
    "#         print(sampled_test.head())\n",
    "#         print(temp_train.head())\n",
    "        augmented_train = pd.concat([sampled_test, temp_train])\n",
    "        augmented_train = shuffle(augmented_train)\n",
    "        augmented_X = augmented_train.drop(['state'], axis=1)\n",
    "        augmented_y = augmented_train['state']\n",
    "        \n",
    "        return augmented_X, augmented_y\n",
    "    \n",
    "    def predict(self, X):\n",
    "        return self.model.predict(X)\n",
    "    \n",
    "    def predict_proba(self, X):\n",
    "        return self.model.predict_proba(X)\n",
    "    \n",
    "    def get_model_name(self):\n",
    "        return self.model.__class__.__name__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(21418, 150)\n",
      "(21418, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/elizabeth/education/chair_sensor/ml_project/venv/lib/python3.5/site-packages/sklearn/utils/validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            x0        y0        z0        x1        y1        z1        x2  \\\n",
      "5918  0.071289 -0.014648  1.001953  0.057617 -0.015625  0.992188  0.067383   \n",
      "4354  0.079102 -0.003906  0.993164  0.070312 -0.004883  0.998047  0.075195   \n",
      "3098  0.068359 -0.004883  1.000000  0.056641 -0.009766  0.990234  0.053711   \n",
      "5199  0.055664 -0.009766  0.991211  0.055664 -0.013672  0.991211  0.064453   \n",
      "2546  0.071289 -0.010742  0.990234  0.072266 -0.007812  0.991211  0.072266   \n",
      "\n",
      "            y2        z2        x3  ...       x47       y47       z47  \\\n",
      "5918 -0.012695  0.990234  0.066406  ...  0.071289 -0.017578  1.000000   \n",
      "4354 -0.013672  0.992188  0.076172  ...  0.082031 -0.008789  0.996094   \n",
      "3098 -0.010742  0.983398  0.070312  ...  0.062500 -0.009766  0.986328   \n",
      "5199 -0.011719  0.999023  0.066406  ...  0.066406 -0.014648  0.996094   \n",
      "2546 -0.006836  0.991211  0.072266  ...  0.075195 -0.010742  0.985352   \n",
      "\n",
      "           x48       y48       z48       x49       y49       z49  state  \n",
      "5918  0.061523 -0.010742  0.981445  0.060547 -0.009766  1.000000      1  \n",
      "4354  0.076172 -0.006836  0.997070  0.079102 -0.006836  0.990234      1  \n",
      "3098  0.055664 -0.003906  1.000000  0.056641 -0.022461  1.000000      0  \n",
      "5199  0.067383 -0.011719  0.994141  0.062500 -0.018555  0.986328      0  \n",
      "2546  0.063477  0.000000  0.985352  0.076172 -0.004883  0.987305      1  \n",
      "\n",
      "[5 rows x 151 columns]\n",
      "         x0        y0        z0        x1        y1        z1        x2  \\\n",
      "0  0.082031  0.021484  1.007812  0.078125  0.032227  1.004883  0.079102   \n",
      "1  0.088867  0.029297  0.995117  0.078125  0.038086  0.990234  0.078125   \n",
      "2  0.074219  0.027344  0.995117  0.077148  0.030273  1.000000  0.081055   \n",
      "3  0.077148  0.017578  1.000000  0.081055  0.024414  0.995117  0.083984   \n",
      "4  0.083008  0.027344  0.988281  0.080078  0.014648  0.993164  0.075195   \n",
      "\n",
      "         y2        z2        x3  ...       x47       y47       z47       x48  \\\n",
      "0  0.018555  0.991211  0.085938  ...  0.083984 -0.042969  0.999023  0.085938   \n",
      "1  0.033203  0.994141  0.080078  ...  0.082031 -0.034180  1.000977  0.093750   \n",
      "2  0.047852  0.995117  0.081055  ...  0.084961 -0.017578  0.985352  0.083984   \n",
      "3  0.013672  0.991211  0.084961  ...  0.083008 -0.000977  0.979492  0.089844   \n",
      "4  0.022461  0.983398  0.085938  ...  0.083984  0.018555  0.995117  0.086914   \n",
      "\n",
      "        y48       z48       x49       y49       z49  state  \n",
      "0 -0.055664  1.009766  0.082031 -0.045898  0.987305      1  \n",
      "1 -0.040039  1.002930  0.086914 -0.034180  0.998047      1  \n",
      "2  0.000000  0.986328  0.085938 -0.010742  0.994141      1  \n",
      "3 -0.001953  0.989258  0.088867 -0.000977  1.000977      1  \n",
      "4  0.018555  1.007812  0.090820  0.014648  0.986328      1  \n",
      "\n",
      "[5 rows x 151 columns]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93      2566\n",
      "           1       0.88      0.94      0.91      2661\n",
      "           2       0.66      0.62      0.64       395\n",
      "           3       0.90      0.41      0.56       411\n",
      "\n",
      "   micro avg       0.88      0.88      0.88      6033\n",
      "   macro avg       0.84      0.73      0.76      6033\n",
      "weighted avg       0.88      0.88      0.88      6033\n",
      "\n",
      "[[2418   79   51   18]\n",
      " [ 139 2497   25    0]\n",
      " [  50   98  246    1]\n",
      " [  17  179   48  167]]\n",
      "balanced accuracy 0.7274506399008532\n"
     ]
    }
   ],
   "source": [
    "#Pseudo-labeling on actual test set\n",
    "train_df = pd.read_csv('../data/processed/train.csv')\n",
    "test_df = pd.read_csv('../data/processed/test.csv')\n",
    "\n",
    "# Preprocess the data\n",
    "X_train, X_test = train_df.drop(['state', 'name'], axis=1), test_df.drop(['state', 'name'], axis=1)\n",
    "y_train, y_test = pd.DataFrame(train_df['state']),  pd.DataFrame(test_df['state'])\n",
    "\n",
    "# Create the PseudoLabeler with XGBRegressor as the base regressor\n",
    "model = PseudoLabeler(\n",
    "#    RandomForestClassifier(n_estimators=100),\n",
    "    GradientBoostingClassifier(n_estimators=100),\n",
    "    X_test,\n",
    "    'state',\n",
    "    sample_rate=0.2\n",
    ")\n",
    "\n",
    "# Train the model and use it to predict\n",
    "model.fit(X_train, y_train)\n",
    "y_hat = model.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_hat))\n",
    "print(confusion_matrix(y_test, y_hat))\n",
    "accuracy = balanced_accuracy_score(y_test, y_hat)\n",
    "print('balanced accuracy', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/elizabeth/education/chair_sensor/ml_project/venv/lib/python3.5/site-packages/ipykernel_launcher.py:70: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_______initial supervised model______\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.93      0.92      2566\n",
      "           1       0.87      0.94      0.90      2661\n",
      "           2       0.74      0.58      0.65       395\n",
      "           3       0.83      0.52      0.64       411\n",
      "\n",
      "   micro avg       0.88      0.88      0.88      6033\n",
      "   macro avg       0.84      0.74      0.78      6033\n",
      "weighted avg       0.88      0.88      0.88      6033\n",
      "\n",
      "[[2391  119   15   41]\n",
      " [ 137 2492   30    2]\n",
      " [  72   94  228    1]\n",
      " [  17  146   35  213]]\n",
      "balanced accuracy 0.7409384685119196\n",
      "(6876, 150) (6876, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/elizabeth/education/chair_sensor/ml_project/venv/lib/python3.5/site-packages/ipykernel_launcher.py:92: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_______ daniel ______\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.93      0.92      2566\n",
      "           1       0.87      0.94      0.90      2661\n",
      "           2       0.73      0.57      0.64       395\n",
      "           3       0.82      0.51      0.63       411\n",
      "\n",
      "   micro avg       0.88      0.88      0.88      6033\n",
      "   macro avg       0.83      0.74      0.77      6033\n",
      "weighted avg       0.88      0.88      0.88      6033\n",
      "\n",
      "[[2386  124   15   41]\n",
      " [ 135 2494   29    3]\n",
      " [  73   92  227    3]\n",
      " [  17  145   39  210]]\n",
      "balanced accuracy 0.7381814993704915\n",
      "(7100, 150) (7100, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/elizabeth/education/chair_sensor/ml_project/venv/lib/python3.5/site-packages/ipykernel_launcher.py:92: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_______ sue ______\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.93      0.92      2566\n",
      "           1       0.87      0.94      0.91      2661\n",
      "           2       0.74      0.58      0.65       395\n",
      "           3       0.82      0.52      0.63       411\n",
      "\n",
      "   micro avg       0.88      0.88      0.88      6033\n",
      "   macro avg       0.84      0.74      0.78      6033\n",
      "weighted avg       0.88      0.88      0.88      6033\n",
      "\n",
      "[[2388  122   15   41]\n",
      " [ 132 2496   30    3]\n",
      " [  72   90  230    3]\n",
      " [  17  146   36  212]]\n",
      "balanced accuracy 0.7416795336525579\n",
      "(7697, 150) (7697, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/elizabeth/education/chair_sensor/ml_project/venv/lib/python3.5/site-packages/ipykernel_launcher.py:92: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_______ lenin ______\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.93      0.92      2566\n",
      "           1       0.87      0.94      0.91      2661\n",
      "           2       0.73      0.58      0.65       395\n",
      "           3       0.83      0.51      0.63       411\n",
      "\n",
      "   micro avg       0.88      0.88      0.88      6033\n",
      "   macro avg       0.84      0.74      0.78      6033\n",
      "weighted avg       0.88      0.88      0.88      6033\n",
      "\n",
      "[[2389  121   15   41]\n",
      " [ 127 2502   30    2]\n",
      " [  71   92  231    1]\n",
      " [  19  145   39  208]]\n",
      "balanced accuracy 0.7405404807819318\n",
      "(8600, 150) (8600, 1)\n"
     ]
    }
   ],
   "source": [
    "#Incremental pseudo-labeling\n",
    "#Case 0: add pseudo-labeled data incrementally, no discrimination. We do per subject\n",
    "from sklearn.model_selection import LeaveOneGroupOut\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "import random\n",
    "\n",
    "def create_augmented_train(model, X, y, X_test, sample_rate, target='state'):\n",
    "    '''\n",
    "    Create and return the augmented_train set that consists\n",
    "    of pseudo-labeled and labeled data.\n",
    "    '''\n",
    "    num_of_samples = int(len(X_test) * sample_rate)\n",
    "\n",
    "    # Train the model and create the pseudo-labels\n",
    "    #model.fit(X, y)\n",
    "    pseudo_labels = model.predict(X_test)\n",
    "\n",
    "    # Add the pseudo-labels to the test set\n",
    "    augmented_test = X_test.copy(deep=True)\n",
    "    augmented_test[target] = pseudo_labels\n",
    "\n",
    "    # Take a subset of the test set with pseudo-labels and append in onto\n",
    "    # the training set\n",
    "    sampled_test = augmented_test.sample(n=num_of_samples)\n",
    "    temp_train = pd.concat([X, y], axis=1)\n",
    "#         print(sampled_test.head())\n",
    "#         print(temp_train.head())\n",
    "    augmented_train = pd.concat([sampled_test, temp_train])\n",
    "    augmented_train = shuffle(augmented_train)\n",
    "    augmented_X = augmented_train.drop(['state'], axis=1)\n",
    "    augmented_y = pd.DataFrame(data=augmented_train['state'], columns=['state'])\n",
    "#     augmented_y = augmented_train['state']\n",
    "    \n",
    "    return augmented_X, augmented_y\n",
    "\n",
    "train_df = pd.read_csv('../data/processed/train.csv')\n",
    "test_df = pd.read_csv('../data/processed/test.csv')\n",
    "\n",
    "X_train, X_test = train_df.drop(['state', 'name'], axis=1), test_df.drop(['state', 'name'], axis=1)\n",
    "y_train, y_test = pd.DataFrame(train_df['state']),  pd.DataFrame(test_df['state'])\n",
    "\n",
    "groups_dict = train_df.groupby('name')\n",
    "\n",
    "# Train initial model\n",
    "index = np.random.randint(0,len(groups_dict), dtype='int')\n",
    "subject_supervised = list(groups_dict.groups)[index]\n",
    "\n",
    "# model = PseudoLabeler(\n",
    "#     RandomForestClassifier(n_estimators=10, warm_start=True),\n",
    "# #    GradientBoostingClassifier(n_estimators=100),\n",
    "#     X_test,\n",
    "#     'state',\n",
    "#     sample_rate=0.0\n",
    "# )\n",
    "\n",
    "model = RandomForestClassifier(criterion='gini',\n",
    "                             max_features=None,\n",
    "                             min_samples_split=5,\n",
    "                             n_estimators=100,\n",
    "                             warm_start=True)\n",
    "\n",
    "X_supervised = pd.DataFrame(data=X_train.values[groups_dict.groups[subject_supervised]])\n",
    "y_supervised = pd.DataFrame(data=y_train.values[groups_dict.groups[subject_supervised]], columns=['state'])\n",
    "\n",
    "model.fit(X_supervised, y_supervised)\n",
    "y_hat = model.predict(X_test)\n",
    "\n",
    "print('_______initial supervised model______')\n",
    "print(classification_report(y_test, y_hat))\n",
    "print(confusion_matrix(y_test, y_hat))\n",
    "accuracy = balanced_accuracy_score(y_test, y_hat)\n",
    "print('balanced accuracy', accuracy)\n",
    "\n",
    "current_X = X_supervised.copy(deep=True)\n",
    "current_y = y_supervised.copy(deep=True)\n",
    "\n",
    "sample_rate = 0.2\n",
    "for subject in groups_dict.groups:\n",
    "    # The rest of the subjects used to augment training set\n",
    "    if subject != subject_supervised:\n",
    "        model.n_estimators += 10\n",
    "        #y_hat = model.predict(X_train.values[groups_dict.groups[subject]])\n",
    "        #model.set_params(test=X_train.values[groups_dict.groups[subject]])\n",
    "        new_test = pd.DataFrame(data=X_train.values[groups_dict.groups[subject]])\n",
    "        current_X, current_y = create_augmented_train(model, current_X, current_y, new_test, sample_rate)\n",
    "        print(current_X.shape, current_y.shape)\n",
    "        model.fit(current_X, current_y)\n",
    "        y_hat = model.predict(X_test)\n",
    "        print('_______', subject, '______')\n",
    "        print(classification_report(y_test, y_hat))\n",
    "        print(confusion_matrix(y_test, y_hat))\n",
    "        accuracy = balanced_accuracy_score(y_test, y_hat)\n",
    "        print('balanced accuracy', accuracy)\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/elizabeth/education/chair_sensor/ml_project/venv/lib/python3.5/site-packages/ipykernel_launcher.py:106: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_______initial supervised model______\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.92      0.92      2566\n",
      "           1       0.87      0.93      0.90      2661\n",
      "           2       0.72      0.60      0.65       395\n",
      "           3       0.81      0.52      0.63       411\n",
      "\n",
      "   micro avg       0.88      0.88      0.88      6033\n",
      "   macro avg       0.83      0.74      0.78      6033\n",
      "weighted avg       0.88      0.88      0.87      6033\n",
      "\n",
      "[[2369  136   16   45]\n",
      " [ 142 2485   30    4]\n",
      " [  68   89  236    2]\n",
      " [  18  133   47  213]]\n",
      "balanced accuracy 0.7432006982764872\n",
      "6093\n",
      "6093\n",
      "     cat  probs\n",
      "500    0    1.0\n",
      "747    0    1.0\n",
      "369    0    1.0\n",
      "367    0    1.0\n",
      "366    0    1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/elizabeth/education/chair_sensor/ml_project/venv/lib/python3.5/site-packages/ipykernel_launcher.py:141: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_______new model______\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.92      0.92      2566\n",
      "           1       0.88      0.94      0.90      2661\n",
      "           2       0.73      0.61      0.66       395\n",
      "           3       0.82      0.52      0.64       411\n",
      "\n",
      "   micro avg       0.88      0.88      0.88      6033\n",
      "   macro avg       0.84      0.75      0.78      6033\n",
      "weighted avg       0.88      0.88      0.88      6033\n",
      "\n",
      "[[2373  133   16   44]\n",
      " [ 135 2490   34    2]\n",
      " [  72   81  241    1]\n",
      " [  19  138   39  215]]\n",
      "balanced accuracy 0.7484412600790409\n",
      "6293\n",
      "6293\n",
      "     cat  probs\n",
      "873    0    1.0\n",
      "359    0    1.0\n",
      "357    0    1.0\n",
      "355    0    1.0\n",
      "354    0    1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/elizabeth/education/chair_sensor/ml_project/venv/lib/python3.5/site-packages/ipykernel_launcher.py:141: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_______new model______\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.93      0.92      2566\n",
      "           1       0.88      0.93      0.90      2661\n",
      "           2       0.72      0.59      0.65       395\n",
      "           3       0.80      0.50      0.61       411\n",
      "\n",
      "   micro avg       0.88      0.88      0.88      6033\n",
      "   macro avg       0.83      0.74      0.77      6033\n",
      "weighted avg       0.88      0.88      0.87      6033\n",
      "\n",
      "[[2382  127   14   43]\n",
      " [ 136 2487   32    6]\n",
      " [  67   90  235    3]\n",
      " [  21  138   47  205]]\n",
      "balanced accuracy 0.7391560688649728\n",
      "6493\n",
      "6493\n",
      "     cat  probs\n",
      "500    0    1.0\n",
      "510    0    1.0\n",
      "507    0    1.0\n",
      "506    0    1.0\n",
      "505    0    1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/elizabeth/education/chair_sensor/ml_project/venv/lib/python3.5/site-packages/ipykernel_launcher.py:141: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_______new model______\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.92      0.92      2566\n",
      "           1       0.87      0.94      0.90      2661\n",
      "           2       0.70      0.57      0.63       395\n",
      "           3       0.81      0.51      0.62       411\n",
      "\n",
      "   micro avg       0.88      0.88      0.88      6033\n",
      "   macro avg       0.82      0.73      0.77      6033\n",
      "weighted avg       0.87      0.88      0.87      6033\n",
      "\n",
      "[[2360  146   17   43]\n",
      " [ 132 2493   31    5]\n",
      " [  73   95  225    2]\n",
      " [  19  136   47  209]]\n",
      "balanced accuracy 0.7336803289494678\n",
      "6693\n",
      "6693\n",
      "     cat  probs\n",
      "0      0    1.0\n",
      "290    0    1.0\n",
      "288    0    1.0\n",
      "287    0    1.0\n",
      "286    0    1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/elizabeth/education/chair_sensor/ml_project/venv/lib/python3.5/site-packages/ipykernel_launcher.py:141: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_______new model______\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.92      0.92      2566\n",
      "           1       0.87      0.93      0.90      2661\n",
      "           2       0.73      0.59      0.65       395\n",
      "           3       0.82      0.50      0.62       411\n",
      "\n",
      "   micro avg       0.88      0.88      0.88      6033\n",
      "   macro avg       0.83      0.74      0.77      6033\n",
      "weighted avg       0.87      0.88      0.87      6033\n",
      "\n",
      "[[2368  144   15   39]\n",
      " [ 139 2486   32    4]\n",
      " [  73   87  233    2]\n",
      " [  22  144   39  206]]\n",
      "balanced accuracy 0.7370405782963327\n",
      "6893\n",
      "6893\n",
      "     cat  probs\n",
      "500    0    1.0\n",
      "594    0    1.0\n",
      "587    0    1.0\n",
      "588    0    1.0\n",
      "589    0    1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/elizabeth/education/chair_sensor/ml_project/venv/lib/python3.5/site-packages/ipykernel_launcher.py:141: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_______new model______\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.92      0.92      2566\n",
      "           1       0.87      0.93      0.90      2661\n",
      "           2       0.72      0.60      0.66       395\n",
      "           3       0.82      0.51      0.63       411\n",
      "\n",
      "   micro avg       0.88      0.88      0.88      6033\n",
      "   macro avg       0.83      0.74      0.78      6033\n",
      "weighted avg       0.88      0.88      0.87      6033\n",
      "\n",
      "[[2371  139   15   41]\n",
      " [ 139 2487   32    3]\n",
      " [  71   85  238    1]\n",
      " [  18  137   45  211]]\n",
      "balanced accuracy 0.7436327311418177\n",
      "7093\n",
      "7093\n",
      "     cat  probs\n",
      "0      0    1.0\n",
      "580    0    1.0\n",
      "572    0    1.0\n",
      "573    0    1.0\n",
      "574    0    1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/elizabeth/education/chair_sensor/ml_project/venv/lib/python3.5/site-packages/ipykernel_launcher.py:141: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_______new model______\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.92      0.92      2566\n",
      "           1       0.87      0.94      0.90      2661\n",
      "           2       0.70      0.58      0.63       395\n",
      "           3       0.80      0.50      0.61       411\n",
      "\n",
      "   micro avg       0.88      0.88      0.88      6033\n",
      "   macro avg       0.82      0.73      0.77      6033\n",
      "weighted avg       0.87      0.88      0.87      6033\n",
      "\n",
      "[[2365  144   15   42]\n",
      " [ 133 2492   32    4]\n",
      " [  76   87  228    4]\n",
      " [  18  138   51  204]]\n",
      "balanced accuracy 0.7329308904700356\n",
      "7293\n",
      "7293\n",
      "     cat  probs\n",
      "500    0    1.0\n",
      "375    0    1.0\n",
      "369    0    1.0\n",
      "370    0    1.0\n",
      "371    0    1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/elizabeth/education/chair_sensor/ml_project/venv/lib/python3.5/site-packages/ipykernel_launcher.py:141: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_______new model______\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.92      0.92      2566\n",
      "           1       0.87      0.94      0.90      2661\n",
      "           2       0.72      0.58      0.64       395\n",
      "           3       0.81      0.51      0.63       411\n",
      "\n",
      "   micro avg       0.88      0.88      0.88      6033\n",
      "   macro avg       0.83      0.74      0.77      6033\n",
      "weighted avg       0.87      0.88      0.87      6033\n",
      "\n",
      "[[2363  145   15   43]\n",
      " [ 132 2492   32    5]\n",
      " [  69   96  230    0]\n",
      " [  17  139   44  211]]\n",
      "balanced accuracy 0.7382597649907218\n",
      "7493\n",
      "7493\n",
      "     cat  probs\n",
      "500    0    1.0\n",
      "635    0    1.0\n",
      "622    0    1.0\n",
      "623    0    1.0\n",
      "624    0    1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/elizabeth/education/chair_sensor/ml_project/venv/lib/python3.5/site-packages/ipykernel_launcher.py:141: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_______new model______\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.92      0.92      2566\n",
      "           1       0.87      0.93      0.90      2661\n",
      "           2       0.71      0.59      0.64       395\n",
      "           3       0.81      0.51      0.62       411\n",
      "\n",
      "   micro avg       0.88      0.88      0.88      6033\n",
      "   macro avg       0.83      0.74      0.77      6033\n",
      "weighted avg       0.87      0.88      0.87      6033\n",
      "\n",
      "[[2370  138   16   42]\n",
      " [ 136 2485   37    3]\n",
      " [  70   90  232    3]\n",
      " [  21  141   41  208]]\n",
      "balanced accuracy 0.7377251180798048\n",
      "7693\n",
      "7693\n",
      "     cat  probs\n",
      "0      0    1.0\n",
      "588    0    1.0\n",
      "568    0    1.0\n",
      "569    0    1.0\n",
      "572    0    1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/elizabeth/education/chair_sensor/ml_project/venv/lib/python3.5/site-packages/ipykernel_launcher.py:141: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_______new model______\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.92      0.92      2566\n",
      "           1       0.87      0.93      0.90      2661\n",
      "           2       0.70      0.59      0.64       395\n",
      "           3       0.82      0.50      0.62       411\n",
      "\n",
      "   micro avg       0.88      0.88      0.88      6033\n",
      "   macro avg       0.82      0.74      0.77      6033\n",
      "weighted avg       0.87      0.88      0.87      6033\n",
      "\n",
      "[[2366  144   15   41]\n",
      " [ 138 2486   34    3]\n",
      " [  70   92  232    1]\n",
      " [  20  134   52  205]]\n",
      "balanced accuracy 0.7356045385911419\n",
      "7893\n",
      "7893\n",
      "     cat  probs\n",
      "787    0    1.0\n",
      "431    0    1.0\n",
      "424    0    1.0\n",
      "425    0    1.0\n",
      "426    0    1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/elizabeth/education/chair_sensor/ml_project/venv/lib/python3.5/site-packages/ipykernel_launcher.py:141: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_______new model______\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.93      0.92      2566\n",
      "           1       0.87      0.94      0.90      2661\n",
      "           2       0.71      0.61      0.66       395\n",
      "           3       0.83      0.51      0.63       411\n",
      "\n",
      "   micro avg       0.88      0.88      0.88      6033\n",
      "   macro avg       0.83      0.74      0.78      6033\n",
      "weighted avg       0.88      0.88      0.88      6033\n",
      "\n",
      "[[2375  134   17   40]\n",
      " [ 132 2491   35    3]\n",
      " [  70   84  240    1]\n",
      " [  19  140   44  208]]\n",
      "balanced accuracy 0.7438392465937511\n",
      "8093\n",
      "8093\n",
      "     cat  probs\n",
      "0      0    1.0\n",
      "603    0    1.0\n",
      "605    0    1.0\n",
      "606    0    1.0\n",
      "607    0    1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/elizabeth/education/chair_sensor/ml_project/venv/lib/python3.5/site-packages/ipykernel_launcher.py:141: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-38-fcb49be32813>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    139\u001b[0m                              n_estimators=100)\n\u001b[1;32m    140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_aug\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_aug\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m     \u001b[0;31m# Evaluate new model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/education/chair_sensor/ml_project/venv/lib/python3.5/site-packages/sklearn/ensemble/forest.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    331\u001b[0m                     \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrees\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    332\u001b[0m                     verbose=self.verbose, class_weight=self.class_weight)\n\u001b[0;32m--> 333\u001b[0;31m                 for i, t in enumerate(trees))\n\u001b[0m\u001b[1;32m    334\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    335\u001b[0m             \u001b[0;31m# Collect newly grown trees\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/education/chair_sensor/ml_project/venv/lib/python3.5/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    918\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    919\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 920\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    921\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    922\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/education/chair_sensor/ml_project/venv/lib/python3.5/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    757\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    758\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 759\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    760\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    761\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/education/chair_sensor/ml_project/venv/lib/python3.5/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    714\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    715\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 716\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    717\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    718\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/education/chair_sensor/ml_project/venv/lib/python3.5/site-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    180\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 182\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    183\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/education/chair_sensor/ml_project/venv/lib/python3.5/site-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    547\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    548\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 549\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    550\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    551\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/education/chair_sensor/ml_project/venv/lib/python3.5/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    223\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 225\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    226\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/education/chair_sensor/ml_project/venv/lib/python3.5/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    223\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 225\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    226\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/education/chair_sensor/ml_project/venv/lib/python3.5/site-packages/sklearn/ensemble/forest.py\u001b[0m in \u001b[0;36m_parallel_build_trees\u001b[0;34m(tree, forest, X, y, sample_weight, tree_idx, n_trees, verbose, class_weight)\u001b[0m\n\u001b[1;32m    117\u001b[0m             \u001b[0mcurr_sample_weight\u001b[0m \u001b[0;34m*=\u001b[0m \u001b[0mcompute_sample_weight\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'balanced'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m         \u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcurr_sample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m         \u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/education/chair_sensor/ml_project/venv/lib/python3.5/site-packages/sklearn/tree/tree.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    799\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    800\u001b[0m             \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcheck_input\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 801\u001b[0;31m             X_idx_sorted=X_idx_sorted)\n\u001b[0m\u001b[1;32m    802\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    803\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/education/chair_sensor/ml_project/venv/lib/python3.5/site-packages/sklearn/tree/tree.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    364\u001b[0m                                            min_impurity_split)\n\u001b[1;32m    365\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 366\u001b[0;31m         \u001b[0mbuilder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_idx_sorted\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    367\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    368\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#Incremental pseudo-labeling\n",
    "#Case 1: add pseudo-labeled data incrementally, most confident PTs have higher priority\n",
    "from sklearn.model_selection import LeaveOneGroupOut\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "import random\n",
    "\n",
    "# def create_augmented_train(model, X, y, X_test, sample_rate, target='state'):\n",
    "#     '''\n",
    "#     Create and return the augmented_train set that consists\n",
    "#     of pseudo-labeled and labeled data.\n",
    "#     '''\n",
    "#     num_of_samples = int(len(X_test) * sample_rate)\n",
    "\n",
    "#     # Train the model and create the pseudo-labels\n",
    "#     #model.fit(X, y)\n",
    "#     pseudo_labels = model.predict(X_test)\n",
    "\n",
    "#     # Add the pseudo-labels to the test set\n",
    "#     augmented_test = X_test.copy(deep=True)\n",
    "#     augmented_test[target] = pseudo_labels\n",
    "\n",
    "#     # Take a subset of the test set with pseudo-labels and append in onto\n",
    "#     # the training set\n",
    "#     sampled_test = augmented_test.sample(n=num_of_samples)\n",
    "#     temp_train = pd.concat([X, y], axis=1)\n",
    "# #         print(sampled_test.head())\n",
    "# #         print(temp_train.head())\n",
    "#     augmented_train = pd.concat([sampled_test, temp_train])\n",
    "#     augmented_train = shuffle(augmented_train)\n",
    "#     augmented_X = augmented_train.drop(['state'], axis=1)\n",
    "#     augmented_y = pd.DataFrame(data=augmented_train['state'], columns=['state'])\n",
    "# #     augmented_y = augmented_train['state']\n",
    "    \n",
    "#     return augmented_X, augmented_y\n",
    "\n",
    "def create_augmented_data(model, X, y, X_train, sample_rate):\n",
    "    print(len(X))\n",
    "    print(len(y))\n",
    "    '''\n",
    "    Create and return the augmented_train set that consists\n",
    "    of pseudo-labeled and labeled data.\n",
    "    '''\n",
    "#     X_pseudo = pd.DataFrame(data=X_train)\n",
    "    # Create the pseudo-labels\n",
    "    pred_probs = model.predict_proba(X_train)\n",
    "    pred_labels = [np.argmax(e) for e in pred_probs]\n",
    "    max_pred_probs = [np.max(e) for e in pred_probs]\n",
    "    \n",
    "    cat_pred_probs = [0 if e <= 1 else 10 for e in pred_labels]\n",
    "    data_df = { 'probs': max_pred_probs, 'cat': cat_pred_probs }\n",
    "    max_pred_probs_df = pd.DataFrame(data=data_df)\n",
    "    max_pred_probs_df = max_pred_probs_df.sort_values(by=['probs'], ascending=False)\n",
    "    print(max_pred_probs_df.head())\n",
    "        \n",
    "    pseudo_size = int(sample_rate * len(X_train))\n",
    "    max_indices = max_pred_probs_df.index.values[:pseudo_size]\n",
    "    \n",
    "#     preds = model.predict(X_train)\n",
    "#     y_pseudo = pd.DataFrame(data=preds, dtype=np.int8)\n",
    "\n",
    "    X_pseudo = pd.DataFrame(data=X_train[max_indices])\n",
    "    pred_labels = np.array(pred_labels)[max_indices]\n",
    "    y_pseudo = pd.DataFrame(data=pred_labels, dtype=np.int8)\n",
    "\n",
    "    # Add the pseudo-labels to the previous training set\n",
    "    X_aug = pd.concat([X, X_pseudo], ignore_index=True)\n",
    "    y_aug = pd.concat([y, y_pseudo], ignore_index=True)\n",
    "\n",
    "    return X_aug, y_aug\n",
    "\n",
    "train_df = pd.read_csv('../data/processed/train.csv')\n",
    "test_df = pd.read_csv('../data/processed/test.csv')\n",
    "\n",
    "X_train, X_test = train_df.drop(['state', 'name'], axis=1), test_df.drop(['state', 'name'], axis=1)\n",
    "y_train, y_test = pd.DataFrame(train_df['state']),  pd.DataFrame(test_df['state'])\n",
    "\n",
    "groups_dict = train_df.groupby('name')\n",
    "\n",
    "# Train initial model\n",
    "index = np.random.randint(0,len(groups_dict), dtype='int')\n",
    "subject_supervised = list(groups_dict.groups)[index]\n",
    "subjects_unsupervised = list()\n",
    "\n",
    "for name in groups_dict.groups.keys():\n",
    "    if name != subject_supervised:\n",
    "        subjects_unsupervised.extend(groups_dict.groups[name].values)\n",
    "\n",
    "model = RandomForestClassifier(criterion='gini',\n",
    "                             max_features=None,\n",
    "                             min_samples_split=5,\n",
    "                             n_estimators=100)\n",
    "\n",
    "X_supervised = pd.DataFrame(data=X_train.values[groups_dict.groups[subject_supervised]])\n",
    "y_supervised = pd.DataFrame(data=y_train.values[groups_dict.groups[subject_supervised]])\n",
    "\n",
    "X_unlabeled = pd.DataFrame(data=X_train.values[subjects_unsupervised])\n",
    "\n",
    "# print('super', len(X_supervised))\n",
    "# print('unsuper', len(X_unlabeled))\n",
    "# print('all', len(X_train))\n",
    "model.fit(X_supervised, y_supervised)\n",
    "y_hat = model.predict(X_test)\n",
    "\n",
    "print('_______initial supervised model______')\n",
    "print(classification_report(y_test, y_hat))\n",
    "print(confusion_matrix(y_test, y_hat))\n",
    "accuracy = balanced_accuracy_score(y_test, y_hat)\n",
    "print('balanced accuracy', accuracy)\n",
    "\n",
    "# current_X = X_supervised.copy(deep=True)\n",
    "# current_y = y_supervised.copy(deep=True)\n",
    "\n",
    "X_aug = pd.DataFrame(data=X_train.values[groups_dict.groups[subject_supervised]])\n",
    "y_aug = pd.DataFrame(data=y_train.values[groups_dict.groups[subject_supervised]])\n",
    "\n",
    "sample_rate = 0.2\n",
    "batch_size = 1000\n",
    "i = 0\n",
    "while i < len(X_unlabeled.values):\n",
    "    start = i\n",
    "    end = start + batch_size\n",
    "    if i >= len(X_unlabeled.values):\n",
    "        end = len(X_unlabeled.values)-1\n",
    "        i = end\n",
    "    else:\n",
    "        i = end\n",
    "    # create augmented data\n",
    "    X_aug, y_aug = create_augmented_data(model, X_aug, y_aug, X_unlabeled.values[start:end], sample_rate)\n",
    "\n",
    "    # Train new model with augmented training set\n",
    "    model = RandomForestClassifier(criterion='gini',\n",
    "                             max_features=None,\n",
    "                             min_samples_split=5,\n",
    "                             n_estimators=100)\n",
    "    \n",
    "    model.fit(X_aug, y_aug)\n",
    "    \n",
    "    # Evaluate new model\n",
    "    y_hat = model.predict(X_test)\n",
    "    print('_______new model______')\n",
    "    print(classification_report(y_test, y_hat))\n",
    "    print(confusion_matrix(y_test, y_hat))\n",
    "    accuracy = balanced_accuracy_score(y_test, y_hat)\n",
    "    print('balanced accuracy', accuracy)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Pseudo-labeling with random selecion for NN\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from numpy import dstack\n",
    "import numpy as np\n",
    "from pandas import read_csv\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import LSTM\n",
    "from keras.utils import to_categorical\n",
    "from matplotlib import pyplot\n",
    "\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load a single file as a numpy array\n",
    "def load_file(filepath):\n",
    "    dataframe = read_csv(filepath, header=None)\n",
    "    return dataframe.values\n",
    "\n",
    "# load a list of files and return as a 3d numpy array\n",
    "def load_group(filenames, prefix=''):\n",
    "    loaded = list()\n",
    "    for name in filenames:\n",
    "        data = load_file(prefix + name)\n",
    "        loaded.append(data)\n",
    "    # stack group so that features are the 3rd dimension\n",
    "    print('loaded', len(loaded[0]))\n",
    "    loaded = dstack(loaded)\n",
    "    print('stacked', loaded.shape)\n",
    "    return loaded\n",
    "\n",
    "# load a dataset group, such as train or test\n",
    "def load_dataset_group(group, freq, win, prefix=''):\n",
    "    filepath = prefix + group + '/'\n",
    "    # load all 9 files as a single array\n",
    "    filenames = list()\n",
    "    # total acceleration\n",
    "    filenames += ['total_acc_x_'+group+'_'+win+'_'+freq+'.csv', 'total_acc_y_'+group+'_'+win+'_'+freq+'.csv', 'total_acc_z_'+group+'_'+win+'_'+freq+'.csv']\n",
    "#     # body acceleration\n",
    "#     filenames += ['body_acc_x_'+group+'_'+win+'_'+freq+'.csv', 'body_acc_y_'+group+'_'+win+'_'+freq+'.csv', 'body_acc_z_'+group+'_'+win+'_'+freq+'.csv']\n",
    "#     # body gyroscope\n",
    "#     filenames += ['body_gyro_x_'+group+'_'+win+'_'+freq+'.csv', 'body_gyro_y_'+group+'_'+win+'_'+freq+'.csv', 'body_gyro_z_'+group+'_'+win+'_'+freq+'.csv']\n",
    "    # load input data\n",
    "    X = load_group(filenames, filepath)\n",
    "    # load class output\n",
    "    y = load_file(prefix + group + '/state_'+group+'_'+win+'_'+freq+'.csv')\n",
    "    print('X:', filenames)\n",
    "    print('y:', prefix + group + '/state_'+group+'_'+win+'_'+freq+'.csv')\n",
    "    return X, y\n",
    "\n",
    "# load the dataset, returns train and test X and y elements\n",
    "def load_dataset(freq, win, prefix=''):\n",
    "    # load all train\n",
    "    trainX, trainy = load_dataset_group('train', freq, win, prefix)\n",
    "    print(trainX.shape, trainy.shape)\n",
    "    # load all test\n",
    "    testX, testy = load_dataset_group('test', freq, win, prefix)\n",
    "    print(testX.shape, testy.shape)\n",
    "    # zero-offset class values\n",
    "#     trainy = trainy - 1\n",
    "#     testy = testy - 1\n",
    "    # one hot encode y\n",
    "    trainy = to_categorical(trainy)\n",
    "    y_true = testy\n",
    "    testy = to_categorical(testy)\n",
    "    print(trainX.shape, trainy.shape, testX.shape, testy.shape, y_true.shape)\n",
    "    return trainX, trainy, testX, testy, y_true\n",
    "\n",
    "# summarize scores\n",
    "def summarize_results(scores):\n",
    "    print(scores)\n",
    "    m, s = mean(scores), std(scores)\n",
    "    print('Accuracy: %.3f%% (+/-%.3f)' % (m, s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded 21436\n",
      "stacked (21436, 50, 3)\n",
      "X: ['total_acc_x_train_50_50.csv', 'total_acc_y_train_50_50.csv', 'total_acc_z_train_50_50.csv']\n",
      "y: ../data/processed/train/state_train_50_50.csv\n",
      "(21436, 50, 3) (21436, 1)\n",
      "loaded 6030\n",
      "stacked (6030, 50, 3)\n",
      "X: ['total_acc_x_test_50_50.csv', 'total_acc_y_test_50_50.csv', 'total_acc_z_test_50_50.csv']\n",
      "y: ../data/processed/test/state_test_50_50.csv\n",
      "(6030, 50, 3) (6030, 1)\n",
      "(21436, 50, 3) (21436, 4) (6030, 50, 3) (6030, 4) (6030, 1)\n",
      "WARNING:tensorflow:From /home/elizabeth/education/chair_sensor/ml_project/venv/lib/python3.5/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /home/elizabeth/education/chair_sensor/ml_project/venv/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From /home/elizabeth/education/chair_sensor/ml_project/venv/lib/python3.5/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/15\n",
      "21436/21436 [==============================] - 45s 2ms/step - loss: 1.1410 - categorical_accuracy: 0.4543\n",
      "Epoch 2/15\n",
      " 1930/21436 [=>............................] - ETA: 46s - loss: 1.1126 - categorical_accuracy: 0.4731"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-481c3543f20a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0mfreq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'50'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0mwin\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'50'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m \u001b[0mpred_classes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_experiment\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfreq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwin\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-3-481c3543f20a>\u001b[0m in \u001b[0;36mrun_experiment\u001b[0;34m(freq, win, repeats)\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrepeats\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m         \u001b[0mpred_classes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtestX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtesty\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscore\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m100.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-481c3543f20a>\u001b[0m in \u001b[0;36mevaluate_model\u001b[0;34m(trainX, trainy, testX, testy)\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'categorical_crossentropy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'adam'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'categorical_accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;31m# fit network\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m     \u001b[0;31m# evaluate model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtestX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtesty\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/education/chair_sensor/ml_project/venv/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m~/education/chair_sensor/ml_project/venv/lib/python3.5/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/education/chair_sensor/ml_project/venv/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/education/chair_sensor/ml_project/venv/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/education/chair_sensor/ml_project/venv/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1439\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1440\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# lstm model\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from keras.layers import Bidirectional\n",
    "\n",
    "# fit and evaluate a model\n",
    "def evaluate_model(trainX, trainy, testX, testy):\n",
    "    verbose, epochs, batch_size = 1, 15, 10\n",
    "    n_timesteps, n_features, n_outputs = trainX.shape[1], trainX.shape[2], trainy.shape[1]\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(100, input_shape=(n_timesteps,n_features)))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(100, activation='relu'))\n",
    "    model.add(Dense(n_outputs, activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['categorical_accuracy'])\n",
    "    # fit network\n",
    "    model.fit(trainX, trainy, epochs=epochs, batch_size=batch_size, verbose=verbose)\n",
    "    # evaluate model\n",
    "    _, accuracy = model.evaluate(testX, testy, batch_size=batch_size, verbose=1)\n",
    "    prediction = model.predict_classes(testX)\n",
    "    return prediction, accuracy\n",
    "\n",
    "# run an experiment\n",
    "def run_experiment(freq, win, repeats=1):\n",
    "    # load data\n",
    "    trainX, trainy, testX, testy, y_true = load_dataset(freq=freq, win=win, prefix='../data/processed/')\n",
    "#     score = evaluate_model(trainX, trainy, testX, testy)\n",
    "#     print(score)\n",
    "    # repeat experiment\n",
    "    scores = list()\n",
    "    for r in range(repeats):\n",
    "        pred_classes, score = evaluate_model(trainX, trainy, testX, testy)\n",
    "        print(score)\n",
    "        score = score * 100.0\n",
    "        print('>#%d: %.3f' % (r+1, score))\n",
    "        scores.append(score)\n",
    "        print(classification_report(y_true, pred_classes))\n",
    "        print(confusion_matrix(y_true, pred_classes))\n",
    "    # summarize results\n",
    "    summarize_results(scores)\n",
    "    return pred_classes, y_true\n",
    "\n",
    "# run the experiment\n",
    "freq = '50'\n",
    "win = '50'\n",
    "pred_classes, y_true = run_experiment(freq, win)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import sample\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# K-fold pseudo-labeling\n",
    "def create_augmented_set(model, X, y, X_test, sample_rate, target='state'):\n",
    "    '''\n",
    "    Create and return the augmented_train set that consists\n",
    "    of pseudo-labeled and labeled data.\n",
    "    '''\n",
    "    num_of_samples = int(len(X_test) * sample_rate)\n",
    "\n",
    "    # Train the model and create the pseudo-labels\n",
    "    #model.fit(X, y)\n",
    "    y_pred = to_categorical(model.predict_classes(X_test))\n",
    "    \n",
    "    # Add the pseudo-labels to the test set\n",
    "#    augmented_test = X_test.copy()\n",
    "    augmented_X = X.copy()\n",
    "    augmented_y = y.copy()\n",
    "    \n",
    "    # Take a subset of the test set with pseudo-labels and append in onto\n",
    "    # the training set\n",
    "    indices = np.random.randint(0, len(X_test), size=(1,num_of_samples))[0]\n",
    "    augmented_X = np.append(augmented_X, X_test[indices], axis=0)\n",
    "#     print('aug', augmented_y)\n",
    "#     print('pred', y_pred)\n",
    "    augmented_y = np.append(augmented_y, y_pred[indices], axis=0)\n",
    "    \n",
    "    return augmented_X, augmented_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded 21436\n",
      "stacked (21436, 50, 3)\n",
      "X: ['total_acc_x_train_50_50.csv', 'total_acc_y_train_50_50.csv', 'total_acc_z_train_50_50.csv']\n",
      "y: ../data/processed/train/state_train_50_50.csv\n",
      "(21436, 50, 3) (21436, 1)\n",
      "loaded 6030\n",
      "stacked (6030, 50, 3)\n",
      "X: ['total_acc_x_test_50_50.csv', 'total_acc_y_test_50_50.csv', 'total_acc_z_test_50_50.csv']\n",
      "y: ../data/processed/test/state_test_50_50.csv\n",
      "(6030, 50, 3) (6030, 1)\n",
      "(21436, 50, 3) (21436, 4) (6030, 50, 3) (6030, 4) (6030, 1)\n",
      "6030\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "split() missing 1 required positional argument: 'X'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-6d024408bbb5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0mfreq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'50'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0mwin\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'50'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m \u001b[0mpred_classes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_experiment\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfreq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwin\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-7-6d024408bbb5>\u001b[0m in \u001b[0;36mrun_experiment\u001b[0;34m(freq, win, repeats)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mKFold\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'test'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: split() missing 1 required positional argument: 'X'"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from keras.layers import Bidirectional\n",
    "from sklearn.model_selection import KFold\n",
    "from numpy import argmax\n",
    "import numpy as np\n",
    "\n",
    "# run an experiment\n",
    "def run_experiment(freq, win, repeats=1):\n",
    "    # load data\n",
    "    trainX, trainy, testX, testy, y_true = load_dataset(freq=freq, win=win, prefix='../data/processed/')\n",
    "    print(len(testX))\n",
    "    \n",
    "    # Partially train baseline model\n",
    "    verbose, epochs, batch_size = 1, 5, 10\n",
    "    n_timesteps, n_features, n_outputs = trainX.shape[1], trainX.shape[2], trainy.shape[1]\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(100, input_shape=(n_timesteps,n_features)))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(100, activation='relu'))\n",
    "    model.add(Dense(n_outputs, activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['categorical_accuracy'])\n",
    "    \n",
    "    scores = list()\n",
    "    for train, test in kf.split(trainX):\n",
    "        print('train', len(train))\n",
    "        print('test', len(test))\n",
    "#         y = np.argmax(trainy[test], axis=1, out=None)\n",
    "        model.fit(trainX[train], trainy[train], epochs=epochs, batch_size=batch_size, verbose=verbose)\n",
    "        _, accuracy = model.evaluate(testX, testy, batch_size=batch_size, verbose=1)\n",
    "        prediction = model.predict_classes(testX)\n",
    "        print('WITHOUT Pseudo-label')\n",
    "        print(classification_report(y_true, prediction))\n",
    "        print(confusion_matrix(y_true, prediction))\n",
    "        scores_wo.append(accuracy * 100.0)\n",
    "        print('Accuracy: %.3f' % accuracy)\n",
    "        \n",
    "        # With augmented training set\n",
    "        sample_rate = 0.2\n",
    "        augmented_X, augmented_y = create_augmented_train(model, trainX[train], trainy[train], trainX[test], sample_rate, target='state')\n",
    "        print('aug', len(augmented_X))\n",
    "        verbose, epochs, batch_size = 1, 5, 10\n",
    "        n_timesteps, n_features, n_outputs = trainX.shape[1], trainX.shape[2], trainy.shape[1]\n",
    "        model = Sequential()\n",
    "        model.add(LSTM(100, input_shape=(n_timesteps,n_features)))\n",
    "        model.add(Dropout(0.5))\n",
    "        model.add(Dense(100, activation='relu'))\n",
    "        model.add(Dense(n_outputs, activation='softmax'))\n",
    "        model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['categorical_accuracy'])\n",
    "\n",
    "        model.fit(augmented_X, augmented_y, epochs=epochs, batch_size=batch_size, verbose=verbose)\n",
    "        _, accuracy = model.evaluate(testX, testy, batch_size=batch_size, verbose=1)\n",
    "        prediction = model.predict_classes(testX)\n",
    "        print('WITH Pseudo-label')\n",
    "        print(classification_report(y_true, prediction))\n",
    "        print(confusion_matrix(y_true, prediction))\n",
    "        scores_wo.append(accuracy * 100.0)\n",
    "        print('Accuracy: %.3f' % accuracy)\n",
    "    return prediction, y_true\n",
    "\n",
    "# run the experiment\n",
    "freq = '50'\n",
    "win = '50'\n",
    "pred_classes, y_true = run_experiment(freq, win)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded 21436\n",
      "stacked (21436, 50, 3)\n",
      "X: ['total_acc_x_train_50_50.csv', 'total_acc_y_train_50_50.csv', 'total_acc_z_train_50_50.csv']\n",
      "y: ../data/processed/train/state_train_50_50.csv\n",
      "(21436, 50, 3) (21436, 1)\n",
      "loaded 6030\n",
      "stacked (6030, 50, 3)\n",
      "X: ['total_acc_x_test_50_50.csv', 'total_acc_y_test_50_50.csv', 'total_acc_z_test_50_50.csv']\n",
      "y: ../data/processed/test/state_test_50_50.csv\n",
      "(6030, 50, 3) (6030, 1)\n",
      "(21436, 50, 3) (21436, 4) (6030, 50, 3) (6030, 4) (6030, 1)\n",
      "6030\n",
      "[[0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " ...\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]]\n",
      "Train on 7500 samples, validate on 2500 samples\n",
      "Epoch 1/5\n",
      "7500/7500 [==============================] - 18s 2ms/step - loss: 2.0883 - categorical_accuracy: 0.4084 - val_loss: 2.5154 - val_categorical_accuracy: 0.3544\n",
      "Epoch 2/5\n",
      "7500/7500 [==============================] - 16s 2ms/step - loss: 2.0808 - categorical_accuracy: 0.4213 - val_loss: 2.5159 - val_categorical_accuracy: 0.3652\n",
      "Epoch 3/5\n",
      "7500/7500 [==============================] - 17s 2ms/step - loss: 2.0704 - categorical_accuracy: 0.4267 - val_loss: 2.4551 - val_categorical_accuracy: 0.1020\n",
      "Epoch 4/5\n",
      "7500/7500 [==============================] - 17s 2ms/step - loss: 2.0169 - categorical_accuracy: 0.4587 - val_loss: 2.2573 - val_categorical_accuracy: 0.4448\n",
      "Epoch 5/5\n",
      "7500/7500 [==============================] - 17s 2ms/step - loss: 1.4958 - categorical_accuracy: 0.6848 - val_loss: 1.6282 - val_categorical_accuracy: 0.7136\n",
      "6030/6030 [==============================] - 3s 493us/step\n",
      "BASELINE against test set\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.07      0.13      2566\n",
      "           1       0.49      0.96      0.65      2658\n",
      "           2       0.33      0.43      0.37       395\n",
      "           3       0.24      0.11      0.15       411\n",
      "\n",
      "   micro avg       0.49      0.49      0.49      6030\n",
      "   macro avg       0.50      0.39      0.33      6030\n",
      "weighted avg       0.66      0.49      0.38      6030\n",
      "\n",
      "[[ 184 2309   47   26]\n",
      " [   0 2543   98   17]\n",
      " [   9  122  169   95]\n",
      " [   2  172  193   44]]\n",
      "Accuracy: 0.488\n",
      "i: 0\n",
      "1000/1000 [==============================] - 1s 521us/step\n",
      "Non-augmented model against new training data\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.39      0.02      0.03       407\n",
      "           1       0.51      0.92      0.65       459\n",
      "           2       0.44      0.57      0.50        68\n",
      "           3       0.46      0.42      0.44        66\n",
      "\n",
      "   micro avg       0.49      0.49      0.49      1000\n",
      "   macro avg       0.45      0.48      0.41      1000\n",
      "weighted avg       0.45      0.49      0.38      1000\n",
      "\n",
      "[[  7 381   6  13]\n",
      " [ 10 421  23   5]\n",
      " [  0  14  39  15]\n",
      " [  1  16  21  28]]\n",
      "Accuracy: 0.495\n",
      "Augmented model against new training data\n",
      "1000/1000 [==============================] - 1s 574us/step\n",
      "1000/1000 [==============================] - 1s 526us/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.30      0.01      0.01       407\n",
      "           1       0.50      0.93      0.65       459\n",
      "           2       0.42      0.56      0.48        68\n",
      "           3       0.46      0.39      0.43        66\n",
      "\n",
      "   micro avg       0.49      0.49      0.49      1000\n",
      "   macro avg       0.42      0.47      0.39      1000\n",
      "weighted avg       0.41      0.49      0.37      1000\n",
      "\n",
      "[[  3 386   8  10]\n",
      " [  7 425  22   5]\n",
      " [  0  15  38  15]\n",
      " [  0  17  23  26]]\n",
      "Accuracy: 0.492\n",
      "Augmented model against test set\n",
      "3070/6030 [==============>...............] - ETA: 1s"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-cd2de89e0fd4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0mfreq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'50'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[0mwin\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'50'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m \u001b[0mpred_classes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_experiment\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfreq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwin\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-25-cd2de89e0fd4>\u001b[0m in \u001b[0;36mrun_experiment\u001b[0;34m(freq, win, repeats)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0;31m# Retrain with new data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Augmented model against test set'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtestX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtesty\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0mpred_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_classes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtestX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclassification_report\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/education/chair_sensor/ml_project/venv/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, x, y, batch_size, verbose, sample_weight, steps)\u001b[0m\n\u001b[1;32m   1111\u001b[0m                                          \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m                                          \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1113\u001b[0;31m                                          steps=steps)\n\u001b[0m\u001b[1;32m   1114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1115\u001b[0m     def predict(self, x,\n",
      "\u001b[0;32m~/education/chair_sensor/ml_project/venv/lib/python3.5/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mtest_loop\u001b[0;34m(model, f, ins, batch_size, verbose, steps)\u001b[0m\n\u001b[1;32m    390\u001b[0m                 \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    391\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 392\u001b[0;31m             \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    393\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    394\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mbatch_index\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/education/chair_sensor/ml_project/venv/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/education/chair_sensor/ml_project/venv/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/education/chair_sensor/ml_project/venv/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1439\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1440\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Pseudo-labeling without selective inclusion of samples\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from keras.layers import Bidirectional\n",
    "from sklearn.model_selection import KFold\n",
    "from numpy import argmax\n",
    "import numpy as np\n",
    "\n",
    "# run an experiment\n",
    "def run_experiment(freq, win, repeats=1):\n",
    "    baseline_margin = 10000\n",
    "    step_size = 1000\n",
    "    \n",
    "    # load data\n",
    "    trainX, trainy, testX, testy, y_true = load_dataset(freq=freq, win=win, prefix='../data/processed/')\n",
    "    print(len(testX))\n",
    "    \n",
    "    Xtrain = trainX[:baseline_margin]\n",
    "    ytrain = trainy[:baseline_margin]\n",
    "    \n",
    "    print(ytrain)\n",
    "    # evaluate model function\n",
    "    verbose, epochs, batch_size = 1, 5, 10\n",
    "    n_timesteps, n_features, n_outputs = trainX.shape[1], trainX.shape[2], trainy.shape[1]\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(100, input_shape=(n_timesteps,n_features)))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(100, activation='relu'))\n",
    "    model.add(Dense(n_outputs, activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['categorical_accuracy'])\n",
    "    model.fit(trainX[:baseline_margin], trainy[:baseline_margin], validation_split=0.25, class_weight={0: 1, 1: 1, 2: 4, 3: 4}, epochs=epochs, batch_size=batch_size, verbose=verbose)\n",
    "    _, accuracy = model.evaluate(testX, testy, batch_size=batch_size, verbose=1)\n",
    "    prediction = model.predict_classes(testX)\n",
    "    print('BASELINE against test set')\n",
    "    print(classification_report(y_true, prediction))\n",
    "    print(confusion_matrix(y_true, prediction))\n",
    "    print('Accuracy: %.3f' % accuracy)\n",
    "    \n",
    "    scores = list()\n",
    "    i = 0\n",
    "    while i < len(trainX):\n",
    "        print('i:', i)\n",
    "        \n",
    "        # Create pseudo-labeled training set\n",
    "        new_train_X = trainX[i:i+step_size]\n",
    "        y = np.argmax(trainy[i:i+step_size], axis=1, out=None)\n",
    "        _, accuracy = model.evaluate(trainX[i:i+step_size], trainy[i:i+step_size], batch_size=batch_size, verbose=1)\n",
    "        prediction = model.predict_classes(trainX[i:i+step_size])\n",
    "        print('Non-augmented model against new training data')\n",
    "        print(classification_report(y, prediction))\n",
    "        print(confusion_matrix(y, prediction))   \n",
    "        print('Accuracy: %.3f' % accuracy)\n",
    "        \n",
    "        # Retrain with new data\n",
    "        print('Augmented model against new training data')\n",
    "        y_cat = to_categorical(prediction, num_classes=4)\n",
    "        model.train_on_batch(new_train_X, y_cat, class_weight={0: 1, 1: 1, 2: 4, 3: 4})\n",
    "        _, accuracy = model.evaluate(new_train_X, trainy[i:i+step_size], batch_size=batch_size, verbose=1)\n",
    "        pred_aug = model.predict_classes(new_train_X, batch_size=batch_size, verbose=verbose)\n",
    "        print(classification_report(y, pred_aug))\n",
    "        print(confusion_matrix(y, pred_aug))\n",
    "        print('Accuracy: %.3f' % accuracy)\n",
    "        \n",
    "        # Retrain with new data\n",
    "        print('Augmented model against test set')\n",
    "        _, accuracy = model.evaluate(testX, testy, batch_size=batch_size, verbose=1)\n",
    "        pred_test = model.predict_classes(testX)\n",
    "        print(classification_report(y_true, pred_test))\n",
    "        print(confusion_matrix(y_true, pred_test))\n",
    "        print('Accuracy: %.3f' % accuracy)\n",
    "\n",
    "        i += step_size\n",
    "    return prediction, y_true\n",
    "\n",
    "# run the experiment\n",
    "freq = '50'\n",
    "win = '50'\n",
    "pred_classes, y_true = run_experiment(freq, win)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded 21436\n",
      "stacked (21436, 50, 3)\n",
      "X: ['total_acc_x_train_50_50.csv', 'total_acc_y_train_50_50.csv', 'total_acc_z_train_50_50.csv']\n",
      "y: ../data/processed/train/state_train_50_50.csv\n",
      "(21436, 50, 3) (21436, 1)\n",
      "loaded 6030\n",
      "stacked (6030, 50, 3)\n",
      "X: ['total_acc_x_test_50_50.csv', 'total_acc_y_test_50_50.csv', 'total_acc_z_test_50_50.csv']\n",
      "y: ../data/processed/test/state_test_50_50.csv\n",
      "(6030, 50, 3) (6030, 1)\n",
      "(21436, 50, 3) (21436, 4) (6030, 50, 3) (6030, 4) (6030, 1)\n",
      "6030\n",
      "Train on 13500 samples, validate on 4500 samples\n",
      "Epoch 1/15\n",
      "13500/13500 [==============================] - 42s 3ms/step - loss: 2.1732 - categorical_accuracy: 0.3350 - val_loss: 1.9480 - val_categorical_accuracy: 0.3802\n",
      "Epoch 2/15\n",
      "13500/13500 [==============================] - 45s 3ms/step - loss: 2.1593 - categorical_accuracy: 0.3664 - val_loss: 1.9412 - val_categorical_accuracy: 0.5909\n",
      "Epoch 3/15\n",
      "13500/13500 [==============================] - 55s 4ms/step - loss: 2.1519 - categorical_accuracy: 0.3737 - val_loss: 1.8604 - val_categorical_accuracy: 0.4353\n",
      "Epoch 4/15\n",
      "13500/13500 [==============================] - 47s 3ms/step - loss: 1.8314 - categorical_accuracy: 0.5388 - val_loss: 1.3568 - val_categorical_accuracy: 0.6520\n",
      "Epoch 5/15\n",
      "13500/13500 [==============================] - 51s 4ms/step - loss: 1.2928 - categorical_accuracy: 0.7479 - val_loss: 1.2554 - val_categorical_accuracy: 0.7282\n",
      "Epoch 6/15\n",
      "13500/13500 [==============================] - 43s 3ms/step - loss: 1.0913 - categorical_accuracy: 0.8119 - val_loss: 1.5089 - val_categorical_accuracy: 0.6240\n",
      "Epoch 7/15\n",
      "13500/13500 [==============================] - 49s 4ms/step - loss: 1.0560 - categorical_accuracy: 0.8068 - val_loss: 1.2199 - val_categorical_accuracy: 0.6518\n",
      "Epoch 8/15\n",
      "13500/13500 [==============================] - 52s 4ms/step - loss: 0.9467 - categorical_accuracy: 0.8328 - val_loss: 1.3309 - val_categorical_accuracy: 0.7780\n",
      "Epoch 9/15\n",
      "13500/13500 [==============================] - 52s 4ms/step - loss: 0.9389 - categorical_accuracy: 0.8297 - val_loss: 1.5047 - val_categorical_accuracy: 0.7624\n",
      "Epoch 10/15\n",
      "13500/13500 [==============================] - 41s 3ms/step - loss: 0.9520 - categorical_accuracy: 0.8241 - val_loss: 1.0272 - val_categorical_accuracy: 0.7771\n",
      "Epoch 11/15\n",
      "13500/13500 [==============================] - 43s 3ms/step - loss: 0.8712 - categorical_accuracy: 0.8396 - val_loss: 1.2362 - val_categorical_accuracy: 0.7873\n",
      "Epoch 12/15\n",
      "13500/13500 [==============================] - 57s 4ms/step - loss: 0.8164 - categorical_accuracy: 0.8492 - val_loss: 1.3220 - val_categorical_accuracy: 0.7544\n",
      "Epoch 13/15\n",
      "13500/13500 [==============================] - 54s 4ms/step - loss: 0.7904 - categorical_accuracy: 0.8549 - val_loss: 1.3697 - val_categorical_accuracy: 0.7593\n",
      "Epoch 14/15\n",
      "13500/13500 [==============================] - 54s 4ms/step - loss: 0.7761 - categorical_accuracy: 0.8541 - val_loss: 1.2975 - val_categorical_accuracy: 0.7496\n",
      "Epoch 15/15\n",
      "13500/13500 [==============================] - 52s 4ms/step - loss: 0.7722 - categorical_accuracy: 0.8548 - val_loss: 1.2381 - val_categorical_accuracy: 0.7682\n",
      "6030/6030 [==============================] - 5s 810us/step\n",
      "BASELINE against test set\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.73      0.84      2566\n",
      "           1       0.77      0.96      0.86      2658\n",
      "           2       0.50      0.67      0.57       395\n",
      "           3       0.61      0.49      0.54       411\n",
      "\n",
      "   micro avg       0.81      0.81      0.81      6030\n",
      "   macro avg       0.72      0.71      0.70      6030\n",
      "weighted avg       0.84      0.81      0.81      6030\n",
      "\n",
      "[[1875  561   66   64]\n",
      " [   0 2539   97   22]\n",
      " [  11   78  264   42]\n",
      " [   9  101  100  201]]\n",
      "Accuracy: 0.809\n",
      "i: 18000\n",
      "1500/1500 [==============================] - 1s 769us/step\n",
      "[[0.9628042  0.01204244 0.00179292 0.02336048]\n",
      " [0.9699649  0.01204919 0.00161226 0.01637357]\n",
      " [0.9728813  0.00936252 0.00127499 0.01648115]\n",
      " ...\n",
      " [0.96506816 0.01529012 0.00156333 0.0180784 ]\n",
      " [0.96789205 0.01516685 0.00145298 0.01548815]\n",
      " [0.97105736 0.0102575  0.00118026 0.01750482]]\n",
      "Non-augmented model against new training data\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.98      0.98       640\n",
      "           1       0.95      0.94      0.95       684\n",
      "           2       0.62      0.65      0.63        93\n",
      "           3       0.82      0.82      0.82        83\n",
      "\n",
      "   micro avg       0.93      0.93      0.93      1500\n",
      "   macro avg       0.84      0.85      0.84      1500\n",
      "weighted avg       0.93      0.93      0.93      1500\n",
      "\n",
      "[[625   0   8   7]\n",
      " [  7 645  26   6]\n",
      " [  1  30  60   2]\n",
      " [  6   6   3  68]]\n",
      "Accuracy: 0.932\n",
      "Augmented model against new training data\n",
      "Epoch 16/30\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 0.1716 - categorical_accuracy: 0.9793\n",
      "Epoch 17/30\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 0.1566 - categorical_accuracy: 0.9700\n",
      "Epoch 18/30\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 0.1238 - categorical_accuracy: 0.9773\n",
      "Epoch 19/30\n",
      "1500/1500 [==============================] - 2s 2ms/step - loss: 0.1207 - categorical_accuracy: 0.9813\n",
      "Epoch 20/30\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 0.1441 - categorical_accuracy: 0.9680\n",
      "Epoch 21/30\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 0.1125 - categorical_accuracy: 0.9747\n",
      "Epoch 22/30\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 0.0864 - categorical_accuracy: 0.9807\n",
      "Epoch 23/30\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 0.1030 - categorical_accuracy: 0.9760\n",
      "Epoch 24/30\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 0.0775 - categorical_accuracy: 0.9853\n",
      "Epoch 25/30\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.1282 - categorical_accuracy: 0.9680\n",
      "Epoch 26/30\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.0661 - categorical_accuracy: 0.9900\n",
      "Epoch 27/30\n",
      "1500/1500 [==============================] - 2s 2ms/step - loss: 0.0716 - categorical_accuracy: 0.9887\n",
      "Epoch 28/30\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.0826 - categorical_accuracy: 0.9853\n",
      "Epoch 29/30\n",
      "1500/1500 [==============================] - 2s 2ms/step - loss: 0.0801 - categorical_accuracy: 0.9833\n",
      "Epoch 30/30\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.0833 - categorical_accuracy: 0.9807\n",
      "1500/1500 [==============================] - 2s 1ms/step\n",
      "1500/1500 [==============================] - 2s 1ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.97      0.98       640\n",
      "           1       0.95      0.94      0.95       684\n",
      "           2       0.59      0.68      0.63        93\n",
      "           3       0.83      0.82      0.82        83\n",
      "\n",
      "   micro avg       0.93      0.93      0.93      1500\n",
      "   macro avg       0.84      0.85      0.85      1500\n",
      "weighted avg       0.94      0.93      0.93      1500\n",
      "\n",
      "[[624   0   8   8]\n",
      " [  4 644  32   4]\n",
      " [  1  27  63   2]\n",
      " [  7   4   4  68]]\n",
      "Accuracy: 0.933\n",
      "Augmented model against test set\n",
      "6030/6030 [==============================] - 7s 1ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.65      0.78      2566\n",
      "           1       0.71      0.83      0.77      2658\n",
      "           2       0.30      0.70      0.42       395\n",
      "           3       0.65      0.41      0.50       411\n",
      "\n",
      "   micro avg       0.72      0.72      0.72      6030\n",
      "   macro avg       0.66      0.65      0.62      6030\n",
      "weighted avg       0.79      0.72      0.73      6030\n",
      "\n",
      "[[1675  756   89   46]\n",
      " [   1 2215  419   23]\n",
      " [  25   72  278   20]\n",
      " [  11   85  147  168]]\n",
      "Accuracy: 0.719\n",
      "i: 19500\n",
      "1500/1500 [==============================] - 2s 1ms/step\n",
      "[[9.9914527e-01 5.9305859e-04 1.4768400e-05 2.4687420e-04]\n",
      " [9.9938190e-01 3.6144728e-04 1.5419550e-05 2.4126032e-04]\n",
      " [9.9938893e-01 3.7073097e-04 1.3664696e-05 2.2655740e-04]\n",
      " ...\n",
      " [6.0098831e-05 1.4079155e-01 8.5733509e-01 1.8132629e-03]\n",
      " [9.6175056e-05 4.0769521e-02 9.5692647e-01 2.2078324e-03]\n",
      " [7.0905364e-05 2.9478053e-02 9.6874565e-01 1.7053500e-03]]\n",
      "Non-augmented model against new training data\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.65      0.78       485\n",
      "           1       0.74      0.50      0.59       878\n",
      "           2       0.12      0.82      0.20        72\n",
      "           3       0.47      0.60      0.53        65\n",
      "\n",
      "   micro avg       0.57      0.57      0.57      1500\n",
      "   macro avg       0.58      0.64      0.53      1500\n",
      "weighted avg       0.78      0.57      0.63      1500\n",
      "\n",
      "[[315 141  23   6]\n",
      " [  0 437 408  33]\n",
      " [  1   7  59   5]\n",
      " [  3   6  17  39]]\n",
      "Accuracy: 0.567\n",
      "Augmented model against new training data\n",
      "Epoch 31/45\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1500/1500 [==============================] - 2s 2ms/step - loss: 0.4875 - categorical_accuracy: 0.9233\n",
      "Epoch 32/45\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 0.4525 - categorical_accuracy: 0.9127\n",
      "Epoch 33/45\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 0.3075 - categorical_accuracy: 0.9473\n",
      "Epoch 34/45\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 0.2927 - categorical_accuracy: 0.9587\n",
      "Epoch 35/45\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 0.2740 - categorical_accuracy: 0.9573\n",
      "Epoch 36/45\n",
      "1500/1500 [==============================] - 4s 2ms/step - loss: 0.2470 - categorical_accuracy: 0.9620\n",
      "Epoch 37/45\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 0.1975 - categorical_accuracy: 0.9707: 0s - loss: 0.1924 - categorical_ac\n",
      "Epoch 38/45\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 0.2081 - categorical_accuracy: 0.9627\n",
      "Epoch 39/45\n",
      "1500/1500 [==============================] - 2s 2ms/step - loss: 0.2244 - categorical_accuracy: 0.9680\n",
      "Epoch 40/45\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 0.1766 - categorical_accuracy: 0.9693\n",
      "Epoch 41/45\n",
      "1500/1500 [==============================] - 2s 2ms/step - loss: 0.1818 - categorical_accuracy: 0.9693\n",
      "Epoch 42/45\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 0.1820 - categorical_accuracy: 0.9700\n",
      "Epoch 43/45\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 0.1599 - categorical_accuracy: 0.9760\n",
      "Epoch 44/45\n",
      "1500/1500 [==============================] - 1s 971us/step - loss: 0.2257 - categorical_accuracy: 0.9647\n",
      "Epoch 45/45\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 0.1774 - categorical_accuracy: 0.9700\n",
      "1500/1500 [==============================] - 1s 782us/step\n",
      "1500/1500 [==============================] - 1s 546us/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.63      0.77       485\n",
      "           1       0.74      0.48      0.58       878\n",
      "           2       0.10      0.81      0.18        72\n",
      "           3       0.51      0.49      0.50        65\n",
      "\n",
      "   micro avg       0.54      0.54      0.54      1500\n",
      "   macro avg       0.58      0.60      0.51      1500\n",
      "weighted avg       0.78      0.54      0.62      1500\n",
      "\n",
      "[[307 136  37   5]\n",
      " [  1 419 438  20]\n",
      " [  1   7  58   6]\n",
      " [  4   5  24  32]]\n",
      "Accuracy: 0.544\n",
      "Augmented model against test set\n",
      "6030/6030 [==============================] - 4s 605us/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.70      0.82      2566\n",
      "           1       0.84      0.76      0.80      2658\n",
      "           2       0.19      0.73      0.30       395\n",
      "           3       0.68      0.41      0.51       411\n",
      "\n",
      "   micro avg       0.71      0.71      0.71      6030\n",
      "   macro avg       0.67      0.65      0.61      6030\n",
      "weighted avg       0.85      0.71      0.76      6030\n",
      "\n",
      "[[1794  244  476   52]\n",
      " [   0 2033  613   12]\n",
      " [  21   69  288   17]\n",
      " [  11   64  166  170]]\n",
      "Accuracy: 0.711\n",
      "i: 21000\n",
      "436/436 [==============================] - 0s 520us/step\n",
      "[[1.19313768e-06 1.16957189e-03 9.98713017e-01 1.16207375e-04]\n",
      " [4.03827971e-06 4.38223640e-03 9.94998336e-01 6.15374593e-04]\n",
      " [3.87397222e-06 5.35742845e-03 9.93135452e-01 1.50316709e-03]\n",
      " ...\n",
      " [1.42904037e-06 7.38952134e-04 9.99193609e-01 6.59500729e-05]\n",
      " [4.71741896e-06 6.75898977e-03 9.91783857e-01 1.45242596e-03]\n",
      " [6.76653508e-06 8.10190197e-03 9.87259865e-01 4.63152258e-03]]\n",
      "Non-augmented model against new training data\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.05      0.09       197\n",
      "           1       0.00      0.00      0.00       187\n",
      "           2       0.11      0.97      0.19        29\n",
      "           3       0.00      0.00      0.00        23\n",
      "\n",
      "   micro avg       0.08      0.08      0.08       436\n",
      "   macro avg       0.25      0.25      0.07       436\n",
      "weighted avg       0.41      0.08      0.05       436\n",
      "\n",
      "[[  9 153  33   2]\n",
      " [  0   0 176  11]\n",
      " [  1   0  28   0]\n",
      " [  0   0  23   0]]\n",
      "Accuracy: 0.085\n",
      "Augmented model against new training data\n",
      "Epoch 46/60\n",
      "436/436 [==============================] - 1s 1ms/step - loss: 0.2598 - categorical_accuracy: 0.9587\n",
      "Epoch 47/60\n",
      "436/436 [==============================] - 1s 1ms/step - loss: 0.3363 - categorical_accuracy: 0.9289\n",
      "Epoch 48/60\n",
      "436/436 [==============================] - 1s 1ms/step - loss: 0.4072 - categorical_accuracy: 0.9106\n",
      "Epoch 49/60\n",
      "436/436 [==============================] - 1s 1ms/step - loss: 0.5486 - categorical_accuracy: 0.9128\n",
      "Epoch 50/60\n",
      "436/436 [==============================] - 1s 1ms/step - loss: 0.4039 - categorical_accuracy: 0.8899\n",
      "Epoch 51/60\n",
      "436/436 [==============================] - 1s 2ms/step - loss: 0.3421 - categorical_accuracy: 0.9427\n",
      "Epoch 52/60\n",
      "436/436 [==============================] - 1s 2ms/step - loss: 0.2941 - categorical_accuracy: 0.9266\n",
      "Epoch 53/60\n",
      "436/436 [==============================] - 1s 1ms/step - loss: 0.2621 - categorical_accuracy: 0.9427\n",
      "Epoch 54/60\n",
      "436/436 [==============================] - 1s 2ms/step - loss: 0.2508 - categorical_accuracy: 0.9472\n",
      "Epoch 55/60\n",
      "436/436 [==============================] - 1s 2ms/step - loss: 0.2394 - categorical_accuracy: 0.9518\n",
      "Epoch 56/60\n",
      "436/436 [==============================] - 1s 1ms/step - loss: 0.1646 - categorical_accuracy: 0.9610\n",
      "Epoch 57/60\n",
      "436/436 [==============================] - 1s 2ms/step - loss: 0.3381 - categorical_accuracy: 0.9587\n",
      "Epoch 58/60\n",
      "436/436 [==============================] - 1s 2ms/step - loss: 0.3386 - categorical_accuracy: 0.9174\n",
      "Epoch 59/60\n",
      "436/436 [==============================] - 1s 2ms/step - loss: 0.2072 - categorical_accuracy: 0.9587\n",
      "Epoch 60/60\n",
      "436/436 [==============================] - 1s 2ms/step - loss: 0.1959 - categorical_accuracy: 0.9472\n",
      "436/436 [==============================] - 0s 975us/step\n",
      "436/436 [==============================] - 0s 811us/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.03      0.05       197\n",
      "           1       0.00      0.00      0.00       187\n",
      "           2       0.11      0.97      0.19        29\n",
      "           3       0.00      0.00      0.00        23\n",
      "\n",
      "   micro avg       0.08      0.08      0.08       436\n",
      "   macro avg       0.24      0.25      0.06       436\n",
      "weighted avg       0.38      0.08      0.04       436\n",
      "\n",
      "[[  5 157  33   2]\n",
      " [  0   0 177  10]\n",
      " [  1   0  28   0]\n",
      " [  0   0  23   0]]\n",
      "Accuracy: 0.076\n",
      "Augmented model against test set\n",
      "6030/6030 [==============================] - 5s 859us/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.52      0.68      2566\n",
      "           1       0.68      0.76      0.72      2658\n",
      "           2       0.20      0.74      0.32       395\n",
      "           3       0.68      0.40      0.50       411\n",
      "\n",
      "   micro avg       0.63      0.63      0.63      6030\n",
      "   macro avg       0.64      0.60      0.55      6030\n",
      "weighted avg       0.78      0.63      0.66      6030\n",
      "\n",
      "[[1329  824  363   50]\n",
      " [   0 2023  627    8]\n",
      " [  13   70  294   18]\n",
      " [   9   64  175  163]]\n",
      "Accuracy: 0.632\n"
     ]
    }
   ],
   "source": [
    "# Pseudo-labeling with selective inclusion of samples with highest probability\n",
    "# With separate validation set for during training\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from keras.layers import Bidirectional\n",
    "from sklearn.model_selection import KFold\n",
    "from numpy import argmax\n",
    "import numpy as np\n",
    "from keras.callbacks import History \n",
    "history = History()\n",
    "\n",
    "# run an experiment\n",
    "def run_experiment(freq, win, repeats=1):\n",
    "    baseline_margin = 18000\n",
    "    val_margin = 0\n",
    "    step_size = 1500\n",
    "    \n",
    "    # load data\n",
    "    trainX, trainy, testX, testy, y_true = load_dataset(freq=freq, win=win, prefix='../data/processed/')\n",
    "    print(len(testX))\n",
    "    \n",
    "    Xtrain = trainX[:baseline_margin]\n",
    "    ytrain = trainy[:baseline_margin]\n",
    "    \n",
    "    Xval = trainX[baseline_margin:baseline_margin+val_margin]\n",
    "    yval = trainy[baseline_margin:baseline_margin+val_margin]\n",
    "    \n",
    "    # evaluate model function\n",
    "    verbose, epochs, batch_size = 1, 15, 10\n",
    "    n_timesteps, n_features, n_outputs = trainX.shape[1], trainX.shape[2], trainy.shape[1]\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(100, input_shape=(n_timesteps,n_features)))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(100, activation='relu'))\n",
    "    model.add(Dense(n_outputs, activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['categorical_accuracy'])\n",
    "    model.fit(trainX[:baseline_margin], trainy[:baseline_margin], validation_split=0.25, class_weight={0: 1, 1: 1, 2: 4, 3: 4}, epochs=epochs, batch_size=batch_size, verbose=verbose, callbacks=[history])\n",
    "    _, accuracy = model.evaluate(testX, testy, batch_size=batch_size, verbose=1)\n",
    "    prediction = model.predict_classes(testX)\n",
    "    print('BASELINE against test set')\n",
    "    print(classification_report(y_true, prediction))\n",
    "    print(confusion_matrix(y_true, prediction))\n",
    "    print('Accuracy: %.3f' % accuracy)\n",
    "#     print('\\nHISTORY:', history.history)\n",
    "#     print('WEIGHTS:', len(model.get_weights()))\n",
    "    \n",
    "    scores = list()\n",
    "    i = baseline_margin + val_margin\n",
    "    cnt = 1\n",
    "    while i < len(trainX):\n",
    "        print('i:', i)\n",
    "        \n",
    "        # Create pseudo-labeled training set\n",
    "        new_train_X = trainX[i:i+step_size]\n",
    "        y = np.argmax(trainy[i:i+step_size], axis=1, out=None)\n",
    "        _, accuracy = model.evaluate(trainX[i:i+step_size], trainy[i:i+step_size], batch_size=batch_size, verbose=1)\n",
    "        prediction = model.predict_classes(trainX[i:i+step_size])\n",
    "        print(model.predict_proba(trainX[i:i+step_size]))\n",
    "        print('Non-augmented model against new training data')\n",
    "        print(classification_report(y, prediction))\n",
    "        print(confusion_matrix(y, prediction))   \n",
    "        print('Accuracy: %.3f' % accuracy)\n",
    "        \n",
    "        # Retrain with new data\n",
    "        print('Augmented model against new training data')\n",
    "        y_cat = to_categorical(prediction, num_classes=4)\n",
    "#        model.train_on_batch(new_train_X, y_cat, class_weight={0: 1, 1: 1, 2: 4, 3: 4})\n",
    "        model.fit(new_train_X, y_cat, class_weight={0: 1, 1: 1, 2: 4, 3: 4}, initial_epoch=epochs*cnt, epochs=epochs*cnt+epochs)\n",
    "#         print('\\nHISTORY:', history.history)\n",
    "#         print('WEIGHTS:', len(model.get_weights()))\n",
    "#        model.fit(new_train_X, y_cat, epocwhaths=epochs, class_weight={0: 1, 1: 1, 2: 4, 3: 4}, validation_data=(Xval, yval))\n",
    "        _, accuracy = model.evaluate(new_train_X, trainy[i:i+step_size], batch_size=batch_size, verbose=1)\n",
    "        pred_aug = model.predict_classes(new_train_X, batch_size=batch_size, verbose=verbose)\n",
    "        print(classification_report(y, pred_aug))\n",
    "        print(confusion_matrix(y, pred_aug))\n",
    "        print('Accuracy: %.3f' % accuracy)\n",
    "        \n",
    "        # Retrain with new data\n",
    "        print('Augmented model against test set')\n",
    "        _, accuracy = model.evaluate(testX, testy, batch_size=batch_size, verbose=1)\n",
    "        pred_test = model.predict_classes(testX)\n",
    "        print(classification_report(y_true, pred_test))\n",
    "        print(confusion_matrix(y_true, pred_test))\n",
    "        print('Accuracy: %.3f' % accuracy)\n",
    "\n",
    "        i += step_size\n",
    "        cnt += 1\n",
    "    return prediction, y_true\n",
    "\n",
    "# run the experiment\n",
    "freq = '50'\n",
    "win = '50'\n",
    "pred_classes, y_true = run_experiment(freq, win)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
