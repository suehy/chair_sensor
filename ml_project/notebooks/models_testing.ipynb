{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pandas import read_csv\n",
    "from sklearn.metrics import accuracy_score, balanced_accuracy_score, roc_auc_score, auc\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from numpy import argmax\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# start with linear classifiers, non-linear ones and eventually the more complex neural nets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load a single file as a numpy array\n",
    "# def load_file(filepath):\n",
    "#     dataframe = read_csv(filepath, header=None, delim_whitespace=True)\n",
    "#     return dataframe.values\n",
    "\n",
    "# load a dataset group, such as train or test\n",
    "# def load_dataset_group(group, prefix=''):\n",
    "#     # load input data\n",
    "#     X = load_file(prefix + group + '/X_'+group+'.txt')\n",
    "#     # load class output\n",
    "#     y = load_file(prefix + group + '/y_'+group+'.txt')\n",
    "#     return X, y\n",
    "\n",
    "# load the dataset, returns train and test X and y elements\n",
    "# def load_dataset(prefix=''):\n",
    "#     # load all train\n",
    "#     trainX, trainy = load_dataset_group('train', prefix + 'HARDataset/')\n",
    "#     print(trainX.shape, trainy.shape)\n",
    "#     # load all test\n",
    "#     testX, testy = load_dataset_group('test', prefix + 'HARDataset/')\n",
    "#     print(testX.shape, testy.shape)\n",
    "#     # flatten y\n",
    "#     trainy, testy = trainy[:,0], testy[:,0]\n",
    "#     print(trainX.shape, trainy.shape, testX.shape, testy.shape)\n",
    "#     return trainX, trainy, testX, testy\n",
    "\n",
    "# def load_dataset(prefix=''):\n",
    "#     # load all train\n",
    "#     train = load_dataset_group('train', prefix + 'HARDataset/')\n",
    "#     print(trainX.shape, trainy.shape)\n",
    "#     # load all test\n",
    "#     testX, testy = load_dataset_group('test', prefix + 'HARDataset/')\n",
    "#     print(testX.shape, testy.shape)\n",
    "#     # flatten y\n",
    "#     trainy, testy = trainy[:,0], testy[:,0]\n",
    "#     print(trainX.shape, trainy.shape, testX.shape, testy.shape)\n",
    "#     return trainX, trainy, testX, testy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path = '../data/processed/flori5hz.csv'\n",
    "# values = load_file(path)\n",
    "# #X, y = load_dataset_group()\n",
    "# values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('../data/processed/train.csv')\n",
    "\n",
    "test_df = pd.read_csv('../data/processed/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1207, 1)\n",
      "(1207,)\n"
     ]
    }
   ],
   "source": [
    "X_train = train_df.drop(['state', 'name'], axis=1)\n",
    "y_train = pd.DataFrame(train_df['state'])\n",
    "\n",
    "X_test = test_df.drop(['state', 'name'], axis=1)\n",
    "y_test = pd.DataFrame(test_df['state'])\n",
    "\n",
    "print(y_test.shape)\n",
    "print(test_df['state'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a dict of standard models to evaluate {name:object}\n",
    "def define_models(models=dict()):\n",
    "    # nonlinear models\n",
    "#     models['knn'] = KNeighborsClassifier()\n",
    "#     models['cart'] = DecisionTreeClassifier()\n",
    "#    models['cart'] = { 'clf': DecisionTreeClassifier(), 'params': {}}\n",
    "    #models['svm'] = SVC()\n",
    "#     models['bayes'] = GaussianNB()\n",
    "    # ensemble models\n",
    "#     models['bag'] = BaggingClassifier(n_estimators=100)\n",
    "    models['rf'] = RandomForestClassifier(n_estimators=100)\n",
    "#     models['et'] = ExtraTreesClassifier(n_estimators=100)\n",
    "    models['gbm'] = GradientBoostingClassifier(n_estimators=100)\n",
    "#     models['bag'] = BaggingClassifier()\n",
    "    #models['rf'] = { 'clf': RandomForestClassifier(n_jobs=-1), 'params': {'n_estimators': [100],\n",
    "#                                                                            'bootstrap': [False],\n",
    "#                                                                            'min_samples_split': [10, 20, 40, 50],\n",
    "#                                                                            'max_features': ['log2', 'sqrt','auto', None], \n",
    "#                                                                           'criterion': ['entropy', 'gini']}}\n",
    "#     models['et'] = ExtraTreesClassifier()\n",
    "#     models['gbm'] = GradientBoostingClassifier()\n",
    "    # sgd is sensitive to feature scaling\n",
    "    #models['sgd'] = SGDClassifier()\n",
    "    #models['gp'] = GaussianProcessClassifier()\n",
    "#     models['mlp'] = MLPClassifier()\n",
    "    print('Defined %d models' % len(models))\n",
    "    return models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defined 2 models\n"
     ]
    }
   ],
   "source": [
    "# get model list\n",
    "models = define_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate a single model\n",
    "def evaluate_model(trainX, trainy, testX, testy, model):\n",
    "    # fit the model\n",
    "    model.fit(trainX, trainy)\n",
    "    # make predictions\n",
    "    yhat = model.predict(testX)\n",
    "    # evaluate predictions\n",
    "    accuracy = balanced_accuracy_score(testy, yhat)\n",
    "    #roc_auc = roc_auc_score(testy, yhat)\n",
    "    \n",
    "    print(classification_report(testy, yhat))\n",
    "    print(confusion_matrix(testy, yhat))\n",
    "    return accuracy * 100.0\n",
    "    #return roc_auc * 100.0\n",
    "\n",
    "# evaluate a dict of models {name:object}, returns {name:score}\n",
    "def evaluate_models(trainX, trainy, testX, testy, models):\n",
    "    results = dict()\n",
    "    for name, model in models.items():\n",
    "        # evaluate the model\n",
    "        results[name] = evaluate_model(trainX, trainy, testX, testy, model)\n",
    "        # show process\n",
    "        print('>%s: %.3f' % (name, results[name]))\n",
    "    return results\n",
    "\n",
    "# print and plot the results\n",
    "def summarize_results(results, maximize=True):\n",
    "    # create a list of (name, mean(scores)) tuples\n",
    "    mean_scores = [(k,v) for k,v in results.items()]\n",
    "    # sort tuples by mean score\n",
    "    mean_scores = sorted(mean_scores, key=lambda x: x[1])\n",
    "    # reverse for descending order (e.g. for accuracy)\n",
    "    if maximize:\n",
    "        mean_scores = list(reversed(mean_scores))\n",
    "    print()\n",
    "    for name, score in mean_scores:\n",
    "        print('Name=%s, Score=%.3f' % (name, score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/elizabeth/education/chair_sensor/ml_project/venv/lib/python3.5/site-packages/ipykernel_launcher.py:4: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  after removing the cwd from sys.path.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.96      0.95       510\n",
      "           1       0.87      0.96      0.92       533\n",
      "           2       0.73      0.58      0.65        79\n",
      "           3       0.89      0.36      0.52        85\n",
      "\n",
      "    accuracy                           0.90      1207\n",
      "   macro avg       0.86      0.72      0.76      1207\n",
      "weighted avg       0.89      0.90      0.89      1207\n",
      "\n",
      "[[490  12   4   4]\n",
      " [ 16 514   3   0]\n",
      " [ 12  21  46   0]\n",
      " [  3  41  10  31]]\n",
      ">rf: 71.803\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/elizabeth/education/chair_sensor/ml_project/venv/lib/python3.5/site-packages/sklearn/ensemble/gradient_boosting.py:1450: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.93      0.94       510\n",
      "           1       0.86      0.97      0.91       533\n",
      "           2       0.69      0.59      0.64        79\n",
      "           3       0.83      0.41      0.55        85\n",
      "\n",
      "    accuracy                           0.89      1207\n",
      "   macro avg       0.83      0.73      0.76      1207\n",
      "weighted avg       0.88      0.89      0.88      1207\n",
      "\n",
      "[[472  23   9   6]\n",
      " [ 13 516   4   0]\n",
      " [ 12  19  47   1]\n",
      " [  1  41   8  35]]\n",
      ">gbm: 72.507\n"
     ]
    }
   ],
   "source": [
    "# evaluate models\n",
    "results = evaluate_models(X_train, y_train, X_test, y_test, models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Name=rf, Score=68.030\n"
     ]
    }
   ],
   "source": [
    "### summarize results\n",
    "summarize_results(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">rf\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "list indices must be integers or slices, not str",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-a03c9daba8d2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     51\u001b[0m         \u001b[0mrun_nested_logo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscorer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m \u001b[0mevaluate_tuned_models\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscorer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-8-a03c9daba8d2>\u001b[0m in \u001b[0;36mevaluate_tuned_models\u001b[0;34m(models, scorer)\u001b[0m\n\u001b[1;32m     48\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'>%s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m         \u001b[0mclf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'clf'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'params'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m         \u001b[0mrun_nested_logo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscorer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/education/chair_sensor/ml_project/venv/lib/python3.5/site-packages/sklearn/ensemble/base.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    142\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m         \u001b[0;34m\"\"\"Returns the index'th estimator in the ensemble.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 144\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimators_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    145\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__iter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: list indices must be integers or slices, not str"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import LeaveOneGroupOut\n",
    "from sklearn.metrics import make_scorer, balanced_accuracy_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from pandas import DataFrame\n",
    "import numpy as np\n",
    "\n",
    "all_df = train_df.append(test_df)\n",
    "all_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "X_all = all_df.drop(['state', 'name'], axis=1)\n",
    "y_all = all_df['state']\n",
    "\n",
    "groups = all_df['name']\n",
    "\n",
    "scorer = make_scorer(balanced_accuracy_score)\n",
    "\n",
    "outcomes = []\n",
    "\n",
    "def run_nested_logo(clf, params, scorer):\n",
    "    logo = LeaveOneGroupOut()\n",
    "    group = 0\n",
    "    \n",
    "    for train_index, test_index in logo.split(X_all, groups=groups):\n",
    "        group += 1\n",
    "        X_train, X_test = X_all.iloc[train_index], X_all.iloc[test_index]\n",
    "        y_train, y_test = y_all.iloc[train_index], y_all.iloc[test_index]\n",
    "        \n",
    "        inner_groups = all_df.iloc[all_df.index.isin(train_index)]['name']\n",
    "\n",
    "        logo = LeaveOneGroupOut()\n",
    "        grid_obj = GridSearchCV(clf, params, scoring=scorer, cv=logo.split(X_train, groups=inner_groups), n_jobs=-1)\n",
    "        grid_obj = grid_obj.fit(X_train, y_train)\n",
    "        \n",
    "        print(grid_obj.best_estimator_)\n",
    "        clf = grid_obj.best_estimator_\n",
    "\n",
    "        clf.fit(X_train, y_train)\n",
    "        predictions = clf.predict(X_test)\n",
    "        \n",
    "        accuracy = balanced_accuracy_score(y_test, predictions)\n",
    "        outcomes.append(accuracy)\n",
    "        print(\"Group {0} accuracy: {1}\".format(group, accuracy))\n",
    "    mean_outcome = np.mean(outcomes)\n",
    "    print(\"Mean Accuracy: {0}\".format(mean_outcome))\n",
    "    \n",
    "def evaluate_tuned_models(models, scorer):\n",
    "    results = dict()\n",
    "    for name, model in models.items():\n",
    "        print('>%s' % (name))\n",
    "        clf, params = model['clf'], model['params']\n",
    "        run_nested_logo(clf, params, scorer)\n",
    "\n",
    "evaluate_tuned_models(models, scorer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest\n",
    "\n",
    "# random_forest = RandomForestClassifier(n_estimators=100)\n",
    "# random_forest.fit(X_train, y_train)\n",
    "# y_pred = random_forest.predict(X_test)\n",
    "# y_pred\n",
    "# acc_random_forest = round(random_forest.score(X_test, y_test) * 100, 2)\n",
    "\n",
    "# cnt = 0\n",
    "# sitting = 0\n",
    "# standing = 0\n",
    "# for i in range(0, len(y_pred)):\n",
    "#     if not y_pred[i] == y_test[i]:\n",
    "#         cnt += 1\n",
    "#         if y_pred[i] == 1:\n",
    "#             sitting += 1\n",
    "#         else:\n",
    "#             standing += 1\n",
    "#         print('predicted', y_pred[i], 'actual', y_test[i])\n",
    "        \n",
    "# print('\\nTotal:', len(y_test))\n",
    "# print('Wrong:', cnt)\n",
    "# print('Accuracy:', acc_random_forest)\n",
    "# print('False positive:', sitting)\n",
    "# print('False negative:', standing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted'].",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31m_RemoteTraceback\u001b[0m                          Traceback (most recent call last)",
      "\u001b[0;31m_RemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"/home/elizabeth/education/chair_sensor/ml_project/venv/lib/python3.5/site-packages/joblib/externals/loky/process_executor.py\", line 418, in _process_worker\n    r = call_item()\n  File \"/home/elizabeth/education/chair_sensor/ml_project/venv/lib/python3.5/site-packages/joblib/externals/loky/process_executor.py\", line 272, in __call__\n    return self.fn(*self.args, **self.kwargs)\n  File \"/home/elizabeth/education/chair_sensor/ml_project/venv/lib/python3.5/site-packages/joblib/_parallel_backends.py\", line 567, in __call__\n    return self.func(*args, **kwargs)\n  File \"/home/elizabeth/education/chair_sensor/ml_project/venv/lib/python3.5/site-packages/joblib/parallel.py\", line 225, in __call__\n    for func, args, kwargs in self.items]\n  File \"/home/elizabeth/education/chair_sensor/ml_project/venv/lib/python3.5/site-packages/joblib/parallel.py\", line 225, in <listcomp>\n    for func, args, kwargs in self.items]\n  File \"/home/elizabeth/education/chair_sensor/ml_project/venv/lib/python3.5/site-packages/sklearn/model_selection/_validation.py\", line 554, in _fit_and_score\n    test_scores = _score(estimator, X_test, y_test, scorer, is_multimetric)\n  File \"/home/elizabeth/education/chair_sensor/ml_project/venv/lib/python3.5/site-packages/sklearn/model_selection/_validation.py\", line 597, in _score\n    return _multimetric_score(estimator, X_test, y_test, scorer)\n  File \"/home/elizabeth/education/chair_sensor/ml_project/venv/lib/python3.5/site-packages/sklearn/model_selection/_validation.py\", line 627, in _multimetric_score\n    score = scorer(estimator, X_test, y_test)\n  File \"/home/elizabeth/education/chair_sensor/ml_project/venv/lib/python3.5/site-packages/sklearn/metrics/scorer.py\", line 97, in __call__\n    **self._kwargs)\n  File \"/home/elizabeth/education/chair_sensor/ml_project/venv/lib/python3.5/site-packages/sklearn/metrics/classification.py\", line 1059, in f1_score\n    sample_weight=sample_weight)\n  File \"/home/elizabeth/education/chair_sensor/ml_project/venv/lib/python3.5/site-packages/sklearn/metrics/classification.py\", line 1182, in fbeta_score\n    sample_weight=sample_weight)\n  File \"/home/elizabeth/education/chair_sensor/ml_project/venv/lib/python3.5/site-packages/sklearn/metrics/classification.py\", line 1415, in precision_recall_fscore_support\n    pos_label)\n  File \"/home/elizabeth/education/chair_sensor/ml_project/venv/lib/python3.5/site-packages/sklearn/metrics/classification.py\", line 1254, in _check_set_wise_labels\n    % (y_type, average_options))\nValueError: Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted'].\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-76d95f3fcaae>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;31m# Run the grid search\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0mgrid_obj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'f1'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgroups\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m \u001b[0mgrid_obj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgrid_obj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;31m# Set the clf to the best combination of parameters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/education/chair_sensor/ml_project/venv/lib/python3.5/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    685\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    686\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 687\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    688\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    689\u001b[0m         \u001b[0;31m# For multi-metric evaluation, store the best_index_, best_params_ and\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/education/chair_sensor/ml_project/venv/lib/python3.5/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1146\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1147\u001b[0m         \u001b[0;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1148\u001b[0;31m         \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1149\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/education/chair_sensor/ml_project/venv/lib/python3.5/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params)\u001b[0m\n\u001b[1;32m    664\u001b[0m                                \u001b[0;32mfor\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    665\u001b[0m                                in product(candidate_params,\n\u001b[0;32m--> 666\u001b[0;31m                                           cv.split(X, y, groups)))\n\u001b[0m\u001b[1;32m    667\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    668\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/education/chair_sensor/ml_project/venv/lib/python3.5/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    932\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    933\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 934\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    935\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    936\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/education/chair_sensor/ml_project/venv/lib/python3.5/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    831\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    832\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 833\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    834\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    835\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/education/chair_sensor/ml_project/venv/lib/python3.5/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[0;34m(future, timeout)\u001b[0m\n\u001b[1;32m    519\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[1;32m    520\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    522\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mLokyTimeoutError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.5/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    403\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mCancelledError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    404\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mFINISHED\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 405\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    406\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    407\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.5/concurrent/futures/_base.py\u001b[0m in \u001b[0;36m__get_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    355\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 357\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    358\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    359\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted']."
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import make_scorer, balanced_accuracy_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import LeaveOneGroupOut\n",
    "\n",
    "X_train = train_df.drop(['state', 'name'], axis=1)\n",
    "y_train = train_df['state']\n",
    "X_test = test_df.drop(['state', 'name'], axis=1)\n",
    "y_test = test_df['state']\n",
    "\n",
    "groups = train_df['name']\n",
    "\n",
    "\n",
    "\n",
    "logo = LeaveOneGroupOut()\n",
    "\n",
    "# Choose the type of classifier. \n",
    "clf = RandomForestClassifier()\n",
    "\n",
    "# clf = GradientBoostingClassifier()\n",
    "\n",
    "depths = [2, 4, 8, 16, 32, 64, 80, 100]\n",
    "\n",
    "# Choose some parameter combinations to try\n",
    "# parameters = {'n_estimators': [100, 200],\n",
    "#               'bootstrap': [False],\n",
    "#               'min_samples_split': [10, 20, 40, 50],\n",
    "#                'max_features': ['log2', 'sqrt','auto', None], \n",
    "#                'criterion': ['entropy', 'gini']\n",
    "# #               'max_depth': depths\n",
    "#              }\n",
    "\n",
    "parameters = {'n_estimators': [100]}\n",
    "\n",
    "# Type of scoring used to compare parameter combinations\n",
    "acc_scorer = make_scorer(balanced_accuracy_score)\n",
    "\n",
    "# Run the grid search\n",
    "grid_obj = GridSearchCV(clf, parameters, scoring=acc_scorer, cv=logo.split(X_train, groups=groups), n_jobs=-1)\n",
    "grid_obj = grid_obj.fit(X_train, y_train)\n",
    "\n",
    "# Set the clf to the best combination of parameters\n",
    "clf = grid_obj.best_estimator_\n",
    "\n",
    "# Fit the best algorithm to the data. \n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "predictions = clf.predict(X_test)\n",
    "print(balanced_accuracy_score(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 100}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_obj.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bootstrap': False,\n",
       " 'criterion': 'gini',\n",
       " 'min_samples_split': 10,\n",
       " 'n_estimators': 200,\n",
       " 'warm_start': False}"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_obj.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=False, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=10,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=200, n_jobs=None,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_obj.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Group 1 accuracy: 0.74502341311965\n",
      "Group 2 accuracy: 0.7084465932863271\n",
      "Group 3 accuracy: 0.4614235167312559\n",
      "Group 4 accuracy: 0.5555467040971589\n",
      "Group 5 accuracy: 0.47061931938279433\n",
      "Group 6 accuracy: 0.8153399197516844\n",
      "Group 7 accuracy: 0.722132992651308\n",
      "Group 8 accuracy: 0.7543498168498168\n",
      "Mean Accuracy: 0.6541102844837494\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import LeaveOneGroupOut\n",
    "from pandas import DataFrame\n",
    "import numpy as np\n",
    "\n",
    "X_train = train_df.drop(['state', 'name'], axis=1)\n",
    "y_train = train_df['state']\n",
    "X_test = test_df.drop(['state', 'name'], axis=1)\n",
    "y_test = test_df['state']\n",
    "\n",
    "X_all = X_train.append(X_test)\n",
    "y_all = y_train.append(y_test)\n",
    "\n",
    "groups = train_df.append(test_df)['name']\n",
    "\n",
    "outcomes = []\n",
    "\n",
    "clf = RandomForestClassifier(criterion='gini',\n",
    "                             max_features=None,\n",
    "                             min_samples_split=5,\n",
    "                             n_estimators=100)\n",
    "\n",
    "clf = GradientBoostingClassifier(n_estimators=100)\n",
    "\n",
    "def run_logo(clf):\n",
    "    logo = LeaveOneGroupOut()\n",
    "    group = 0\n",
    "    \n",
    "    for train_index, test_index in logo.split(X_all, groups=groups):\n",
    "        group += 1\n",
    "        X_train, X_test = X_all.values[train_index], X_all.values[test_index]\n",
    "        y_train, y_test = y_all.values[train_index], y_all.values[test_index]\n",
    "        clf.fit(X_train, y_train)\n",
    "        predictions = clf.predict(X_test)\n",
    "        accuracy = balanced_accuracy_score(y_test, predictions)\n",
    "        outcomes.append(accuracy)\n",
    "        print(\"Group {0} accuracy: {1}\".format(group, accuracy))\n",
    "    mean_outcome = np.mean(outcomes)\n",
    "    print(\"Mean Accuracy: {0}\".format(mean_outcome)) \n",
    "\n",
    "run_logo(clf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing keras neural network models\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from numpy import dstack\n",
    "import numpy as np\n",
    "from pandas import read_csv\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from keras.utils import to_categorical\n",
    "from matplotlib import pyplot\n",
    "\n",
    "\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# load a single file as a numpy array\n",
    "def load_file(filepath):\n",
    "    dataframe = read_csv(filepath, header=None)\n",
    "    return dataframe.values\n",
    "\n",
    "# load a list of files and return as a 3d numpy array\n",
    "def load_group(filenames, prefix=''):\n",
    "    print(prefix)\n",
    "    loaded = list()\n",
    "    for name in filenames:\n",
    "        data = load_file(prefix + name)\n",
    "        loaded.append(data)\n",
    "    # stack group so that features are the 3rd dimension\n",
    "    #print('loaded', len(loaded[0]))\n",
    "    #print('loaded', loaded)\n",
    "    loaded = dstack(loaded)\n",
    "    #print('stacked', loaded.shape)\n",
    "    print('stacked', loaded)\n",
    "    return loaded\n",
    "\n",
    "# load a dataset group, such as train or test\n",
    "def load_dataset_group(group, freq, win, overlap, prefix=''):\n",
    "    filepath = prefix + '/'\n",
    "    print(filepath)\n",
    "    # load all 9 files as a single array\n",
    "    filenames = list()\n",
    "    # total acceleration\n",
    "    filenames += ['total_acc_x_'+group+'_'+freq+'_'+win+'_'+overlap+'.csv', 'total_acc_y_'+group+'_'+freq+'_'+win+'_'+overlap+'.csv', 'total_acc_z_'+group+'_'+freq+'_'+win+'_'+overlap+'.csv']\n",
    "#     # body acceleration\n",
    "#     filenames += ['body_acc_x_'+group+'_'+win+'_'+freq+'.csv', 'body_acc_y_'+group+'_'+win+'_'+freq+'.csv', 'body_acc_z_'+group+'_'+win+'_'+freq+'.csv']\n",
    "#     # body gyroscope\n",
    "#     filenames += ['body_gyro_x_'+group+'_'+win+'_'+freq+'.csv', 'body_gyro_y_'+group+'_'+win+'_'+freq+'.csv', 'body_gyro_z_'+group+'_'+win+'_'+freq+'.csv']\n",
    "    # load input data\n",
    "    X = load_group(filenames, filepath)\n",
    "    # load class output\n",
    "    y = load_file(prefix + '/state_'+group+'_'+freq+'_'+win+'_'+overlap+'.csv')\n",
    "    print('X:', filenames)\n",
    "    print('y:', prefix + '/state_'+group+'_'+freq+'_'+win+'_'+overlap+'.csv')\n",
    "    return X, y\n",
    "\n",
    "# load the dataset, returns train and test X and y elements\n",
    "def load_dataset(freq, win, overlap, prefix=''):\n",
    "    # load all train\n",
    "    trainX, trainy = load_dataset_group('train', freq, win, overlap, prefix)\n",
    "    print(trainX.shape, trainy.shape)\n",
    "    # load all test\n",
    "    #testX, testy = load_dataset_group('test', freq, win, prefix)\n",
    "    #print(testX.shape, testy.shape)\n",
    "\n",
    "    # one hot encode y\n",
    "    trainy = to_categorical(trainy)\n",
    "#     y_true = testy\n",
    "#     testy = to_categorical(testy)\n",
    "#     print(trainX.shape, trainy.shape, testX.shape, testy.shape)\n",
    "#     return trainX, trainy, testX, testy, y_true\n",
    "    return trainX, trainy\n",
    "\n",
    "# summarize scores\n",
    "def summarize_results(scores):\n",
    "    print(scores)\n",
    "    m, s = mean(scores), std(scores)\n",
    "    print('Accuracy: %.3f%% (+/-%.3f)' % (m, s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../data/processed/train/keras/done//\n",
      "../data/processed/train/keras/done//\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0919 12:24:02.680808 139704229000960 ag_logging.py:145] Entity <function standard_lstm at 0x7f0f0e940268> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: No module named 'tensorflow_core.contrib'\n",
      "W0919 12:24:02.782994 139704229000960 ag_logging.py:145] Entity <function cudnn_lstm at 0x7f0f0e9402f0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: No module named 'tensorflow_core.contrib'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stacked [[[-2.73437500e-02 -1.18164062e-01  9.96093750e-01]\n",
      "  [-2.63671875e-02 -1.14257812e-01  9.90234375e-01]\n",
      "  [-2.34375000e-02 -1.20117188e-01  9.95117188e-01]\n",
      "  ...\n",
      "  [-3.61328125e-02 -1.17187500e-01  9.83398438e-01]\n",
      "  [-2.34375000e-02 -1.16210938e-01  9.90234375e-01]\n",
      "  [-3.22265625e-02 -1.23046875e-01  9.89257812e-01]]\n",
      "\n",
      " [[-3.22265625e-02 -1.18164062e-01  9.90234375e-01]\n",
      "  [-2.14843750e-02 -1.19140625e-01  9.95117188e-01]\n",
      "  [-2.92968750e-02 -1.15234375e-01  9.84375000e-01]\n",
      "  ...\n",
      "  [-2.53906250e-02 -1.20117188e-01  9.88281250e-01]\n",
      "  [-3.12500000e-02 -1.11328125e-01  9.84375000e-01]\n",
      "  [-3.22265625e-02 -1.11328125e-01  9.93164062e-01]]\n",
      "\n",
      " [[-3.12500000e-02 -1.11328125e-01  9.87304688e-01]\n",
      "  [-3.51562500e-02 -1.21093750e-01  9.90234375e-01]\n",
      "  [-2.05078125e-02 -1.18164062e-01  9.94140625e-01]\n",
      "  ...\n",
      "  [-3.22265625e-02 -1.22070312e-01  9.91210938e-01]\n",
      "  [-3.12500000e-02 -1.18164062e-01  9.94140625e-01]\n",
      "  [-2.63671875e-02 -1.13281250e-01  9.86328125e-01]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[ 8.10546875e-02 -7.81250000e-03  9.85351562e-01]\n",
      "  [ 8.39843750e-02 -9.76562500e-04  1.00000000e+00]\n",
      "  [ 8.20312500e-02 -1.95312500e-03  9.93164062e-01]\n",
      "  ...\n",
      "  [ 8.39843750e-02  9.76562500e-04  9.91210938e-01]\n",
      "  [ 7.61718750e-02 -1.95312500e-03  9.88281250e-01]\n",
      "  [ 8.30078125e-02 -3.90625000e-03  9.94140625e-01]]\n",
      "\n",
      " [[ 8.00781250e-02 -9.76562500e-03  9.99023438e-01]\n",
      "  [ 7.42187500e-02 -3.90625000e-03  9.90234375e-01]\n",
      "  [ 7.22656250e-02 -8.78906250e-03  1.00585938e+00]\n",
      "  ...\n",
      "  [ 7.03125000e-02 -9.76562500e-03  9.95117188e-01]\n",
      "  [ 7.22656250e-02  9.76562500e-04  9.99023438e-01]\n",
      "  [ 8.20312500e-02 -3.90625000e-03  9.86328125e-01]]\n",
      "\n",
      " [[ 8.49609375e-02  0.00000000e+00  9.88281250e-01]\n",
      "  [ 7.03125000e-02 -1.36718750e-02  9.80468750e-01]\n",
      "  [ 8.39843750e-02 -6.83593750e-03  9.82421875e-01]\n",
      "  ...\n",
      "  [ 8.00781250e-02  0.00000000e+00  9.95117188e-01]\n",
      "  [ 8.20312500e-02 -1.17187500e-02  1.00390625e+00]\n",
      "  [ 8.39843750e-02 -7.81250000e-03  1.01074219e+00]]]\n",
      "X: ['total_acc_x_train_30_60_45.csv', 'total_acc_y_train_30_60_45.csv', 'total_acc_z_train_30_60_45.csv']\n",
      "y: ../data/processed/train/keras/done//state_train_30_60_45.csv\n",
      "(13741, 60, 3) (13741, 1)\n",
      "WARNING: Entity <function standard_lstm at 0x7f0f0e940268> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: No module named 'tensorflow_core.contrib'\n",
      "WARNING: Entity <function cudnn_lstm at 0x7f0f0e9402f0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: No module named 'tensorflow_core.contrib'\n",
      "Train on 13741 samples\n",
      "Epoch 1/75\n",
      "13741/13741 [==============================] - 22s 2ms/sample - loss: 1.1105 - categorical_accuracy: 0.4490\n",
      "Epoch 2/75\n",
      "13741/13741 [==============================] - 24s 2ms/sample - loss: 1.0875 - categorical_accuracy: 0.4943\n",
      "Epoch 3/75\n",
      "13741/13741 [==============================] - 25s 2ms/sample - loss: 0.9951 - categorical_accuracy: 0.6107\n",
      "Epoch 4/75\n",
      "13741/13741 [==============================] - 25s 2ms/sample - loss: 0.9348 - categorical_accuracy: 0.6576\n",
      "Epoch 5/75\n",
      "13741/13741 [==============================] - 26s 2ms/sample - loss: 0.8727 - categorical_accuracy: 0.6847\n",
      "Epoch 6/75\n",
      "13741/13741 [==============================] - 25s 2ms/sample - loss: 0.7768 - categorical_accuracy: 0.7156\n",
      "Epoch 7/75\n",
      "13741/13741 [==============================] - 25s 2ms/sample - loss: 0.6273 - categorical_accuracy: 0.7658\n",
      "Epoch 8/75\n",
      "13741/13741 [==============================] - 25s 2ms/sample - loss: 0.5543 - categorical_accuracy: 0.7980\n",
      "Epoch 9/75\n",
      "13741/13741 [==============================] - 25s 2ms/sample - loss: 0.4866 - categorical_accuracy: 0.8250\n",
      "Epoch 10/75\n",
      "13741/13741 [==============================] - 25s 2ms/sample - loss: 0.4364 - categorical_accuracy: 0.8444\n",
      "Epoch 11/75\n",
      "13741/13741 [==============================] - 25s 2ms/sample - loss: 0.4516 - categorical_accuracy: 0.8398\n",
      "Epoch 12/75\n",
      "13741/13741 [==============================] - 25s 2ms/sample - loss: 0.4017 - categorical_accuracy: 0.8596\n",
      "Epoch 13/75\n",
      "13741/13741 [==============================] - 25s 2ms/sample - loss: 0.3790 - categorical_accuracy: 0.8707\n",
      "Epoch 14/75\n",
      "13741/13741 [==============================] - 25s 2ms/sample - loss: 0.3670 - categorical_accuracy: 0.8702\n",
      "Epoch 15/75\n",
      "13741/13741 [==============================] - 26s 2ms/sample - loss: 0.3694 - categorical_accuracy: 0.8672\n",
      "Epoch 16/75\n",
      "13741/13741 [==============================] - 25s 2ms/sample - loss: 0.3458 - categorical_accuracy: 0.8808\n",
      "Epoch 17/75\n",
      "13741/13741 [==============================] - 25s 2ms/sample - loss: 0.3484 - categorical_accuracy: 0.8766\n",
      "Epoch 18/75\n",
      "13741/13741 [==============================] - 25s 2ms/sample - loss: 0.3362 - categorical_accuracy: 0.8831\n",
      "Epoch 19/75\n",
      "13741/13741 [==============================] - 25s 2ms/sample - loss: 0.3156 - categorical_accuracy: 0.8908\n",
      "Epoch 20/75\n",
      "13741/13741 [==============================] - 25s 2ms/sample - loss: 0.3185 - categorical_accuracy: 0.8888\n",
      "Epoch 21/75\n",
      "13741/13741 [==============================] - 25s 2ms/sample - loss: 0.2919 - categorical_accuracy: 0.8995\n",
      "Epoch 22/75\n",
      "13741/13741 [==============================] - 25s 2ms/sample - loss: 0.2957 - categorical_accuracy: 0.8967\n",
      "Epoch 23/75\n",
      "13741/13741 [==============================] - 26s 2ms/sample - loss: 0.2963 - categorical_accuracy: 0.8972\n",
      "Epoch 24/75\n",
      "13741/13741 [==============================] - 26s 2ms/sample - loss: 0.2841 - categorical_accuracy: 0.9009\n",
      "Epoch 25/75\n",
      "13741/13741 [==============================] - 26s 2ms/sample - loss: 0.2943 - categorical_accuracy: 0.8986\n",
      "Epoch 26/75\n",
      "13741/13741 [==============================] - 26s 2ms/sample - loss: 0.2655 - categorical_accuracy: 0.9067\n",
      "Epoch 27/75\n",
      "13741/13741 [==============================] - 26s 2ms/sample - loss: 0.2661 - categorical_accuracy: 0.9084\n",
      "Epoch 28/75\n",
      "13741/13741 [==============================] - 26s 2ms/sample - loss: 0.2543 - categorical_accuracy: 0.9116\n",
      "Epoch 29/75\n",
      "13741/13741 [==============================] - 26s 2ms/sample - loss: 0.2538 - categorical_accuracy: 0.9114\n",
      "Epoch 30/75\n",
      "13741/13741 [==============================] - 26s 2ms/sample - loss: 0.2471 - categorical_accuracy: 0.9159\n",
      "Epoch 31/75\n",
      "13741/13741 [==============================] - 26s 2ms/sample - loss: 0.2619 - categorical_accuracy: 0.9071\n",
      "Epoch 32/75\n",
      "13741/13741 [==============================] - 26s 2ms/sample - loss: 0.2559 - categorical_accuracy: 0.9118\n",
      "Epoch 33/75\n",
      "13741/13741 [==============================] - 26s 2ms/sample - loss: 0.2392 - categorical_accuracy: 0.9183\n",
      "Epoch 34/75\n",
      "13741/13741 [==============================] - 27s 2ms/sample - loss: 0.2575 - categorical_accuracy: 0.9114\n",
      "Epoch 35/75\n",
      "13741/13741 [==============================] - 26s 2ms/sample - loss: 0.2330 - categorical_accuracy: 0.9179\n",
      "Epoch 36/75\n",
      "13741/13741 [==============================] - 26s 2ms/sample - loss: 0.2437 - categorical_accuracy: 0.9161\n",
      "Epoch 37/75\n",
      "13741/13741 [==============================] - 26s 2ms/sample - loss: 0.2627 - categorical_accuracy: 0.9092\n",
      "Epoch 38/75\n",
      "13741/13741 [==============================] - 26s 2ms/sample - loss: 0.2219 - categorical_accuracy: 0.9231\n",
      "Epoch 39/75\n",
      "13741/13741 [==============================] - 26s 2ms/sample - loss: 0.2236 - categorical_accuracy: 0.9198\n",
      "Epoch 40/75\n",
      "13741/13741 [==============================] - 26s 2ms/sample - loss: 0.2261 - categorical_accuracy: 0.9213\n",
      "Epoch 41/75\n",
      "13741/13741 [==============================] - 26s 2ms/sample - loss: 0.2111 - categorical_accuracy: 0.9253\n",
      "Epoch 42/75\n",
      "13741/13741 [==============================] - 26s 2ms/sample - loss: 0.2167 - categorical_accuracy: 0.9236\n",
      "Epoch 43/75\n",
      "13741/13741 [==============================] - 26s 2ms/sample - loss: 0.2095 - categorical_accuracy: 0.9274\n",
      "Epoch 44/75\n",
      "13741/13741 [==============================] - 26s 2ms/sample - loss: 0.2148 - categorical_accuracy: 0.9254\n",
      "Epoch 45/75\n",
      "13741/13741 [==============================] - 26s 2ms/sample - loss: 0.2170 - categorical_accuracy: 0.9258\n",
      "Epoch 46/75\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13741/13741 [==============================] - 21s 2ms/sample - loss: 0.1999 - categorical_accuracy: 0.9285\n",
      "Epoch 47/75\n",
      "13741/13741 [==============================] - 21s 1ms/sample - loss: 0.2083 - categorical_accuracy: 0.9276\n",
      "Epoch 48/75\n",
      "13741/13741 [==============================] - 20s 1ms/sample - loss: 0.2042 - categorical_accuracy: 0.9255\n",
      "Epoch 49/75\n",
      "13741/13741 [==============================] - 21s 2ms/sample - loss: 0.1981 - categorical_accuracy: 0.9322\n",
      "Epoch 50/75\n",
      "13741/13741 [==============================] - 20s 1ms/sample - loss: 0.1977 - categorical_accuracy: 0.9314\n",
      "Epoch 51/75\n",
      "13741/13741 [==============================] - 20s 1ms/sample - loss: 0.2060 - categorical_accuracy: 0.9283\n",
      "Epoch 52/75\n",
      "13741/13741 [==============================] - 21s 1ms/sample - loss: 0.1956 - categorical_accuracy: 0.9312\n",
      "Epoch 53/75\n",
      "13741/13741 [==============================] - 21s 1ms/sample - loss: 0.1831 - categorical_accuracy: 0.9343\n",
      "Epoch 54/75\n",
      "13741/13741 [==============================] - 21s 1ms/sample - loss: 0.1845 - categorical_accuracy: 0.9354\n",
      "Epoch 55/75\n",
      "13741/13741 [==============================] - 21s 2ms/sample - loss: 0.2017 - categorical_accuracy: 0.9300\n",
      "Epoch 56/75\n",
      "13741/13741 [==============================] - 20s 1ms/sample - loss: 0.2047 - categorical_accuracy: 0.9261\n",
      "Epoch 57/75\n",
      "13741/13741 [==============================] - 21s 1ms/sample - loss: 0.1780 - categorical_accuracy: 0.9380\n",
      "Epoch 58/75\n",
      "13741/13741 [==============================] - 20s 1ms/sample - loss: 0.1768 - categorical_accuracy: 0.9368\n",
      "Epoch 59/75\n",
      "13741/13741 [==============================] - 20s 1ms/sample - loss: 0.1839 - categorical_accuracy: 0.9356\n",
      "Epoch 60/75\n",
      "13741/13741 [==============================] - 20s 1ms/sample - loss: 0.1770 - categorical_accuracy: 0.9389\n",
      "Epoch 61/75\n",
      "13741/13741 [==============================] - 20s 1ms/sample - loss: 0.1817 - categorical_accuracy: 0.9360\n",
      "Epoch 62/75\n",
      "13741/13741 [==============================] - 20s 1ms/sample - loss: 0.1810 - categorical_accuracy: 0.9367\n",
      "Epoch 63/75\n",
      "13741/13741 [==============================] - 20s 1ms/sample - loss: 0.1692 - categorical_accuracy: 0.9408\n",
      "Epoch 64/75\n",
      "13741/13741 [==============================] - 21s 1ms/sample - loss: 0.1835 - categorical_accuracy: 0.9360\n",
      "Epoch 65/75\n",
      "13741/13741 [==============================] - 21s 2ms/sample - loss: 0.1704 - categorical_accuracy: 0.9393\n",
      "Epoch 66/75\n",
      "13741/13741 [==============================] - 22s 2ms/sample - loss: 0.1744 - categorical_accuracy: 0.9399\n",
      "Epoch 67/75\n",
      "13741/13741 [==============================] - 21s 2ms/sample - loss: 0.1693 - categorical_accuracy: 0.9414\n",
      "Epoch 68/75\n",
      "13741/13741 [==============================] - 21s 2ms/sample - loss: 0.1677 - categorical_accuracy: 0.9427\n",
      "Epoch 69/75\n",
      "13741/13741 [==============================] - 21s 2ms/sample - loss: 0.1682 - categorical_accuracy: 0.9421\n",
      "Epoch 70/75\n",
      "13741/13741 [==============================] - 21s 2ms/sample - loss: 0.1597 - categorical_accuracy: 0.9447\n",
      "Epoch 71/75\n",
      "13741/13741 [==============================] - 21s 2ms/sample - loss: 0.1640 - categorical_accuracy: 0.9419\n",
      "Epoch 72/75\n",
      "13741/13741 [==============================] - 21s 2ms/sample - loss: 0.1580 - categorical_accuracy: 0.9467\n",
      "Epoch 73/75\n",
      "13741/13741 [==============================] - 21s 2ms/sample - loss: 0.1609 - categorical_accuracy: 0.9426\n",
      "Epoch 74/75\n",
      "13741/13741 [==============================] - 21s 2ms/sample - loss: 0.1569 - categorical_accuracy: 0.9461\n",
      "Epoch 75/75\n",
      "13741/13741 [==============================] - 21s 2ms/sample - loss: 0.1576 - categorical_accuracy: 0.9449\n"
     ]
    }
   ],
   "source": [
    "# lstm model\n",
    "# from sklearn.metrics import confusion_matrix\n",
    "from keras.layers import Bidirectional\n",
    "\n",
    "# fit and evaluate a model\n",
    "def evaluate_model(trainX, trainy):\n",
    "    verbose, epochs, batch_size = 1, 75, 32\n",
    "    n_timesteps, n_features, n_outputs = trainX.shape[1], trainX.shape[2], trainy.shape[1]\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(150, input_shape=(n_timesteps,n_features)))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(150, activation='relu'))\n",
    "    model.add(Dense(n_outputs, activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['categorical_accuracy'])\n",
    "    # fit network\n",
    "#     model.fit(trainX, trainy, validation_split=0.2, epochs=epochs, batch_size=batch_size, verbose=verbose)\n",
    "    model.fit(trainX, trainy, epochs=epochs, batch_size=batch_size, verbose=verbose)\n",
    "    # evaluate model\n",
    "#     _, accuracy = model.evaluate(testX, testy, batch_size=batch_size, verbose=1)\n",
    "#     prediction = model.predict_classes(testX)\n",
    "    return model\n",
    "\n",
    "# run an experiment\n",
    "def run_experiment(freq, win, overlap, source, repeats=1):\n",
    "    # load data\n",
    "    trainX, trainy = load_dataset(freq=freq, win=win, overlap=overlap, prefix=source)\n",
    "\n",
    "    model = evaluate_model(trainX, trainy)\n",
    "#     print(classification_report(y_true, pred_classes))\n",
    "#     print(confusion_matrix(y_true, pred_classes))\n",
    "    # summarize results\n",
    "#     summarize_results(scores)\n",
    "    return model\n",
    "\n",
    "# run the experiment \n",
    "freq = '30'\n",
    "win = '60'\n",
    "overlap = '45'\n",
    "source = '../data/processed/train/keras/done/'\n",
    "model = run_experiment(freq, win, overlap, source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to disk\n",
      "Loaded model from disk\n"
     ]
    }
   ],
   "source": [
    "## Save model to model.h5\n",
    "\n",
    "from tensorflow.keras.models import model_from_json\n",
    "import os\n",
    "\n",
    "# Saving model\n",
    "# serialize model to JSON\n",
    "model_json = model.to_json()\n",
    "with open(\"model.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "# serialize weights to HDF5\n",
    "model.save_weights(\"model.h5\")\n",
    "print(\"Saved model to disk\")\n",
    "\n",
    "# Loading model\n",
    "json_file = open('model.json', 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "loaded_model = model_from_json(loaded_model_json)\n",
    "# load weights into new model\n",
    "loaded_model.load_weights(\"model.h5\")\n",
    "print(\"Loaded model from disk\")\n",
    "\n",
    "# # evaluate loaded model on test data\n",
    "# loaded_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['categorical_accuracy'])\n",
    "# #loaded_model.compile(loss='binary_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
    "# # score = loaded_model.evaluate(X, Y, verbose=0)\n",
    "# # print(\"%s: %.2f%%\" % (loaded_model.metrics_names[1], score[1]*100))\n",
    "\n",
    "# _, accuracy = model.evaluate(testX, testy, batch_size=1, verbose=1)\n",
    "# print('>#%d: %.3f' % (1, accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to disk\n"
     ]
    }
   ],
   "source": [
    "# save model and architecture to single file\n",
    "model.save(\"model.h5\")\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/elizabeth/fun/ml_examples/keras_examples/venv/lib/python3.5/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /home/elizabeth/fun/ml_examples/keras_examples/venv/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From /home/elizabeth/fun/ml_examples/keras_examples/venv/lib/python3.5/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "model = load_model('model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named 'tensorflowjs'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-686419c4aa76>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Save model in tfjs layer format\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflowjs\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtfjs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mtfjs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverters\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_keras_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"./\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: No module named 'tensorflowjs'"
     ]
    }
   ],
   "source": [
    "# # Save model in tfjs layer format\n",
    "# import tensorflowjs as tfjs\n",
    "\n",
    "# tfjs.converters.save_keras_model(model, \"./\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded 22952\n",
      "stacked (22952, 50, 3)\n",
      "X: ['total_acc_x_train_50_50.csv', 'total_acc_y_train_50_50.csv', 'total_acc_z_train_50_50.csv']\n",
      "y: ../data/processed/train/state_train_50_50.csv\n",
      "(22952, 50, 3) (22952, 1)\n",
      "loaded 4514\n",
      "stacked (4514, 50, 3)\n",
      "X: ['total_acc_x_test_50_50.csv', 'total_acc_y_test_50_50.csv', 'total_acc_z_test_50_50.csv']\n",
      "y: ../data/processed/test/state_test_50_50.csv\n",
      "(4514, 50, 3) (4514, 1)\n",
      "(22952, 50, 3) (22952, 4) (4514, 50, 3) (4514, 4)\n",
      "Epoch 1/15\n",
      "22952/22952 [==============================] - 44s 2ms/step - loss: 0.6862 - categorical_accuracy: 0.7197\n",
      "Epoch 2/15\n",
      "22952/22952 [==============================] - 42s 2ms/step - loss: 0.3934 - categorical_accuracy: 0.8586\n",
      "Epoch 3/15\n",
      "22952/22952 [==============================] - 42s 2ms/step - loss: 0.3613 - categorical_accuracy: 0.8688\n",
      "Epoch 4/15\n",
      "22952/22952 [==============================] - 42s 2ms/step - loss: 0.3318 - categorical_accuracy: 0.8788\n",
      "Epoch 5/15\n",
      "22952/22952 [==============================] - 42s 2ms/step - loss: 0.3141 - categorical_accuracy: 0.8867\n",
      "Epoch 6/15\n",
      "22952/22952 [==============================] - 42s 2ms/step - loss: 0.3054 - categorical_accuracy: 0.8896\n",
      "Epoch 7/15\n",
      "22952/22952 [==============================] - 42s 2ms/step - loss: 0.2918 - categorical_accuracy: 0.8946\n",
      "Epoch 8/15\n",
      "22952/22952 [==============================] - 42s 2ms/step - loss: 0.2816 - categorical_accuracy: 0.8973\n",
      "Epoch 9/15\n",
      "22952/22952 [==============================] - 42s 2ms/step - loss: 0.2674 - categorical_accuracy: 0.9041\n",
      "Epoch 10/15\n",
      "22952/22952 [==============================] - 42s 2ms/step - loss: 0.2626 - categorical_accuracy: 0.9047\n",
      "Epoch 11/15\n",
      "22952/22952 [==============================] - 42s 2ms/step - loss: 0.2635 - categorical_accuracy: 0.9058\n",
      "Epoch 12/15\n",
      "22952/22952 [==============================] - 42s 2ms/step - loss: 0.2460 - categorical_accuracy: 0.9111\n",
      "Epoch 13/15\n",
      "22952/22952 [==============================] - 42s 2ms/step - loss: 0.2412 - categorical_accuracy: 0.9122\n",
      "Epoch 14/15\n",
      "22952/22952 [==============================] - 44s 2ms/step - loss: 0.2427 - categorical_accuracy: 0.9132\n",
      "Epoch 15/15\n",
      "22952/22952 [==============================] - 43s 2ms/step - loss: 0.2319 - categorical_accuracy: 0.9146\n",
      "4514/4514 [==============================] - 2s 452us/step\n",
      ">#1: 88.901\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.96      0.93      1677\n",
      "           1       0.92      0.95      0.93      1980\n",
      "           2       0.73      0.55      0.63       401\n",
      "           3       0.81      0.66      0.73       456\n",
      "\n",
      "   micro avg       0.89      0.89      0.89      4514\n",
      "   macro avg       0.84      0.78      0.80      4514\n",
      "weighted avg       0.88      0.89      0.88      4514\n",
      "\n",
      "[[1609   24   27   17]\n",
      " [  49 1883   20   28]\n",
      " [  63   92  221   25]\n",
      " [  68   52   36  300]]\n",
      "[88.90119611946258]\n",
      "Accuracy: 88.901% (+/-0.000)\n"
     ]
    }
   ],
   "source": [
    "# cnn-lstm model\n",
    "\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from numpy import dstack\n",
    "from pandas import read_csv\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import TimeDistributed\n",
    "from keras.layers.convolutional import Conv1D\n",
    "from keras.layers.convolutional import MaxPooling1D\n",
    "from keras.utils import to_categorical\n",
    "from matplotlib import pyplot\n",
    "\n",
    "# fit and evaluate a model\n",
    "def evaluate_model(trainX, trainy, testX, testy):\n",
    "    # define model\n",
    "    verbose, epochs, batch_size = 1, 15, 10\n",
    "    n_timesteps, n_features, n_outputs = trainX.shape[1], trainX.shape[2], trainy.shape[1]\n",
    "    \n",
    "    #splitting windows into blocks because cnn learns features from the blocks,\n",
    "    #and the window timesteps have dependencies we want to learn\n",
    "    # reshape data into time steps of sub-sequences\n",
    "    n_steps, n_length = 1, 50\n",
    "    trainX = trainX.reshape((trainX.shape[0], n_steps, n_length, n_features))\n",
    "    testX = testX.reshape((testX.shape[0], n_steps, n_length, n_features))\n",
    "    # define model\n",
    "    model = Sequential()\n",
    "    model.add(TimeDistributed(Conv1D(filters=64, kernel_size=3, activation='relu'), input_shape=(None,n_length,n_features)))\n",
    "    model.add(TimeDistributed(Conv1D(filters=64, kernel_size=3, activation='relu')))\n",
    "    model.add(TimeDistributed(Dropout(0.5)))\n",
    "    model.add(TimeDistributed(MaxPooling1D(pool_size=2)))\n",
    "    model.add(TimeDistributed(Flatten()))\n",
    "    model.add(LSTM(100))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(100, activation='relu'))\n",
    "    model.add(Dense(n_outputs, activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['categorical_accuracy'])\n",
    "    # fit network\n",
    "    model.fit(trainX, trainy, epochs=epochs, batch_size=batch_size, verbose=verbose)\n",
    "    # evaluate model\n",
    "    _, accuracy = model.evaluate(testX, testy, batch_size=batch_size, verbose=1)\n",
    "    prediction = model.predict_classes(testX)\n",
    "    return prediction, accuracy\n",
    "\n",
    "# run an experiment\n",
    "def run_experiment(freq, win, repeats=1):\n",
    "    # load data\n",
    "    trainX, trainy, testX, testy, y_true = load_dataset(freq=freq, win=win, prefix='../data/processed/')\n",
    "#     score = evaluate_model(trainX, trainy, testX, testy)\n",
    "#     print(score)\n",
    "    # repeat experiment\n",
    "    scores = list()\n",
    "    for r in range(repeats):\n",
    "        pred_classes, score = evaluate_model(trainX, trainy, testX, testy)\n",
    "        score = score * 100.0\n",
    "        print('>#%d: %.3f' % (r+1, score))\n",
    "        scores.append(score)\n",
    "        print(classification_report(y_true, pred_classes))\n",
    "        print(confusion_matrix(y_true, pred_classes))\n",
    "    # summarize results\n",
    "    summarize_results(scores)\n",
    "\n",
    "# run the experiment\n",
    "freq = '50'\n",
    "win = '50'\n",
    "run_experiment(freq, win)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded 9182\n",
      "stacked (9182, 50, 3)\n",
      "X: ['total_acc_x_train_50_50.csv', 'total_acc_y_train_50_50.csv', 'total_acc_z_train_50_50.csv']\n",
      "y: ../data/processed/train/state_train_50_50.csv\n",
      "(9182, 50, 3) (9182, 1)\n",
      "loaded 1806\n",
      "stacked (1806, 50, 3)\n",
      "X: ['total_acc_x_test_50_50.csv', 'total_acc_y_test_50_50.csv', 'total_acc_z_test_50_50.csv']\n",
      "y: ../data/processed/test/state_test_50_50.csv\n",
      "(1806, 50, 3) (1806, 1)\n",
      "(9182, 50, 3) (9182, 4) (1806, 50, 3) (1806, 4)\n",
      "Epoch 1/15\n",
      "9182/9182 [==============================] - 11s 1ms/step - loss: 1.1147 - categorical_accuracy: 0.4720\n",
      "Epoch 2/15\n",
      "9182/9182 [==============================] - 10s 1ms/step - loss: 0.7306 - categorical_accuracy: 0.7487\n",
      "Epoch 3/15\n",
      "9182/9182 [==============================] - 10s 1ms/step - loss: 0.5211 - categorical_accuracy: 0.8093\n",
      "Epoch 4/15\n",
      "9182/9182 [==============================] - 10s 1ms/step - loss: 0.4582 - categorical_accuracy: 0.8404\n",
      "Epoch 5/15\n",
      "9182/9182 [==============================] - 10s 1ms/step - loss: 0.4269 - categorical_accuracy: 0.8561\n",
      "Epoch 6/15\n",
      "9182/9182 [==============================] - 10s 1ms/step - loss: 0.4006 - categorical_accuracy: 0.8607\n",
      "Epoch 7/15\n",
      "9182/9182 [==============================] - 10s 1ms/step - loss: 0.3790 - categorical_accuracy: 0.8684\n",
      "Epoch 8/15\n",
      "9182/9182 [==============================] - 10s 1ms/step - loss: 0.3704 - categorical_accuracy: 0.8702\n",
      "Epoch 9/15\n",
      "9182/9182 [==============================] - 10s 1ms/step - loss: 0.3565 - categorical_accuracy: 0.8780\n",
      "Epoch 10/15\n",
      "9182/9182 [==============================] - 10s 1ms/step - loss: 0.3456 - categorical_accuracy: 0.8801\n",
      "Epoch 11/15\n",
      "9182/9182 [==============================] - 10s 1ms/step - loss: 0.3338 - categorical_accuracy: 0.8795\n",
      "Epoch 12/15\n",
      "9182/9182 [==============================] - 10s 1ms/step - loss: 0.3200 - categorical_accuracy: 0.8858\n",
      "Epoch 13/15\n",
      "9182/9182 [==============================] - 10s 1ms/step - loss: 0.3162 - categorical_accuracy: 0.8870\n",
      "Epoch 14/15\n",
      "9182/9182 [==============================] - 10s 1ms/step - loss: 0.3121 - categorical_accuracy: 0.8884\n",
      "Epoch 15/15\n",
      "9182/9182 [==============================] - 10s 1ms/step - loss: 0.2940 - categorical_accuracy: 0.8977\n",
      "1806/1806 [==============================] - 1s 363us/step\n",
      ">#1: 86.268\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.96      0.93       676\n",
      "           1       0.93      0.92      0.93       790\n",
      "           2       0.48      0.50      0.49       157\n",
      "           3       0.73      0.56      0.63       183\n",
      "\n",
      "   micro avg       0.86      0.86      0.86      1806\n",
      "   macro avg       0.76      0.74      0.74      1806\n",
      "weighted avg       0.86      0.86      0.86      1806\n",
      "\n",
      "[[648   0  21   7]\n",
      " [ 34 729  25   2]\n",
      " [ 16  33  79  29]\n",
      " [ 22  18  41 102]]\n",
      "[86.26799506866523]\n",
      "Accuracy: 86.268% (+/-0.000)\n"
     ]
    }
   ],
   "source": [
    "# convlstm model\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from numpy import dstack\n",
    "from pandas import read_csv\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import TimeDistributed\n",
    "from keras.layers import ConvLSTM2D\n",
    "from keras.utils import to_categorical\n",
    "from matplotlib import pyplot\n",
    "\n",
    "# fit and evaluate a model\n",
    "def evaluate_model(trainX, trainy, testX, testy):\n",
    "    # define model\n",
    "    verbose, epochs, batch_size = 1, 15, 10\n",
    "    n_timesteps, n_features, n_outputs = trainX.shape[1], trainX.shape[2], trainy.shape[1]\n",
    "    # reshape into subsequences (samples, time steps, rows, cols, channels)\n",
    "    n_steps, n_length = 1, 50\n",
    "    trainX = trainX.reshape((trainX.shape[0], n_steps, 1, n_length, n_features))\n",
    "    testX = testX.reshape((testX.shape[0], n_steps, 1, n_length, n_features))\n",
    "#     print('reshaped')\n",
    "#     print(trainX.shape)\n",
    "    # define model\n",
    "    model = Sequential()\n",
    "    model.add(ConvLSTM2D(filters=64, kernel_size=(1,3), activation='relu', input_shape=(n_steps, 1, n_length, n_features)))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(100, activation='relu'))\n",
    "    model.add(Dense(n_outputs, activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['categorical_accuracy'])\n",
    "    # fit network\n",
    "    model.fit(trainX, trainy, epochs=epochs, batch_size=batch_size, verbose=verbose)\n",
    "    # evaluate model\n",
    "    _, accuracy = model.evaluate(testX, testy, batch_size=batch_size, verbose=1)\n",
    "    prediction = model.predict_classes(testX)\n",
    "    return prediction, accuracy\n",
    "\n",
    "# run an experiment\n",
    "def run_experiment(freq, win, repeats=1):\n",
    "    # load data\n",
    "    trainX, trainy, testX, testy, y_true = load_dataset(freq=freq, win=win, prefix='../data/processed/')\n",
    "#     score = evaluate_model(trainX, trainy, testX, testy)\n",
    "#     print(score)\n",
    "    # repeat experiment\n",
    "    scores = list()\n",
    "    for r in range(repeats):\n",
    "        pred_classes, score = evaluate_model(trainX, trainy, testX, testy)\n",
    "        score = score * 100.0\n",
    "        print('>#%d: %.3f' % (r+1, score))\n",
    "        scores.append(score)\n",
    "        print(classification_report(y_true, pred_classes))\n",
    "        print(confusion_matrix(y_true, pred_classes))\n",
    "    # summarize results\n",
    "    summarize_results(scores)\n",
    "\n",
    "# run the experiment\n",
    "freq = '50'\n",
    "win = '50'\n",
    "run_experiment(freq, win)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
