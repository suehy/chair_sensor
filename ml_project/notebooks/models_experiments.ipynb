{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code running experiments with different models and parameters\n",
    "import pandas as pd\n",
    "from pandas import read_csv\n",
    "from pandas import DataFrame\n",
    "from sklearn.metrics import balanced_accuracy_score, f1_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.naive_bayes import ComplementNB\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from numpy import argmax\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## A separate test set is kept for consistent comparison of models (eg. its semi-supervised counterpart)\n",
    "\n",
    "train_df = pd.read_csv('../data/processed/train.csv')\n",
    "# test_df = pd.read_csv('../data/processed/test.csv')\n",
    "\n",
    "X_train = train_df.drop(['state', 'name'], axis=1)\n",
    "y_train = pd.DataFrame(train_df['state'])\n",
    "\n",
    "# X_test = test_df.drop(['state', 'name'], axis=1)\n",
    "# y_test = pd.DataFrame(test_df['state'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_models(models=dict()):\n",
    "    # nonlinear models\n",
    "#     models['knn'] = KNeighborsClassifier()\n",
    "#     models['cart'] = DecisionTreeClassifier()\n",
    "    models['svm'] = SVC()\n",
    "#     models['bayes'] = GaussianNB()\n",
    "# #     models['mnb'] = MultinomialNB()\n",
    "# #     models['cnb'] = ComplementNB()\n",
    "#     # ensemble models\n",
    "#     models['rf'] = RandomForestClassifier()\n",
    "#     models['et'] = ExtraTreesClassifier()\n",
    "    models['gbm'] = GradientBoostingClassifier()\n",
    "#     models['bag'] = BaggingClassifier()\n",
    "    models['mlp'] = MLPClassifier()\n",
    "    print('Defined %d models' % len(models))\n",
    "    return models\n",
    "\n",
    "# print and plot the results\n",
    "def summarize_results(results, maximize=True):\n",
    "    # create a list of (name, mean(scores)) tuples\n",
    "    mean_scores = [(k,v) for k,v in results.items()]\n",
    "    # sort tuples by mean score\n",
    "    mean_scores = sorted(mean_scores, key=lambda x: x[1])\n",
    "    # reverse for descending order (e.g. for accuracy)\n",
    "    if maximize:\n",
    "        mean_scores = list(reversed(mean_scores))\n",
    "    print()\n",
    "    for name, score in mean_scores:\n",
    "        print('Name=%s, Score=%.3f' % (name, score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = define_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import LeaveOneGroupOut\n",
    "\n",
    "def evaluate_model(trainX, trainy, testX, testy, model):\n",
    "    trainy, testy = trainy[:,0], testy[:,0]\n",
    "    # fit the model\n",
    "    model.fit(trainX, trainy)\n",
    "    # make predictions\n",
    "    yhat = model.predict(testX)\n",
    "\n",
    "#     hat, test = 0,0\n",
    "#     for i in range(len(yhat)):\n",
    "#         if yhat[i] == 0:\n",
    "#             hat += 1\n",
    "#         if testy[i][0] == 0:\n",
    "#             test += 1\n",
    "#     print('hat', hat)\n",
    "#     print('test', test)\n",
    "    # evaluate predictions\n",
    "#     accuracy = balanced_accuracy_score(testy, yhat)\n",
    "    f1_macro = f1_score(testy, yhat, average='macro')\n",
    "    f1_micro = f1_score(testy, yhat, average='micro')\n",
    "    f1 = f1_score(testy, yhat, average=None)\n",
    "\n",
    "#     print('accuracy:', accuracy)\n",
    "#     print(classification_report(testy, yhat))\n",
    "#     print(confusion_matrix(testy, yhat))\n",
    "    return f1, f1_macro, f1_micro\n",
    "\n",
    "def run_logo(clf, X_all, y_all, groups):\n",
    "    logo = LeaveOneGroupOut()\n",
    "    group = 0\n",
    "    \n",
    "    f1s = []\n",
    "    f1_macros = []\n",
    "    f1_micros = []\n",
    "    for train_index, test_index in logo.split(X_all, groups=groups):\n",
    "        group += 1\n",
    "        X_train, X_test = X_all.values[train_index], X_all.values[test_index]\n",
    "        y_train, y_test = y_all.values[train_index], y_all.values[test_index]\n",
    "        f1, f1_macro, f1_micro = evaluate_model(X_train, y_train, X_test, y_test, clf)\n",
    "        f1s.append(f1)\n",
    "        f1_macros.append(f1_macro)\n",
    "        f1_micros.append(f1_micro)\n",
    "#         print(\"Group {0} f1-scores: {1}\".format(group, f1))\n",
    "#         print(f1_macros)\n",
    "#         print(f1_micros)\n",
    "        \n",
    "#     return np.average(f1s, axis=0).tolist()\n",
    "    return np.average(f1s, axis=0).tolist(), [np.average(f1_macros).tolist()], [np.average(f1_micros).tolist()]\n",
    "\n",
    "def evaluate_models(trainX, trainy, models, groups):\n",
    "    results = dict()\n",
    "    for name, model in models.items():\n",
    "        results[name] = run_logo(model, trainX, trainy, groups)\n",
    "        # show process\n",
    "        print(name, results[name])\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Run LOGO CV for all models with no hyperparameter tuning and show f1-scores\n",
    "## These results serves as a baseline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "from os import path\n",
    "import re\n",
    "import csv\n",
    "\n",
    "source = '../data/processed/sklearn'\n",
    "dest = 'results'\n",
    "i = 1\n",
    "for name in listdir(source):\n",
    "    filename = source + '/' + name\n",
    "    if not name.endswith('csv') or not name.startswith('train'):\n",
    "        continue\n",
    "    pattern = 'train' + '[0-9]*[0-9]_[0-9]*[0-9]_[0-9]*[0-9]' + '.csv'\n",
    "    match = re.search(pattern, name)\n",
    "    if not match:\n",
    "        continue\n",
    "        \n",
    "    print(i, 'out of 79 files')\n",
    "    print('Reading file', name)\n",
    "\n",
    "    train_df = pd.read_csv(filename)\n",
    "\n",
    "    X_train = train_df.drop(['state', 'name'], axis=1)\n",
    "    y_train = pd.DataFrame(train_df['state'])\n",
    "    groups = train_df['name']\n",
    "    \n",
    "    # counting the number of samples per class\n",
    "    freq = [0,0,0,0]\n",
    "    for val in y_train['state']:\n",
    "        freq[val] += 1\n",
    "    \n",
    "    print('class frequencies', freq)\n",
    "    \n",
    "    results = evaluate_models(X_train, y_train, models, groups)\n",
    "        \n",
    "    # save results and freq into file per model\n",
    "    combi = re.search('train(.+?).csv', name)\n",
    "    if combi:\n",
    "        combi = combi.group(1)\n",
    "        \n",
    "#     with open(dest + '/combis', 'a+') as outFile:\n",
    "#         row = [combi]\n",
    "#         row.extend(freq)\n",
    "#         writer = csv.writer(outFile)\n",
    "#         writer.writerow(row)\n",
    "    \n",
    "    header = ['comb', 'f1-0', 'f1-1', 'f1-2', 'f1-2', 'macro f1', 'micro f1']\n",
    "\n",
    "    for key in results:\n",
    "        row = [combi]\n",
    "        for e in results[key]:\n",
    "            row.extend(e)\n",
    "        \n",
    "        outFilename = dest + '/' + key + '.csv'\n",
    "        if not path.isfile(outFilename):\n",
    "            print('creating new file', outFilename)\n",
    "            with open(outFilename, 'w') as outFile:\n",
    "                writer = csv.writer(outFile)\n",
    "                writer.writerow(header)\n",
    "                writer.writerow(row)\n",
    "        else:\n",
    "#         row = [combi]\n",
    "#         row.extend(freq)\n",
    "#         writer = csv.writer(outFile)\n",
    "#         writer.writerow(row)\n",
    "            print('opening existing file', outFilename)\n",
    "            with open(outFilename, 'a+') as outFile:\n",
    "                writer = csv.writer(outFile)\n",
    "                writer.writerow(row)\n",
    "    i += 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# experiments keras neural network models\n",
    "# from numpy import mean\n",
    "# from numpy import std\n",
    "# from numpy import dstack\n",
    "# import numpy as np\n",
    "# from pandas import read_csv\n",
    "# import tensorflow as tf\n",
    "# from keras.models import Sequential\n",
    "# from keras.layers import Dense\n",
    "# from keras.layers import Flatten\n",
    "# from keras.layers import Dropout\n",
    "# from keras.layers import LSTM\n",
    "# from keras.utils import to_categorical\n",
    "# from keras.layers import Bidirectional\n",
    "\n",
    "# from matplotlib import pyplot\n",
    "\n",
    "# from sklearn.metrics import confusion_matrix\n",
    "# from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load a single file as a numpy array\n",
    "# def load_file(filepath):\n",
    "#     dataframe = read_csv(filepath, header=None)\n",
    "#     return dataframe.values\n",
    "\n",
    "# # load a list of files and return as a 3d numpy array\n",
    "# def load_group(filenames, prefix=''):\n",
    "#     loaded = list()\n",
    "#     for name in filenames:\n",
    "#         data = load_file(prefix + name)\n",
    "#         loaded.append(data)\n",
    "#     # stack group so that features are the 3rd dimension\n",
    "#     print('loaded', len(loaded[0]))\n",
    "#     print('loaded', loaded)\n",
    "#     loaded = dstack(loaded)\n",
    "#     print('stacked', loaded.shape)\n",
    "#     print('stacked', loaded)\n",
    "#     return loaded\n",
    "\n",
    "# # load a dataset group, such as train or test\n",
    "# def load_dataset_group(group, freq, win, prefix=''):\n",
    "#     filepath = prefix + group + '/'\n",
    "#     # load all 9 files as a single array\n",
    "#     filenames = list()\n",
    "#     # total acceleration\n",
    "#     filenames += ['total_acc_x_'+group+'_'+win+'_'+freq+'.csv', 'total_acc_y_'+group+'_'+win+'_'+freq+'.csv', 'total_acc_z_'+group+'_'+win+'_'+freq+'.csv']\n",
    "#     # load input data\n",
    "#     X = load_group(filenames, filepath)\n",
    "#     # load class output\n",
    "#     y = load_file(prefix + group + '/state_'+group+'_'+win+'_'+freq+'.csv')\n",
    "#     print('X:', filenames)\n",
    "#     print('y:', prefix + group + '/state_'+group+'_'+win+'_'+freq+'.csv')\n",
    "#     return X, y\n",
    "\n",
    "# # load the dataset, returns train and test X and y elements\n",
    "# def load_dataset(freq, win, prefix=''):\n",
    "#     # load all train\n",
    "#     trainX, trainy = load_dataset_group('train', freq, win, prefix)\n",
    "#     print(trainX.shape, trainy.shape)\n",
    "#     # load all test\n",
    "#     testX, testy = load_dataset_group('test', freq, win, prefix)\n",
    "#     print(testX.shape, testy.shape)\n",
    "#     # zero-offset class values\n",
    "# #     trainy = trainy - 1\n",
    "# #     testy = testy - 1\n",
    "#     # one hot encode y\n",
    "#     trainy = to_categorical(trainy)\n",
    "#     y_true = testy\n",
    "#     testy = to_categorical(testy)\n",
    "#     print(trainX.shape, trainy.shape, testX.shape, testy.shape)\n",
    "#     return trainX, trainy, testX, testy, y_true\n",
    "\n",
    "# # summarize scores\n",
    "# def summarize_results(scores):\n",
    "#     print(scores)\n",
    "#     m, s = mean(scores), std(scores)\n",
    "#     print('Accuracy: %.3f%% (+/-%.3f)' % (m, s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lstm model\n",
    "\n",
    "# fit and evaluate a model\n",
    "# def evaluate_model(trainX, trainy, testX, testy):\n",
    "#     verbose, epochs, batch_size = 1, 20, 10\n",
    "#     n_timesteps, n_features, n_outputs = trainX.shape[1], trainX.shape[2], trainy.shape[1]\n",
    "#     model = Sequential()\n",
    "#     model.add(LSTM(100, input_shape=(n_timesteps,n_features)))\n",
    "#     model.add(Dropout(0.5))\n",
    "#     model.add(Dense(100, activation='relu'))\n",
    "#     model.add(Dense(n_outputs, activation='softmax'))\n",
    "#     model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['categorical_accuracy'])\n",
    "#     # fit network\n",
    "# #     model.fit(trainX, trainy, validation_split=0.2, epochs=epochs, batch_size=batch_size, verbose=verbose)\n",
    "#     model.fit(trainX, trainy, epochs=epochs, batch_size=batch_size, verbose=verbose)\n",
    "#     # evaluate model\n",
    "#     _, accuracy = model.evaluate(testX, testy, batch_size=batch_size, verbose=1)\n",
    "#     prediction = model.predict_classes(testX)\n",
    "#     return prediction, accuracy, model\n",
    "\n",
    "# # run an experiment\n",
    "# def run_experiment(freq, win, repeats=1):\n",
    "#     # load data\n",
    "#     trainX, trainy, testX, testy, y_true = load_dataset(freq=freq, win=win, prefix='../data/processed/')\n",
    "# #     score = evaluate_model(trainX, trainy, testX, testy)\n",
    "# #     print(score)\n",
    "#     # repeat experiment\n",
    "#     scores = list()\n",
    "# #     for r in range(repeats):\n",
    "#     pred_classes, score, model = evaluate_model(trainX, trainy, testX, testy)\n",
    "#     print(score)\n",
    "#     score = score * 100.0\n",
    "#     print('>#%d: %.3f' % (1, score))\n",
    "#     scores.append(score)\n",
    "# #     print(classification_report(y_true, pred_classes))\n",
    "# #     print(confusion_matrix(y_true, pred_classes))\n",
    "#     # summarize results\n",
    "#     summarize_results(scores)\n",
    "#     return pred_classes, y_true, model\n",
    "\n",
    "# # run the experiment\n",
    "# freq = '50'\n",
    "# win = '50'\n",
    "# pred_classes, y_true, model = run_experiment(freq, win)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
